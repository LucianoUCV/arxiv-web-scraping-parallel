<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization</title>
<!--Generated on Mon May 26 12:36:25 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on May 26, 2025.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2505.19912v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S1" title="In APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S2" title="In APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>The Adjacent Possible: From Evolutionary Theory to LLMs</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S2.SS1" title="In 2 The Adjacent Possible: From Evolutionary Theory to LLMs â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Incremental Evolution in Complex Systems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S2.SS2" title="In 2 The Adjacent Possible: From Evolutionary Theory to LLMs â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Applying the Adjacent Possible to LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S2.SS3" title="In 2 The Adjacent Possible: From Evolutionary Theory to LLMs â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Applying the Adjacent Possible to LLMs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S3" title="In APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data-Centric AI and Efficient Adaptation: Trends and Benchmarks</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S3.SS1" title="In 3 Data-Centric AI and Efficient Adaptation: Trends and Benchmarks â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Data-Centric AI and Incremental Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S3.SS2" title="In 3 Data-Centric AI and Efficient Adaptation: Trends and Benchmarks â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Large Language Models and Adaptation Challenges</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S3.SS3" title="In 3 Data-Centric AI and Efficient Adaptation: Trends and Benchmarks â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Data-Centric AI and Incremental Learning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S4" title="In APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S4.SS1" title="In 4 Experimental Setup â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Dataset, Model, and Computational Constraints</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S4.SS2" title="In 4 Experimental Setup â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Perturbations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S4.SS3" title="In 4 Experimental Setup â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Evaluation Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5" title="In APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiment Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.SS1" title="In 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Quantitative Results (Full Experiment)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.SS2" title="In 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Qualitative Analysis (Scaled-Down Experiment)</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S6" title="In APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S7" title="In APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S8" title="In APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S9" title="In APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Appendix: Code</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Javier MarÃ­n 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">javier@jmarin.info</span>
<br class="ltx_break"/>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
</div>
<div class="ltx_dates">(May 26, 2025)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">We present Adjacent Possible Exploration (APE), a simple yet effective method for adapting large language models to specific tasks using minimal computational resources. Unlike traditional fine-tuning that requires extensive compute, APE iteratively fine-tunes models on small, carefully selected data batches (200 examples), retaining only improvements. On news summarization, APE achieves 33.9% BLEU improvement using just a T4 GPU in 60 minutes, matching or exceeding more complex methods like LoRA while remaining conceptually simple. Our approach is particularly valuable for researchers and practitioners with limited computational resources. We provide open-source code and demonstrate APEâ€™s effectiveness through both automatic metrics and human evaluation. While inspired by evolutionary theoryâ€™s â€™adjacent possible,â€™ APEâ€™s core insight has a very practical application: small, iterative data perturbations can efficiently guide LLMs toward task-specific performance without expensive retraining.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs) excel in tasks like text generation and translationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib5" title="">5</a>]</cite>, yet adapting them to specific domains, such as news summarization, often requires resource-intensive post-trainingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib3" title="">3</a>]</cite>. This tension between generalization and task-specific performance prompts a key question: how can we adapt LLMs efficiently without extensive retraining? We propose Adjacent Possible Exploration (APE), a data-centric methodology that serves as a reusable benchmark for LLM adaptation across diverse tasks, not just summarization, by leveraging small, iterative data perturbations. APE bridges evolutionary theory and AI, offering a scalable, data-driven alternative to high resources demanding methods.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Drawing on Evolutionary EpistemologyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib6" title="">6</a>]</cite>, which views cognitive and technological progress through an evolutionary lens, we apply Stuart Kauffmanâ€™s â€œadjacent possibleâ€ (TAP) theoryÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib19" title="">19</a>]</cite> as a heuristic. TAP theory postulates that complex systemsâ€”biologicalÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib36" title="">36</a>]</cite>, technologicalÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib1" title="">1</a>]</cite>, or computationalÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib18" title="">18</a>]</cite>â€”evolve via small, emergent steps. In biology, a new enzyme might unlock a metabolic pathÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib36" title="">36</a>]</cite>; in LLMs, data perturbations can enhance task performance by exploring nearby possibilitiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib23" title="">23</a>]</cite>. APE harnesses this principle, considering LLMsâ€™ parameter spaces as ecosystems ripe for exploration through controlled data tweaks, analogous to evolutionary niche expansionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib21" title="">21</a>]</cite>. While this biological â€œanalogy-as-heuristicâ€ guides optimization, it cannot fully capture lifeâ€™s self-organizing dynamics.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">APE offers a computationally efficient benchmark by fine-tuning LLMs on small data batches, avoiding large-scale retrainingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib3" title="">3</a>]</cite>. Unlike full fine-tuning, which risks overfitting, or parameter-efficient methods like prompt tuning and adapters, APE reduces resource demands, preserves pre-trained knowledge, and enables dynamic adjustments. Its data-centric focus aligns with AI trendsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib25" title="">25</a>]</cite>, balancing objectives like informativeness and fluency. Beyond news summarization, APEâ€™s iterative approach can benchmark adaptation on datasets like XSum or Multi-News for tasks such as question answering or multi-document summarization, requiring only minimal adjustments, thus broadening its utility in resource-constrained settings.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>The Adjacent Possible: From Evolutionary Theory to LLMs</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Incremental Evolution in Complex Systems</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The â€œadjacent possibleâ€ (TAP) was introduced by Stuart Kauffman to describe how evolutionary systems expand through incremental, emergent stepsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib21" title="">21</a>]</cite>. In biological evolution, TAP represents possibilities one step from the current stateâ€”new molecular interactions or ecological niches emerging from existing configurations. For instance, a new enzyme might enable a bacterium to metabolize a novel substrate, opening paths for further adaptationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib20" title="">20</a>]</cite>. This process is stochastic yet constrained, exploring nearby possibilities rather than leaping to distant states, often yielding unexpected innovations through self-organization.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Applying the Adjacent Possible to LLMs</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.4">Adjacent Possible Exploration (APE) adapts TAP as a heuristic framework to guide iterative fine-tuning of large language models (LLMs). At each iteration, APE fine-tunes the model on a small data batch, retaining updates only if performance improves, systematically exploring â€œadjacentâ€ possibilitiesâ€”small, feasible data perturbationsâ€”to enhance task-specific outcomes while mitigating risks like catastrophic forgettingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib26" title="">26</a>]</cite>. To illustrate this, we model performance evolution using a simplified logistic equation. Let <math alttext="S(t)" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.1"><semantics id="S2.SS2.p1.1.m1.1a"><mrow id="S2.SS2.p1.1.m1.1.2" xref="S2.SS2.p1.1.m1.1.2.cmml"><mi id="S2.SS2.p1.1.m1.1.2.2" xref="S2.SS2.p1.1.m1.1.2.2.cmml">S</mi><mo id="S2.SS2.p1.1.m1.1.2.1" xref="S2.SS2.p1.1.m1.1.2.1.cmml">â¢</mo><mrow id="S2.SS2.p1.1.m1.1.2.3.2" xref="S2.SS2.p1.1.m1.1.2.cmml"><mo id="S2.SS2.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S2.SS2.p1.1.m1.1.2.cmml">(</mo><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">t</mi><mo id="S2.SS2.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S2.SS2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.2"><times id="S2.SS2.p1.1.m1.1.2.1.cmml" xref="S2.SS2.p1.1.m1.1.2.1"></times><ci id="S2.SS2.p1.1.m1.1.2.2.cmml" xref="S2.SS2.p1.1.m1.1.2.2">ğ‘†</ci><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">S(t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.1d">italic_S ( italic_t )</annotation></semantics></math> represent the modelâ€™s performance at iteration <math alttext="t" class="ltx_Math" display="inline" id="S2.SS2.p1.2.m2.1"><semantics id="S2.SS2.p1.2.m2.1a"><mi id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.2.m2.1d">italic_t</annotation></semantics></math>, with <math alttext="S(0)=S_{0}" class="ltx_Math" display="inline" id="S2.SS2.p1.3.m3.1"><semantics id="S2.SS2.p1.3.m3.1a"><mrow id="S2.SS2.p1.3.m3.1.2" xref="S2.SS2.p1.3.m3.1.2.cmml"><mrow id="S2.SS2.p1.3.m3.1.2.2" xref="S2.SS2.p1.3.m3.1.2.2.cmml"><mi id="S2.SS2.p1.3.m3.1.2.2.2" xref="S2.SS2.p1.3.m3.1.2.2.2.cmml">S</mi><mo id="S2.SS2.p1.3.m3.1.2.2.1" xref="S2.SS2.p1.3.m3.1.2.2.1.cmml">â¢</mo><mrow id="S2.SS2.p1.3.m3.1.2.2.3.2" xref="S2.SS2.p1.3.m3.1.2.2.cmml"><mo id="S2.SS2.p1.3.m3.1.2.2.3.2.1" stretchy="false" xref="S2.SS2.p1.3.m3.1.2.2.cmml">(</mo><mn id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">0</mn><mo id="S2.SS2.p1.3.m3.1.2.2.3.2.2" stretchy="false" xref="S2.SS2.p1.3.m3.1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.SS2.p1.3.m3.1.2.1" xref="S2.SS2.p1.3.m3.1.2.1.cmml">=</mo><msub id="S2.SS2.p1.3.m3.1.2.3" xref="S2.SS2.p1.3.m3.1.2.3.cmml"><mi id="S2.SS2.p1.3.m3.1.2.3.2" xref="S2.SS2.p1.3.m3.1.2.3.2.cmml">S</mi><mn id="S2.SS2.p1.3.m3.1.2.3.3" xref="S2.SS2.p1.3.m3.1.2.3.3.cmml">0</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.2.cmml" xref="S2.SS2.p1.3.m3.1.2"><eq id="S2.SS2.p1.3.m3.1.2.1.cmml" xref="S2.SS2.p1.3.m3.1.2.1"></eq><apply id="S2.SS2.p1.3.m3.1.2.2.cmml" xref="S2.SS2.p1.3.m3.1.2.2"><times id="S2.SS2.p1.3.m3.1.2.2.1.cmml" xref="S2.SS2.p1.3.m3.1.2.2.1"></times><ci id="S2.SS2.p1.3.m3.1.2.2.2.cmml" xref="S2.SS2.p1.3.m3.1.2.2.2">ğ‘†</ci><cn id="S2.SS2.p1.3.m3.1.1.cmml" type="integer" xref="S2.SS2.p1.3.m3.1.1">0</cn></apply><apply id="S2.SS2.p1.3.m3.1.2.3.cmml" xref="S2.SS2.p1.3.m3.1.2.3"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.1.2.3.1.cmml" xref="S2.SS2.p1.3.m3.1.2.3">subscript</csymbol><ci id="S2.SS2.p1.3.m3.1.2.3.2.cmml" xref="S2.SS2.p1.3.m3.1.2.3.2">ğ‘†</ci><cn id="S2.SS2.p1.3.m3.1.2.3.3.cmml" type="integer" xref="S2.SS2.p1.3.m3.1.2.3.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">S(0)=S_{0}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.3.m3.1d">italic_S ( 0 ) = italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> as the pre-trained baseline and <math alttext="S_{\max}" class="ltx_Math" display="inline" id="S2.SS2.p1.4.m4.1"><semantics id="S2.SS2.p1.4.m4.1a"><msub id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">S</mi><mi id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">max</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">ğ‘†</ci><max id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3"></max></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">S_{\max}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.4.m4.1d">italic_S start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT</annotation></semantics></math> as the taskâ€™s theoretical maximum (e.g., a normalized BLEU or ROUGE score). The performance growth is approximated as:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\frac{dS(t)}{dt}\approx k\cdot S(t)\cdot\left(1-\frac{S(t)}{S_{\max}}\right)," class="ltx_Math" display="block" id="S2.Ex1.m1.4"><semantics id="S2.Ex1.m1.4a"><mrow id="S2.Ex1.m1.4.4.1" xref="S2.Ex1.m1.4.4.1.1.cmml"><mrow id="S2.Ex1.m1.4.4.1.1" xref="S2.Ex1.m1.4.4.1.1.cmml"><mfrac id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml"><mrow id="S2.Ex1.m1.1.1.1" xref="S2.Ex1.m1.1.1.1.cmml"><mi id="S2.Ex1.m1.1.1.1.3" xref="S2.Ex1.m1.1.1.1.3.cmml">d</mi><mo id="S2.Ex1.m1.1.1.1.2" xref="S2.Ex1.m1.1.1.1.2.cmml">â¢</mo><mi id="S2.Ex1.m1.1.1.1.4" xref="S2.Ex1.m1.1.1.1.4.cmml">S</mi><mo id="S2.Ex1.m1.1.1.1.2a" xref="S2.Ex1.m1.1.1.1.2.cmml">â¢</mo><mrow id="S2.Ex1.m1.1.1.1.5.2" xref="S2.Ex1.m1.1.1.1.cmml"><mo id="S2.Ex1.m1.1.1.1.5.2.1" stretchy="false" xref="S2.Ex1.m1.1.1.1.cmml">(</mo><mi id="S2.Ex1.m1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.cmml">t</mi><mo id="S2.Ex1.m1.1.1.1.5.2.2" stretchy="false" xref="S2.Ex1.m1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.Ex1.m1.1.1.3" xref="S2.Ex1.m1.1.1.3.cmml"><mi id="S2.Ex1.m1.1.1.3.2" xref="S2.Ex1.m1.1.1.3.2.cmml">d</mi><mo id="S2.Ex1.m1.1.1.3.1" xref="S2.Ex1.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.Ex1.m1.1.1.3.3" xref="S2.Ex1.m1.1.1.3.3.cmml">t</mi></mrow></mfrac><mo id="S2.Ex1.m1.4.4.1.1.2" xref="S2.Ex1.m1.4.4.1.1.2.cmml">â‰ˆ</mo><mrow id="S2.Ex1.m1.4.4.1.1.1" xref="S2.Ex1.m1.4.4.1.1.1.cmml"><mrow id="S2.Ex1.m1.4.4.1.1.1.3" xref="S2.Ex1.m1.4.4.1.1.1.3.cmml"><mrow id="S2.Ex1.m1.4.4.1.1.1.3.2" xref="S2.Ex1.m1.4.4.1.1.1.3.2.cmml"><mi id="S2.Ex1.m1.4.4.1.1.1.3.2.2" xref="S2.Ex1.m1.4.4.1.1.1.3.2.2.cmml">k</mi><mo id="S2.Ex1.m1.4.4.1.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.Ex1.m1.4.4.1.1.1.3.2.1.cmml">â‹…</mo><mi id="S2.Ex1.m1.4.4.1.1.1.3.2.3" xref="S2.Ex1.m1.4.4.1.1.1.3.2.3.cmml">S</mi></mrow><mo id="S2.Ex1.m1.4.4.1.1.1.3.1" xref="S2.Ex1.m1.4.4.1.1.1.3.1.cmml">â¢</mo><mrow id="S2.Ex1.m1.4.4.1.1.1.3.3.2" xref="S2.Ex1.m1.4.4.1.1.1.3.cmml"><mo id="S2.Ex1.m1.4.4.1.1.1.3.3.2.1" stretchy="false" xref="S2.Ex1.m1.4.4.1.1.1.3.cmml">(</mo><mi id="S2.Ex1.m1.3.3" xref="S2.Ex1.m1.3.3.cmml">t</mi><mo id="S2.Ex1.m1.4.4.1.1.1.3.3.2.2" rspace="0.055em" stretchy="false" xref="S2.Ex1.m1.4.4.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.4.4.1.1.1.2" rspace="0.222em" xref="S2.Ex1.m1.4.4.1.1.1.2.cmml">â‹…</mo><mrow id="S2.Ex1.m1.4.4.1.1.1.1.1" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.cmml"><mo id="S2.Ex1.m1.4.4.1.1.1.1.1.2" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex1.m1.4.4.1.1.1.1.1.1" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.cmml"><mn id="S2.Ex1.m1.4.4.1.1.1.1.1.1.2" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml">1</mn><mo id="S2.Ex1.m1.4.4.1.1.1.1.1.1.1" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml">âˆ’</mo><mfrac id="S2.Ex1.m1.2.2" xref="S2.Ex1.m1.2.2.cmml"><mrow id="S2.Ex1.m1.2.2.1" xref="S2.Ex1.m1.2.2.1.cmml"><mi id="S2.Ex1.m1.2.2.1.3" xref="S2.Ex1.m1.2.2.1.3.cmml">S</mi><mo id="S2.Ex1.m1.2.2.1.2" xref="S2.Ex1.m1.2.2.1.2.cmml">â¢</mo><mrow id="S2.Ex1.m1.2.2.1.4.2" xref="S2.Ex1.m1.2.2.1.cmml"><mo id="S2.Ex1.m1.2.2.1.4.2.1" stretchy="false" xref="S2.Ex1.m1.2.2.1.cmml">(</mo><mi id="S2.Ex1.m1.2.2.1.1" xref="S2.Ex1.m1.2.2.1.1.cmml">t</mi><mo id="S2.Ex1.m1.2.2.1.4.2.2" stretchy="false" xref="S2.Ex1.m1.2.2.1.cmml">)</mo></mrow></mrow><msub id="S2.Ex1.m1.2.2.3" xref="S2.Ex1.m1.2.2.3.cmml"><mi id="S2.Ex1.m1.2.2.3.2" xref="S2.Ex1.m1.2.2.3.2.cmml">S</mi><mi id="S2.Ex1.m1.2.2.3.3" xref="S2.Ex1.m1.2.2.3.3.cmml">max</mi></msub></mfrac></mrow><mo id="S2.Ex1.m1.4.4.1.1.1.1.1.3" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.Ex1.m1.4.4.1.2" xref="S2.Ex1.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.4b"><apply id="S2.Ex1.m1.4.4.1.1.cmml" xref="S2.Ex1.m1.4.4.1"><approx id="S2.Ex1.m1.4.4.1.1.2.cmml" xref="S2.Ex1.m1.4.4.1.1.2"></approx><apply id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1"><divide id="S2.Ex1.m1.1.1.2.cmml" xref="S2.Ex1.m1.1.1"></divide><apply id="S2.Ex1.m1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1"><times id="S2.Ex1.m1.1.1.1.2.cmml" xref="S2.Ex1.m1.1.1.1.2"></times><ci id="S2.Ex1.m1.1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.1.3">ğ‘‘</ci><ci id="S2.Ex1.m1.1.1.1.4.cmml" xref="S2.Ex1.m1.1.1.1.4">ğ‘†</ci><ci id="S2.Ex1.m1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1">ğ‘¡</ci></apply><apply id="S2.Ex1.m1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.3"><times id="S2.Ex1.m1.1.1.3.1.cmml" xref="S2.Ex1.m1.1.1.3.1"></times><ci id="S2.Ex1.m1.1.1.3.2.cmml" xref="S2.Ex1.m1.1.1.3.2">ğ‘‘</ci><ci id="S2.Ex1.m1.1.1.3.3.cmml" xref="S2.Ex1.m1.1.1.3.3">ğ‘¡</ci></apply></apply><apply id="S2.Ex1.m1.4.4.1.1.1.cmml" xref="S2.Ex1.m1.4.4.1.1.1"><ci id="S2.Ex1.m1.4.4.1.1.1.2.cmml" xref="S2.Ex1.m1.4.4.1.1.1.2">â‹…</ci><apply id="S2.Ex1.m1.4.4.1.1.1.3.cmml" xref="S2.Ex1.m1.4.4.1.1.1.3"><times id="S2.Ex1.m1.4.4.1.1.1.3.1.cmml" xref="S2.Ex1.m1.4.4.1.1.1.3.1"></times><apply id="S2.Ex1.m1.4.4.1.1.1.3.2.cmml" xref="S2.Ex1.m1.4.4.1.1.1.3.2"><ci id="S2.Ex1.m1.4.4.1.1.1.3.2.1.cmml" xref="S2.Ex1.m1.4.4.1.1.1.3.2.1">â‹…</ci><ci id="S2.Ex1.m1.4.4.1.1.1.3.2.2.cmml" xref="S2.Ex1.m1.4.4.1.1.1.3.2.2">ğ‘˜</ci><ci id="S2.Ex1.m1.4.4.1.1.1.3.2.3.cmml" xref="S2.Ex1.m1.4.4.1.1.1.3.2.3">ğ‘†</ci></apply><ci id="S2.Ex1.m1.3.3.cmml" xref="S2.Ex1.m1.3.3">ğ‘¡</ci></apply><apply id="S2.Ex1.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1.1"><minus id="S2.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.1"></minus><cn id="S2.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml" type="integer" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.2">1</cn><apply id="S2.Ex1.m1.2.2.cmml" xref="S2.Ex1.m1.2.2"><divide id="S2.Ex1.m1.2.2.2.cmml" xref="S2.Ex1.m1.2.2"></divide><apply id="S2.Ex1.m1.2.2.1.cmml" xref="S2.Ex1.m1.2.2.1"><times id="S2.Ex1.m1.2.2.1.2.cmml" xref="S2.Ex1.m1.2.2.1.2"></times><ci id="S2.Ex1.m1.2.2.1.3.cmml" xref="S2.Ex1.m1.2.2.1.3">ğ‘†</ci><ci id="S2.Ex1.m1.2.2.1.1.cmml" xref="S2.Ex1.m1.2.2.1.1">ğ‘¡</ci></apply><apply id="S2.Ex1.m1.2.2.3.cmml" xref="S2.Ex1.m1.2.2.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.2.2.3.1.cmml" xref="S2.Ex1.m1.2.2.3">subscript</csymbol><ci id="S2.Ex1.m1.2.2.3.2.cmml" xref="S2.Ex1.m1.2.2.3.2">ğ‘†</ci><max id="S2.Ex1.m1.2.2.3.3.cmml" xref="S2.Ex1.m1.2.2.3.3"></max></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.4c">\frac{dS(t)}{dt}\approx k\cdot S(t)\cdot\left(1-\frac{S(t)}{S_{\max}}\right),</annotation><annotation encoding="application/x-llamapun" id="S2.Ex1.m1.4d">divide start_ARG italic_d italic_S ( italic_t ) end_ARG start_ARG italic_d italic_t end_ARG â‰ˆ italic_k â‹… italic_S ( italic_t ) â‹… ( 1 - divide start_ARG italic_S ( italic_t ) end_ARG start_ARG italic_S start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT end_ARG ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p1.6">where <math alttext="k" class="ltx_Math" display="inline" id="S2.SS2.p1.5.m1.1"><semantics id="S2.SS2.p1.5.m1.1a"><mi id="S2.SS2.p1.5.m1.1.1" xref="S2.SS2.p1.5.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m1.1b"><ci id="S2.SS2.p1.5.m1.1.1.cmml" xref="S2.SS2.p1.5.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.5.m1.1d">italic_k</annotation></semantics></math> is a rate constant reflecting fine-tuning efficiency. This logistic form captures constrained growth toward <math alttext="S_{\max}" class="ltx_Math" display="inline" id="S2.SS2.p1.6.m2.1"><semantics id="S2.SS2.p1.6.m2.1a"><msub id="S2.SS2.p1.6.m2.1.1" xref="S2.SS2.p1.6.m2.1.1.cmml"><mi id="S2.SS2.p1.6.m2.1.1.2" xref="S2.SS2.p1.6.m2.1.1.2.cmml">S</mi><mi id="S2.SS2.p1.6.m2.1.1.3" xref="S2.SS2.p1.6.m2.1.1.3.cmml">max</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m2.1b"><apply id="S2.SS2.p1.6.m2.1.1.cmml" xref="S2.SS2.p1.6.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m2.1.1.1.cmml" xref="S2.SS2.p1.6.m2.1.1">subscript</csymbol><ci id="S2.SS2.p1.6.m2.1.1.2.cmml" xref="S2.SS2.p1.6.m2.1.1.2">ğ‘†</ci><max id="S2.SS2.p1.6.m2.1.1.3.cmml" xref="S2.SS2.p1.6.m2.1.1.3"></max></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m2.1c">S_{\max}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.6.m2.1d">italic_S start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT</annotation></semantics></math>, aligning with TAPâ€™s incremental nature. These models guide APEâ€™s design, not predict exact outcomes, serving as a heuristic to structure data exploration rather than a precise forecast of performance.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">APEâ€™s TAP-inspired approach differs from standard fine-tuning, which risks overwriting pre-trained knowledge with fixed schedulesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib26" title="">26</a>]</cite>, by dynamically evaluating performance gains (<math alttext="\Delta S(t)&gt;\theta" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mrow id="S2.SS2.p2.1.m1.1.2" xref="S2.SS2.p2.1.m1.1.2.cmml"><mrow id="S2.SS2.p2.1.m1.1.2.2" xref="S2.SS2.p2.1.m1.1.2.2.cmml"><mi id="S2.SS2.p2.1.m1.1.2.2.2" mathvariant="normal" xref="S2.SS2.p2.1.m1.1.2.2.2.cmml">Î”</mi><mo id="S2.SS2.p2.1.m1.1.2.2.1" xref="S2.SS2.p2.1.m1.1.2.2.1.cmml">â¢</mo><mi id="S2.SS2.p2.1.m1.1.2.2.3" xref="S2.SS2.p2.1.m1.1.2.2.3.cmml">S</mi><mo id="S2.SS2.p2.1.m1.1.2.2.1a" xref="S2.SS2.p2.1.m1.1.2.2.1.cmml">â¢</mo><mrow id="S2.SS2.p2.1.m1.1.2.2.4.2" xref="S2.SS2.p2.1.m1.1.2.2.cmml"><mo id="S2.SS2.p2.1.m1.1.2.2.4.2.1" stretchy="false" xref="S2.SS2.p2.1.m1.1.2.2.cmml">(</mo><mi id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">t</mi><mo id="S2.SS2.p2.1.m1.1.2.2.4.2.2" stretchy="false" xref="S2.SS2.p2.1.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.SS2.p2.1.m1.1.2.1" xref="S2.SS2.p2.1.m1.1.2.1.cmml">&gt;</mo><mi id="S2.SS2.p2.1.m1.1.2.3" xref="S2.SS2.p2.1.m1.1.2.3.cmml">Î¸</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><apply id="S2.SS2.p2.1.m1.1.2.cmml" xref="S2.SS2.p2.1.m1.1.2"><gt id="S2.SS2.p2.1.m1.1.2.1.cmml" xref="S2.SS2.p2.1.m1.1.2.1"></gt><apply id="S2.SS2.p2.1.m1.1.2.2.cmml" xref="S2.SS2.p2.1.m1.1.2.2"><times id="S2.SS2.p2.1.m1.1.2.2.1.cmml" xref="S2.SS2.p2.1.m1.1.2.2.1"></times><ci id="S2.SS2.p2.1.m1.1.2.2.2.cmml" xref="S2.SS2.p2.1.m1.1.2.2.2">Î”</ci><ci id="S2.SS2.p2.1.m1.1.2.2.3.cmml" xref="S2.SS2.p2.1.m1.1.2.2.3">ğ‘†</ci><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">ğ‘¡</ci></apply><ci id="S2.SS2.p2.1.m1.1.2.3.cmml" xref="S2.SS2.p2.1.m1.1.2.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">\Delta S(t)&gt;\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">roman_Î” italic_S ( italic_t ) &gt; italic_Î¸</annotation></semantics></math>) after each iteration. Unlike parameter-efficient methods like adaptersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib15" title="">15</a>]</cite> or prompt tuningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib22" title="">22</a>]</cite>, which alter architecture or input space, APE optimizes data selection without structural changes, offering a practical framework for resource-constrained adaptation.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Applying the Adjacent Possible to LLMs</h3>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">The Adjacent Possible Exploration (APE) method leverages the Adjacent Possible (TAP) framework to guide the iterative fine-tuning of large language models (LLMs). It provides a structured formalism that extends beyond standard fine-tuning heuristics. At each iteration, APE fine-tunes the model on a small batch of data, retaining updates only if they improve performance metrics. While iterative fine-tuning on small batches may resemble ad hoc heuristics, APE uses TAP to formalize the exploration process, ensuring that each iteration systematically explores â€œadjacentâ€ possibilitiesâ€”small, feasible perturbations in the training dataâ€”to achieve incremental improvements while mitigating risks such as catastrophic forgettingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib26" title="">26</a>]</cite>. Specifically, TAP provides a framework for selecting data perturbations that are likely to yield meaningful improvements, akin to exploring nearby states in a complex systemÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib34" title="">34</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.3">To formalize this process, we adapt Kauffmanâ€™s TAP frameworkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib21" title="">21</a>]</cite> to model the evolution of the modelâ€™s performance state over training iterations. Let <math alttext="S(t)" class="ltx_Math" display="inline" id="S2.SS3.p2.1.m1.1"><semantics id="S2.SS3.p2.1.m1.1a"><mrow id="S2.SS3.p2.1.m1.1.2" xref="S2.SS3.p2.1.m1.1.2.cmml"><mi id="S2.SS3.p2.1.m1.1.2.2" xref="S2.SS3.p2.1.m1.1.2.2.cmml">S</mi><mo id="S2.SS3.p2.1.m1.1.2.1" xref="S2.SS3.p2.1.m1.1.2.1.cmml">â¢</mo><mrow id="S2.SS3.p2.1.m1.1.2.3.2" xref="S2.SS3.p2.1.m1.1.2.cmml"><mo id="S2.SS3.p2.1.m1.1.2.3.2.1" stretchy="false" xref="S2.SS3.p2.1.m1.1.2.cmml">(</mo><mi id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">t</mi><mo id="S2.SS3.p2.1.m1.1.2.3.2.2" stretchy="false" xref="S2.SS3.p2.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><apply id="S2.SS3.p2.1.m1.1.2.cmml" xref="S2.SS3.p2.1.m1.1.2"><times id="S2.SS3.p2.1.m1.1.2.1.cmml" xref="S2.SS3.p2.1.m1.1.2.1"></times><ci id="S2.SS3.p2.1.m1.1.2.2.cmml" xref="S2.SS3.p2.1.m1.1.2.2">ğ‘†</ci><ci id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">S(t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.1.m1.1d">italic_S ( italic_t )</annotation></semantics></math> represent a proxy for the modelâ€™s performance at iteration <math alttext="t" class="ltx_Math" display="inline" id="S2.SS3.p2.2.m2.1"><semantics id="S2.SS3.p2.2.m2.1a"><mi id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><ci id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.2.m2.1d">italic_t</annotation></semantics></math>, with <math alttext="S(0)=S_{0}" class="ltx_Math" display="inline" id="S2.SS3.p2.3.m3.1"><semantics id="S2.SS3.p2.3.m3.1a"><mrow id="S2.SS3.p2.3.m3.1.2" xref="S2.SS3.p2.3.m3.1.2.cmml"><mrow id="S2.SS3.p2.3.m3.1.2.2" xref="S2.SS3.p2.3.m3.1.2.2.cmml"><mi id="S2.SS3.p2.3.m3.1.2.2.2" xref="S2.SS3.p2.3.m3.1.2.2.2.cmml">S</mi><mo id="S2.SS3.p2.3.m3.1.2.2.1" xref="S2.SS3.p2.3.m3.1.2.2.1.cmml">â¢</mo><mrow id="S2.SS3.p2.3.m3.1.2.2.3.2" xref="S2.SS3.p2.3.m3.1.2.2.cmml"><mo id="S2.SS3.p2.3.m3.1.2.2.3.2.1" stretchy="false" xref="S2.SS3.p2.3.m3.1.2.2.cmml">(</mo><mn id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml">0</mn><mo id="S2.SS3.p2.3.m3.1.2.2.3.2.2" stretchy="false" xref="S2.SS3.p2.3.m3.1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.SS3.p2.3.m3.1.2.1" xref="S2.SS3.p2.3.m3.1.2.1.cmml">=</mo><msub id="S2.SS3.p2.3.m3.1.2.3" xref="S2.SS3.p2.3.m3.1.2.3.cmml"><mi id="S2.SS3.p2.3.m3.1.2.3.2" xref="S2.SS3.p2.3.m3.1.2.3.2.cmml">S</mi><mn id="S2.SS3.p2.3.m3.1.2.3.3" xref="S2.SS3.p2.3.m3.1.2.3.3.cmml">0</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><apply id="S2.SS3.p2.3.m3.1.2.cmml" xref="S2.SS3.p2.3.m3.1.2"><eq id="S2.SS3.p2.3.m3.1.2.1.cmml" xref="S2.SS3.p2.3.m3.1.2.1"></eq><apply id="S2.SS3.p2.3.m3.1.2.2.cmml" xref="S2.SS3.p2.3.m3.1.2.2"><times id="S2.SS3.p2.3.m3.1.2.2.1.cmml" xref="S2.SS3.p2.3.m3.1.2.2.1"></times><ci id="S2.SS3.p2.3.m3.1.2.2.2.cmml" xref="S2.SS3.p2.3.m3.1.2.2.2">ğ‘†</ci><cn id="S2.SS3.p2.3.m3.1.1.cmml" type="integer" xref="S2.SS3.p2.3.m3.1.1">0</cn></apply><apply id="S2.SS3.p2.3.m3.1.2.3.cmml" xref="S2.SS3.p2.3.m3.1.2.3"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.2.3.1.cmml" xref="S2.SS3.p2.3.m3.1.2.3">subscript</csymbol><ci id="S2.SS3.p2.3.m3.1.2.3.2.cmml" xref="S2.SS3.p2.3.m3.1.2.3.2">ğ‘†</ci><cn id="S2.SS3.p2.3.m3.1.2.3.3.cmml" type="integer" xref="S2.SS3.p2.3.m3.1.2.3.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">S(0)=S_{0}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.3.m3.1d">italic_S ( 0 ) = italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> as the initial performance of the pre-trained model. The rate of improvement is approximated by a logistic-like differential equation:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\frac{dS(t)}{dt}\approx k\cdot S(t)\cdot\left(1-\frac{S(t)}{S_{\text{max}}}%
\right)," class="ltx_Math" display="block" id="S2.Ex2.m1.4"><semantics id="S2.Ex2.m1.4a"><mrow id="S2.Ex2.m1.4.4.1" xref="S2.Ex2.m1.4.4.1.1.cmml"><mrow id="S2.Ex2.m1.4.4.1.1" xref="S2.Ex2.m1.4.4.1.1.cmml"><mfrac id="S2.Ex2.m1.1.1" xref="S2.Ex2.m1.1.1.cmml"><mrow id="S2.Ex2.m1.1.1.1" xref="S2.Ex2.m1.1.1.1.cmml"><mi id="S2.Ex2.m1.1.1.1.3" xref="S2.Ex2.m1.1.1.1.3.cmml">d</mi><mo id="S2.Ex2.m1.1.1.1.2" xref="S2.Ex2.m1.1.1.1.2.cmml">â¢</mo><mi id="S2.Ex2.m1.1.1.1.4" xref="S2.Ex2.m1.1.1.1.4.cmml">S</mi><mo id="S2.Ex2.m1.1.1.1.2a" xref="S2.Ex2.m1.1.1.1.2.cmml">â¢</mo><mrow id="S2.Ex2.m1.1.1.1.5.2" xref="S2.Ex2.m1.1.1.1.cmml"><mo id="S2.Ex2.m1.1.1.1.5.2.1" stretchy="false" xref="S2.Ex2.m1.1.1.1.cmml">(</mo><mi id="S2.Ex2.m1.1.1.1.1" xref="S2.Ex2.m1.1.1.1.1.cmml">t</mi><mo id="S2.Ex2.m1.1.1.1.5.2.2" stretchy="false" xref="S2.Ex2.m1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.Ex2.m1.1.1.3" xref="S2.Ex2.m1.1.1.3.cmml"><mi id="S2.Ex2.m1.1.1.3.2" xref="S2.Ex2.m1.1.1.3.2.cmml">d</mi><mo id="S2.Ex2.m1.1.1.3.1" xref="S2.Ex2.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.Ex2.m1.1.1.3.3" xref="S2.Ex2.m1.1.1.3.3.cmml">t</mi></mrow></mfrac><mo id="S2.Ex2.m1.4.4.1.1.2" xref="S2.Ex2.m1.4.4.1.1.2.cmml">â‰ˆ</mo><mrow id="S2.Ex2.m1.4.4.1.1.1" xref="S2.Ex2.m1.4.4.1.1.1.cmml"><mrow id="S2.Ex2.m1.4.4.1.1.1.3" xref="S2.Ex2.m1.4.4.1.1.1.3.cmml"><mrow id="S2.Ex2.m1.4.4.1.1.1.3.2" xref="S2.Ex2.m1.4.4.1.1.1.3.2.cmml"><mi id="S2.Ex2.m1.4.4.1.1.1.3.2.2" xref="S2.Ex2.m1.4.4.1.1.1.3.2.2.cmml">k</mi><mo id="S2.Ex2.m1.4.4.1.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.Ex2.m1.4.4.1.1.1.3.2.1.cmml">â‹…</mo><mi id="S2.Ex2.m1.4.4.1.1.1.3.2.3" xref="S2.Ex2.m1.4.4.1.1.1.3.2.3.cmml">S</mi></mrow><mo id="S2.Ex2.m1.4.4.1.1.1.3.1" xref="S2.Ex2.m1.4.4.1.1.1.3.1.cmml">â¢</mo><mrow id="S2.Ex2.m1.4.4.1.1.1.3.3.2" xref="S2.Ex2.m1.4.4.1.1.1.3.cmml"><mo id="S2.Ex2.m1.4.4.1.1.1.3.3.2.1" stretchy="false" xref="S2.Ex2.m1.4.4.1.1.1.3.cmml">(</mo><mi id="S2.Ex2.m1.3.3" xref="S2.Ex2.m1.3.3.cmml">t</mi><mo id="S2.Ex2.m1.4.4.1.1.1.3.3.2.2" rspace="0.055em" stretchy="false" xref="S2.Ex2.m1.4.4.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="S2.Ex2.m1.4.4.1.1.1.2" rspace="0.222em" xref="S2.Ex2.m1.4.4.1.1.1.2.cmml">â‹…</mo><mrow id="S2.Ex2.m1.4.4.1.1.1.1.1" xref="S2.Ex2.m1.4.4.1.1.1.1.1.1.cmml"><mo id="S2.Ex2.m1.4.4.1.1.1.1.1.2" xref="S2.Ex2.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex2.m1.4.4.1.1.1.1.1.1" xref="S2.Ex2.m1.4.4.1.1.1.1.1.1.cmml"><mn id="S2.Ex2.m1.4.4.1.1.1.1.1.1.2" xref="S2.Ex2.m1.4.4.1.1.1.1.1.1.2.cmml">1</mn><mo id="S2.Ex2.m1.4.4.1.1.1.1.1.1.1" xref="S2.Ex2.m1.4.4.1.1.1.1.1.1.1.cmml">âˆ’</mo><mfrac id="S2.Ex2.m1.2.2" xref="S2.Ex2.m1.2.2.cmml"><mrow id="S2.Ex2.m1.2.2.1" xref="S2.Ex2.m1.2.2.1.cmml"><mi id="S2.Ex2.m1.2.2.1.3" xref="S2.Ex2.m1.2.2.1.3.cmml">S</mi><mo id="S2.Ex2.m1.2.2.1.2" xref="S2.Ex2.m1.2.2.1.2.cmml">â¢</mo><mrow id="S2.Ex2.m1.2.2.1.4.2" xref="S2.Ex2.m1.2.2.1.cmml"><mo id="S2.Ex2.m1.2.2.1.4.2.1" stretchy="false" xref="S2.Ex2.m1.2.2.1.cmml">(</mo><mi id="S2.Ex2.m1.2.2.1.1" xref="S2.Ex2.m1.2.2.1.1.cmml">t</mi><mo id="S2.Ex2.m1.2.2.1.4.2.2" stretchy="false" xref="S2.Ex2.m1.2.2.1.cmml">)</mo></mrow></mrow><msub id="S2.Ex2.m1.2.2.3" xref="S2.Ex2.m1.2.2.3.cmml"><mi id="S2.Ex2.m1.2.2.3.2" xref="S2.Ex2.m1.2.2.3.2.cmml">S</mi><mtext id="S2.Ex2.m1.2.2.3.3" xref="S2.Ex2.m1.2.2.3.3a.cmml">max</mtext></msub></mfrac></mrow><mo id="S2.Ex2.m1.4.4.1.1.1.1.1.3" xref="S2.Ex2.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.Ex2.m1.4.4.1.2" xref="S2.Ex2.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.4b"><apply id="S2.Ex2.m1.4.4.1.1.cmml" xref="S2.Ex2.m1.4.4.1"><approx id="S2.Ex2.m1.4.4.1.1.2.cmml" xref="S2.Ex2.m1.4.4.1.1.2"></approx><apply id="S2.Ex2.m1.1.1.cmml" xref="S2.Ex2.m1.1.1"><divide id="S2.Ex2.m1.1.1.2.cmml" xref="S2.Ex2.m1.1.1"></divide><apply id="S2.Ex2.m1.1.1.1.cmml" xref="S2.Ex2.m1.1.1.1"><times id="S2.Ex2.m1.1.1.1.2.cmml" xref="S2.Ex2.m1.1.1.1.2"></times><ci id="S2.Ex2.m1.1.1.1.3.cmml" xref="S2.Ex2.m1.1.1.1.3">ğ‘‘</ci><ci id="S2.Ex2.m1.1.1.1.4.cmml" xref="S2.Ex2.m1.1.1.1.4">ğ‘†</ci><ci id="S2.Ex2.m1.1.1.1.1.cmml" xref="S2.Ex2.m1.1.1.1.1">ğ‘¡</ci></apply><apply id="S2.Ex2.m1.1.1.3.cmml" xref="S2.Ex2.m1.1.1.3"><times id="S2.Ex2.m1.1.1.3.1.cmml" xref="S2.Ex2.m1.1.1.3.1"></times><ci id="S2.Ex2.m1.1.1.3.2.cmml" xref="S2.Ex2.m1.1.1.3.2">ğ‘‘</ci><ci id="S2.Ex2.m1.1.1.3.3.cmml" xref="S2.Ex2.m1.1.1.3.3">ğ‘¡</ci></apply></apply><apply id="S2.Ex2.m1.4.4.1.1.1.cmml" xref="S2.Ex2.m1.4.4.1.1.1"><ci id="S2.Ex2.m1.4.4.1.1.1.2.cmml" xref="S2.Ex2.m1.4.4.1.1.1.2">â‹…</ci><apply id="S2.Ex2.m1.4.4.1.1.1.3.cmml" xref="S2.Ex2.m1.4.4.1.1.1.3"><times id="S2.Ex2.m1.4.4.1.1.1.3.1.cmml" xref="S2.Ex2.m1.4.4.1.1.1.3.1"></times><apply id="S2.Ex2.m1.4.4.1.1.1.3.2.cmml" xref="S2.Ex2.m1.4.4.1.1.1.3.2"><ci id="S2.Ex2.m1.4.4.1.1.1.3.2.1.cmml" xref="S2.Ex2.m1.4.4.1.1.1.3.2.1">â‹…</ci><ci id="S2.Ex2.m1.4.4.1.1.1.3.2.2.cmml" xref="S2.Ex2.m1.4.4.1.1.1.3.2.2">ğ‘˜</ci><ci id="S2.Ex2.m1.4.4.1.1.1.3.2.3.cmml" xref="S2.Ex2.m1.4.4.1.1.1.3.2.3">ğ‘†</ci></apply><ci id="S2.Ex2.m1.3.3.cmml" xref="S2.Ex2.m1.3.3">ğ‘¡</ci></apply><apply id="S2.Ex2.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.4.4.1.1.1.1.1"><minus id="S2.Ex2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.4.4.1.1.1.1.1.1.1"></minus><cn id="S2.Ex2.m1.4.4.1.1.1.1.1.1.2.cmml" type="integer" xref="S2.Ex2.m1.4.4.1.1.1.1.1.1.2">1</cn><apply id="S2.Ex2.m1.2.2.cmml" xref="S2.Ex2.m1.2.2"><divide id="S2.Ex2.m1.2.2.2.cmml" xref="S2.Ex2.m1.2.2"></divide><apply id="S2.Ex2.m1.2.2.1.cmml" xref="S2.Ex2.m1.2.2.1"><times id="S2.Ex2.m1.2.2.1.2.cmml" xref="S2.Ex2.m1.2.2.1.2"></times><ci id="S2.Ex2.m1.2.2.1.3.cmml" xref="S2.Ex2.m1.2.2.1.3">ğ‘†</ci><ci id="S2.Ex2.m1.2.2.1.1.cmml" xref="S2.Ex2.m1.2.2.1.1">ğ‘¡</ci></apply><apply id="S2.Ex2.m1.2.2.3.cmml" xref="S2.Ex2.m1.2.2.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.2.2.3.1.cmml" xref="S2.Ex2.m1.2.2.3">subscript</csymbol><ci id="S2.Ex2.m1.2.2.3.2.cmml" xref="S2.Ex2.m1.2.2.3.2">ğ‘†</ci><ci id="S2.Ex2.m1.2.2.3.3a.cmml" xref="S2.Ex2.m1.2.2.3.3"><mtext id="S2.Ex2.m1.2.2.3.3.cmml" mathsize="70%" xref="S2.Ex2.m1.2.2.3.3">max</mtext></ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.4c">\frac{dS(t)}{dt}\approx k\cdot S(t)\cdot\left(1-\frac{S(t)}{S_{\text{max}}}%
\right),</annotation><annotation encoding="application/x-llamapun" id="S2.Ex2.m1.4d">divide start_ARG italic_d italic_S ( italic_t ) end_ARG start_ARG italic_d italic_t end_ARG â‰ˆ italic_k â‹… italic_S ( italic_t ) â‹… ( 1 - divide start_ARG italic_S ( italic_t ) end_ARG start_ARG italic_S start_POSTSUBSCRIPT max end_POSTSUBSCRIPT end_ARG ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.p2.9">where <math alttext="k" class="ltx_Math" display="inline" id="S2.SS3.p2.4.m1.1"><semantics id="S2.SS3.p2.4.m1.1a"><mi id="S2.SS3.p2.4.m1.1.1" xref="S2.SS3.p2.4.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m1.1b"><ci id="S2.SS3.p2.4.m1.1.1.cmml" xref="S2.SS3.p2.4.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.4.m1.1d">italic_k</annotation></semantics></math> is a rate constant reflecting the efficiency of each fine-tuning step, and <math alttext="S_{\text{max}}" class="ltx_Math" display="inline" id="S2.SS3.p2.5.m2.1"><semantics id="S2.SS3.p2.5.m2.1a"><msub id="S2.SS3.p2.5.m2.1.1" xref="S2.SS3.p2.5.m2.1.1.cmml"><mi id="S2.SS3.p2.5.m2.1.1.2" xref="S2.SS3.p2.5.m2.1.1.2.cmml">S</mi><mtext id="S2.SS3.p2.5.m2.1.1.3" xref="S2.SS3.p2.5.m2.1.1.3a.cmml">max</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.5.m2.1b"><apply id="S2.SS3.p2.5.m2.1.1.cmml" xref="S2.SS3.p2.5.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.5.m2.1.1.1.cmml" xref="S2.SS3.p2.5.m2.1.1">subscript</csymbol><ci id="S2.SS3.p2.5.m2.1.1.2.cmml" xref="S2.SS3.p2.5.m2.1.1.2">ğ‘†</ci><ci id="S2.SS3.p2.5.m2.1.1.3a.cmml" xref="S2.SS3.p2.5.m2.1.1.3"><mtext id="S2.SS3.p2.5.m2.1.1.3.cmml" mathsize="70%" xref="S2.SS3.p2.5.m2.1.1.3">max</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.5.m2.1c">S_{\text{max}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.5.m2.1d">italic_S start_POSTSUBSCRIPT max end_POSTSUBSCRIPT</annotation></semantics></math> represents the theoretical maximum performance achievable on the task, i.e., the upper bound of performance as defined by a chosen metric or composite score (e.g., the maximum value of BLEU, ROUGE, or a normalized aggregate of multiple metrics). The structure of the equation remains unchanged regardless of the metric used, though the values of <math alttext="S(t)" class="ltx_Math" display="inline" id="S2.SS3.p2.6.m3.1"><semantics id="S2.SS3.p2.6.m3.1a"><mrow id="S2.SS3.p2.6.m3.1.2" xref="S2.SS3.p2.6.m3.1.2.cmml"><mi id="S2.SS3.p2.6.m3.1.2.2" xref="S2.SS3.p2.6.m3.1.2.2.cmml">S</mi><mo id="S2.SS3.p2.6.m3.1.2.1" xref="S2.SS3.p2.6.m3.1.2.1.cmml">â¢</mo><mrow id="S2.SS3.p2.6.m3.1.2.3.2" xref="S2.SS3.p2.6.m3.1.2.cmml"><mo id="S2.SS3.p2.6.m3.1.2.3.2.1" stretchy="false" xref="S2.SS3.p2.6.m3.1.2.cmml">(</mo><mi id="S2.SS3.p2.6.m3.1.1" xref="S2.SS3.p2.6.m3.1.1.cmml">t</mi><mo id="S2.SS3.p2.6.m3.1.2.3.2.2" stretchy="false" xref="S2.SS3.p2.6.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.6.m3.1b"><apply id="S2.SS3.p2.6.m3.1.2.cmml" xref="S2.SS3.p2.6.m3.1.2"><times id="S2.SS3.p2.6.m3.1.2.1.cmml" xref="S2.SS3.p2.6.m3.1.2.1"></times><ci id="S2.SS3.p2.6.m3.1.2.2.cmml" xref="S2.SS3.p2.6.m3.1.2.2">ğ‘†</ci><ci id="S2.SS3.p2.6.m3.1.1.cmml" xref="S2.SS3.p2.6.m3.1.1">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.6.m3.1c">S(t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.6.m3.1d">italic_S ( italic_t )</annotation></semantics></math> and <math alttext="S_{\text{max}}" class="ltx_Math" display="inline" id="S2.SS3.p2.7.m4.1"><semantics id="S2.SS3.p2.7.m4.1a"><msub id="S2.SS3.p2.7.m4.1.1" xref="S2.SS3.p2.7.m4.1.1.cmml"><mi id="S2.SS3.p2.7.m4.1.1.2" xref="S2.SS3.p2.7.m4.1.1.2.cmml">S</mi><mtext id="S2.SS3.p2.7.m4.1.1.3" xref="S2.SS3.p2.7.m4.1.1.3a.cmml">max</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.7.m4.1b"><apply id="S2.SS3.p2.7.m4.1.1.cmml" xref="S2.SS3.p2.7.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.7.m4.1.1.1.cmml" xref="S2.SS3.p2.7.m4.1.1">subscript</csymbol><ci id="S2.SS3.p2.7.m4.1.1.2.cmml" xref="S2.SS3.p2.7.m4.1.1.2">ğ‘†</ci><ci id="S2.SS3.p2.7.m4.1.1.3a.cmml" xref="S2.SS3.p2.7.m4.1.1.3"><mtext id="S2.SS3.p2.7.m4.1.1.3.cmml" mathsize="70%" xref="S2.SS3.p2.7.m4.1.1.3">max</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.7.m4.1c">S_{\text{max}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.7.m4.1d">italic_S start_POSTSUBSCRIPT max end_POSTSUBSCRIPT</annotation></semantics></math> depend on the metricâ€™s scale; for instance, switching from BLEU to ROUGE redefines <math alttext="S(t)" class="ltx_Math" display="inline" id="S2.SS3.p2.8.m5.1"><semantics id="S2.SS3.p2.8.m5.1a"><mrow id="S2.SS3.p2.8.m5.1.2" xref="S2.SS3.p2.8.m5.1.2.cmml"><mi id="S2.SS3.p2.8.m5.1.2.2" xref="S2.SS3.p2.8.m5.1.2.2.cmml">S</mi><mo id="S2.SS3.p2.8.m5.1.2.1" xref="S2.SS3.p2.8.m5.1.2.1.cmml">â¢</mo><mrow id="S2.SS3.p2.8.m5.1.2.3.2" xref="S2.SS3.p2.8.m5.1.2.cmml"><mo id="S2.SS3.p2.8.m5.1.2.3.2.1" stretchy="false" xref="S2.SS3.p2.8.m5.1.2.cmml">(</mo><mi id="S2.SS3.p2.8.m5.1.1" xref="S2.SS3.p2.8.m5.1.1.cmml">t</mi><mo id="S2.SS3.p2.8.m5.1.2.3.2.2" stretchy="false" xref="S2.SS3.p2.8.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.8.m5.1b"><apply id="S2.SS3.p2.8.m5.1.2.cmml" xref="S2.SS3.p2.8.m5.1.2"><times id="S2.SS3.p2.8.m5.1.2.1.cmml" xref="S2.SS3.p2.8.m5.1.2.1"></times><ci id="S2.SS3.p2.8.m5.1.2.2.cmml" xref="S2.SS3.p2.8.m5.1.2.2">ğ‘†</ci><ci id="S2.SS3.p2.8.m5.1.1.cmml" xref="S2.SS3.p2.8.m5.1.1">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.8.m5.1c">S(t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.8.m5.1d">italic_S ( italic_t )</annotation></semantics></math> but preserves the logistic growth toward <math alttext="S_{\text{max}}" class="ltx_Math" display="inline" id="S2.SS3.p2.9.m6.1"><semantics id="S2.SS3.p2.9.m6.1a"><msub id="S2.SS3.p2.9.m6.1.1" xref="S2.SS3.p2.9.m6.1.1.cmml"><mi id="S2.SS3.p2.9.m6.1.1.2" xref="S2.SS3.p2.9.m6.1.1.2.cmml">S</mi><mtext id="S2.SS3.p2.9.m6.1.1.3" xref="S2.SS3.p2.9.m6.1.1.3a.cmml">max</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.9.m6.1b"><apply id="S2.SS3.p2.9.m6.1.1.cmml" xref="S2.SS3.p2.9.m6.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.9.m6.1.1.1.cmml" xref="S2.SS3.p2.9.m6.1.1">subscript</csymbol><ci id="S2.SS3.p2.9.m6.1.1.2.cmml" xref="S2.SS3.p2.9.m6.1.1.2">ğ‘†</ci><ci id="S2.SS3.p2.9.m6.1.1.3a.cmml" xref="S2.SS3.p2.9.m6.1.1.3"><mtext id="S2.SS3.p2.9.m6.1.1.3.cmml" mathsize="70%" xref="S2.SS3.p2.9.m6.1.1.3">max</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.9.m6.1c">S_{\text{max}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.9.m6.1d">italic_S start_POSTSUBSCRIPT max end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.4">This equation captures the constrained nature of TAP in practical systems. Unlike standard fine-tuning, which often uses a fixed schedule and risks overwriting previously learned knowledgeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib26" title="">26</a>]</cite>, APE dynamically guides the fine-tuning process: at each iteration, the performance gain <math alttext="\Delta S(t)" class="ltx_Math" display="inline" id="S2.SS3.p3.1.m1.1"><semantics id="S2.SS3.p3.1.m1.1a"><mrow id="S2.SS3.p3.1.m1.1.2" xref="S2.SS3.p3.1.m1.1.2.cmml"><mi id="S2.SS3.p3.1.m1.1.2.2" mathvariant="normal" xref="S2.SS3.p3.1.m1.1.2.2.cmml">Î”</mi><mo id="S2.SS3.p3.1.m1.1.2.1" xref="S2.SS3.p3.1.m1.1.2.1.cmml">â¢</mo><mi id="S2.SS3.p3.1.m1.1.2.3" xref="S2.SS3.p3.1.m1.1.2.3.cmml">S</mi><mo id="S2.SS3.p3.1.m1.1.2.1a" xref="S2.SS3.p3.1.m1.1.2.1.cmml">â¢</mo><mrow id="S2.SS3.p3.1.m1.1.2.4.2" xref="S2.SS3.p3.1.m1.1.2.cmml"><mo id="S2.SS3.p3.1.m1.1.2.4.2.1" stretchy="false" xref="S2.SS3.p3.1.m1.1.2.cmml">(</mo><mi id="S2.SS3.p3.1.m1.1.1" xref="S2.SS3.p3.1.m1.1.1.cmml">t</mi><mo id="S2.SS3.p3.1.m1.1.2.4.2.2" stretchy="false" xref="S2.SS3.p3.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.1.m1.1b"><apply id="S2.SS3.p3.1.m1.1.2.cmml" xref="S2.SS3.p3.1.m1.1.2"><times id="S2.SS3.p3.1.m1.1.2.1.cmml" xref="S2.SS3.p3.1.m1.1.2.1"></times><ci id="S2.SS3.p3.1.m1.1.2.2.cmml" xref="S2.SS3.p3.1.m1.1.2.2">Î”</ci><ci id="S2.SS3.p3.1.m1.1.2.3.cmml" xref="S2.SS3.p3.1.m1.1.2.3">ğ‘†</ci><ci id="S2.SS3.p3.1.m1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.1.m1.1c">\Delta S(t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.1.m1.1d">roman_Î” italic_S ( italic_t )</annotation></semantics></math> is evaluated, and updates are retained only if <math alttext="\Delta S(t)&gt;\theta" class="ltx_Math" display="inline" id="S2.SS3.p3.2.m2.1"><semantics id="S2.SS3.p3.2.m2.1a"><mrow id="S2.SS3.p3.2.m2.1.2" xref="S2.SS3.p3.2.m2.1.2.cmml"><mrow id="S2.SS3.p3.2.m2.1.2.2" xref="S2.SS3.p3.2.m2.1.2.2.cmml"><mi id="S2.SS3.p3.2.m2.1.2.2.2" mathvariant="normal" xref="S2.SS3.p3.2.m2.1.2.2.2.cmml">Î”</mi><mo id="S2.SS3.p3.2.m2.1.2.2.1" xref="S2.SS3.p3.2.m2.1.2.2.1.cmml">â¢</mo><mi id="S2.SS3.p3.2.m2.1.2.2.3" xref="S2.SS3.p3.2.m2.1.2.2.3.cmml">S</mi><mo id="S2.SS3.p3.2.m2.1.2.2.1a" xref="S2.SS3.p3.2.m2.1.2.2.1.cmml">â¢</mo><mrow id="S2.SS3.p3.2.m2.1.2.2.4.2" xref="S2.SS3.p3.2.m2.1.2.2.cmml"><mo id="S2.SS3.p3.2.m2.1.2.2.4.2.1" stretchy="false" xref="S2.SS3.p3.2.m2.1.2.2.cmml">(</mo><mi id="S2.SS3.p3.2.m2.1.1" xref="S2.SS3.p3.2.m2.1.1.cmml">t</mi><mo id="S2.SS3.p3.2.m2.1.2.2.4.2.2" stretchy="false" xref="S2.SS3.p3.2.m2.1.2.2.cmml">)</mo></mrow></mrow><mo id="S2.SS3.p3.2.m2.1.2.1" xref="S2.SS3.p3.2.m2.1.2.1.cmml">&gt;</mo><mi id="S2.SS3.p3.2.m2.1.2.3" xref="S2.SS3.p3.2.m2.1.2.3.cmml">Î¸</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.2.m2.1b"><apply id="S2.SS3.p3.2.m2.1.2.cmml" xref="S2.SS3.p3.2.m2.1.2"><gt id="S2.SS3.p3.2.m2.1.2.1.cmml" xref="S2.SS3.p3.2.m2.1.2.1"></gt><apply id="S2.SS3.p3.2.m2.1.2.2.cmml" xref="S2.SS3.p3.2.m2.1.2.2"><times id="S2.SS3.p3.2.m2.1.2.2.1.cmml" xref="S2.SS3.p3.2.m2.1.2.2.1"></times><ci id="S2.SS3.p3.2.m2.1.2.2.2.cmml" xref="S2.SS3.p3.2.m2.1.2.2.2">Î”</ci><ci id="S2.SS3.p3.2.m2.1.2.2.3.cmml" xref="S2.SS3.p3.2.m2.1.2.2.3">ğ‘†</ci><ci id="S2.SS3.p3.2.m2.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1">ğ‘¡</ci></apply><ci id="S2.SS3.p3.2.m2.1.2.3.cmml" xref="S2.SS3.p3.2.m2.1.2.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.2.m2.1c">\Delta S(t)&gt;\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.2.m2.1d">roman_Î” italic_S ( italic_t ) &gt; italic_Î¸</annotation></semantics></math>, where <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS3.p3.3.m3.1"><semantics id="S2.SS3.p3.3.m3.1a"><mi id="S2.SS3.p3.3.m3.1.1" xref="S2.SS3.p3.3.m3.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.3.m3.1b"><ci id="S2.SS3.p3.3.m3.1.1.cmml" xref="S2.SS3.p3.3.m3.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.3.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.3.m3.1d">italic_Î¸</annotation></semantics></math> is a threshold derived from the expected growth rate <math alttext="k" class="ltx_Math" display="inline" id="S2.SS3.p3.4.m4.1"><semantics id="S2.SS3.p3.4.m4.1a"><mi id="S2.SS3.p3.4.m4.1.1" xref="S2.SS3.p3.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.4.m4.1b"><ci id="S2.SS3.p3.4.m4.1.1.cmml" xref="S2.SS3.p3.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.4.m4.1d">italic_k</annotation></semantics></math>. This threshold ensures that updates align with TAPâ€™s principle, avoiding large updates that could destabilize the model or lead to overfitting.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><svg class="ltx_picture ltx_centering" height="317.63" id="S2.F1.pic1" overflow="visible" version="1.1" width="473.55"><g fill="#000000" stroke="#000000" transform="translate(0,317.63) matrix(1 0 0 -1 0 0) translate(236.77,0) translate(0,148.19)"><g stroke-width="0.8pt"><path d="M -236.22 -147.64 M -236.22 -147.64 L -236.22 147.64 L 236.22 147.64 L 236.22 -147.64 Z M 236.22 147.64" style="fill:none"></path></g><g stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -107.91 155.22)"><foreignobject height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="216.2"><span class="ltx_text ltx_font_bold" id="S2.F1.pic1.4.4.4.4.1.1">Modelâ€™s Data Space Representation</span></foreignobject></g><g fill="#D9D9D9"><path d="M -163.39 -118.11 C -163.39 -110.5 -169.56 -104.33 -177.17 -104.33 C -184.78 -104.33 -190.94 -110.5 -190.94 -118.11 C -190.94 -125.72 -184.78 -131.89 -177.17 -131.89 C -169.56 -131.89 -163.39 -125.72 -163.39 -118.11 Z M -177.17 -118.11" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M -163.39 -59.06 C -163.39 -51.44 -169.56 -45.28 -177.17 -45.28 C -184.78 -45.28 -190.94 -51.44 -190.94 -59.06 C -190.94 -66.67 -184.78 -72.83 -177.17 -72.83 C -169.56 -72.83 -163.39 -66.67 -163.39 -59.06 Z M -177.17 -59.06" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M -163.39 0 C -163.39 7.61 -169.56 13.78 -177.17 13.78 C -184.78 13.78 -190.94 7.61 -190.94 0 C -190.94 -7.61 -184.78 -13.78 -177.17 -13.78 C -169.56 -13.78 -163.39 -7.61 -163.39 0 Z M -177.17 0" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M -163.39 59.06 C -163.39 66.67 -169.56 72.83 -177.17 72.83 C -184.78 72.83 -190.94 66.67 -190.94 59.06 C -190.94 51.44 -184.78 45.28 -177.17 45.28 C -169.56 45.28 -163.39 51.44 -163.39 59.06 Z M -177.17 59.06" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M -163.39 118.11 C -163.39 125.72 -169.56 131.89 -177.17 131.89 C -184.78 131.89 -190.94 125.72 -190.94 118.11 C -190.94 110.5 -184.78 104.33 -177.17 104.33 C -169.56 104.33 -163.39 110.5 -163.39 118.11 Z M -177.17 118.11" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M -74.8 -118.11 C -74.8 -110.5 -80.97 -104.33 -88.58 -104.33 C -96.19 -104.33 -102.36 -110.5 -102.36 -118.11 C -102.36 -125.72 -96.19 -131.89 -88.58 -131.89 C -80.97 -131.89 -74.8 -125.72 -74.8 -118.11 Z M -88.58 -118.11" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M -74.8 -59.06 C -74.8 -51.44 -80.97 -45.28 -88.58 -45.28 C -96.19 -45.28 -102.36 -51.44 -102.36 -59.06 C -102.36 -66.67 -96.19 -72.83 -88.58 -72.83 C -80.97 -72.83 -74.8 -66.67 -74.8 -59.06 Z M -88.58 -59.06" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M -74.8 0 C -74.8 7.61 -80.97 13.78 -88.58 13.78 C -96.19 13.78 -102.36 7.61 -102.36 0 C -102.36 -7.61 -96.19 -13.78 -88.58 -13.78 C -80.97 -13.78 -74.8 -7.61 -74.8 0 Z M -88.58 0" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M -74.8 59.06 C -74.8 66.67 -80.97 72.83 -88.58 72.83 C -96.19 72.83 -102.36 66.67 -102.36 59.06 C -102.36 51.44 -96.19 45.28 -88.58 45.28 C -80.97 45.28 -74.8 51.44 -74.8 59.06 Z M -88.58 59.06" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M -74.8 118.11 C -74.8 125.72 -80.97 131.89 -88.58 131.89 C -96.19 131.89 -102.36 125.72 -102.36 118.11 C -102.36 110.5 -96.19 104.33 -88.58 104.33 C -80.97 104.33 -74.8 110.5 -74.8 118.11 Z M -88.58 118.11" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 13.78 -118.11 C 13.78 -110.5 7.61 -104.33 0 -104.33 C -7.61 -104.33 -13.78 -110.5 -13.78 -118.11 C -13.78 -125.72 -7.61 -131.89 0 -131.89 C 7.61 -131.89 13.78 -125.72 13.78 -118.11 Z M 0 -118.11" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 13.78 -59.06 C 13.78 -51.44 7.61 -45.28 0 -45.28 C -7.61 -45.28 -13.78 -51.44 -13.78 -59.06 C -13.78 -66.67 -7.61 -72.83 0 -72.83 C 7.61 -72.83 13.78 -66.67 13.78 -59.06 Z M 0 -59.06" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 13.78 0 C 13.78 7.61 7.61 13.78 0 13.78 C -7.61 13.78 -13.78 7.61 -13.78 0 C -13.78 -7.61 -7.61 -13.78 0 -13.78 C 7.61 -13.78 13.78 -7.61 13.78 0 Z M 0 0" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 13.78 59.06 C 13.78 66.67 7.61 72.83 0 72.83 C -7.61 72.83 -13.78 66.67 -13.78 59.06 C -13.78 51.44 -7.61 45.28 0 45.28 C 7.61 45.28 13.78 51.44 13.78 59.06 Z M 0 59.06" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 13.78 118.11 C 13.78 125.72 7.61 131.89 0 131.89 C -7.61 131.89 -13.78 125.72 -13.78 118.11 C -13.78 110.5 -7.61 104.33 0 104.33 C 7.61 104.33 13.78 110.5 13.78 118.11 Z M 0 118.11" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 102.36 -118.11 C 102.36 -110.5 96.19 -104.33 88.58 -104.33 C 80.97 -104.33 74.8 -110.5 74.8 -118.11 C 74.8 -125.72 80.97 -131.89 88.58 -131.89 C 96.19 -131.89 102.36 -125.72 102.36 -118.11 Z M 88.58 -118.11" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 102.36 -59.06 C 102.36 -51.44 96.19 -45.28 88.58 -45.28 C 80.97 -45.28 74.8 -51.44 74.8 -59.06 C 74.8 -66.67 80.97 -72.83 88.58 -72.83 C 96.19 -72.83 102.36 -66.67 102.36 -59.06 Z M 88.58 -59.06" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 102.36 0 C 102.36 7.61 96.19 13.78 88.58 13.78 C 80.97 13.78 74.8 7.61 74.8 0 C 74.8 -7.61 80.97 -13.78 88.58 -13.78 C 96.19 -13.78 102.36 -7.61 102.36 0 Z M 88.58 0" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 102.36 59.06 C 102.36 66.67 96.19 72.83 88.58 72.83 C 80.97 72.83 74.8 66.67 74.8 59.06 C 74.8 51.44 80.97 45.28 88.58 45.28 C 96.19 45.28 102.36 51.44 102.36 59.06 Z M 88.58 59.06" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 102.36 118.11 C 102.36 125.72 96.19 131.89 88.58 131.89 C 80.97 131.89 74.8 125.72 74.8 118.11 C 74.8 110.5 80.97 104.33 88.58 104.33 C 96.19 104.33 102.36 110.5 102.36 118.11 Z M 88.58 118.11" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 190.94 -118.11 C 190.94 -110.5 184.78 -104.33 177.17 -104.33 C 169.56 -104.33 163.39 -110.5 163.39 -118.11 C 163.39 -125.72 169.56 -131.89 177.17 -131.89 C 184.78 -131.89 190.94 -125.72 190.94 -118.11 Z M 177.17 -118.11" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 190.94 -59.06 C 190.94 -51.44 184.78 -45.28 177.17 -45.28 C 169.56 -45.28 163.39 -51.44 163.39 -59.06 C 163.39 -66.67 169.56 -72.83 177.17 -72.83 C 184.78 -72.83 190.94 -66.67 190.94 -59.06 Z M 177.17 -59.06" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 190.94 0 C 190.94 7.61 184.78 13.78 177.17 13.78 C 169.56 13.78 163.39 7.61 163.39 0 C 163.39 -7.61 169.56 -13.78 177.17 -13.78 C 184.78 -13.78 190.94 -7.61 190.94 0 Z M 177.17 0" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 190.94 59.06 C 190.94 66.67 184.78 72.83 177.17 72.83 C 169.56 72.83 163.39 66.67 163.39 59.06 C 163.39 51.44 169.56 45.28 177.17 45.28 C 184.78 45.28 190.94 51.44 190.94 59.06 Z M 177.17 59.06" style="stroke:none"></path></g><g fill="#D9D9D9"><path d="M 190.94 118.11 C 190.94 125.72 184.78 131.89 177.17 131.89 C 169.56 131.89 163.39 125.72 163.39 118.11 C 163.39 110.5 169.56 104.33 177.17 104.33 C 184.78 104.33 190.94 110.5 190.94 118.11 Z M 177.17 118.11" style="stroke:none"></path></g><g fill="#B3FFFF" stroke-width="0.8pt"><path d="M 15.4 0 C 15.4 8.51 8.51 15.4 0 15.4 C -8.51 15.4 -15.4 8.51 -15.4 0 C -15.4 -8.51 -8.51 -15.4 0 -15.4 C 8.51 -15.4 15.4 -8.51 15.4 0 Z M 0 0" style="stroke:none"></path></g><g fill="#000000" stroke="#000000" stroke-width="0.8pt" transform="matrix(1.0 0.0 0.0 1.0 -6.58 -3.48)"><foreignobject height="11.95" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.16"><math alttext="S_{0}" class="ltx_Math" display="inline" id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><msub id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">S</mi><mn id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2">ğ‘†</ci><cn id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">S_{0}</annotation><annotation encoding="application/x-llamapun" id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math></foreignobject></g><g fill="#BFFFBF"><path d="M 102.36 0 C 102.36 7.61 96.19 13.78 88.58 13.78 C 80.97 13.78 74.8 7.61 74.8 0 C 74.8 -7.61 80.97 -13.78 88.58 -13.78 C 96.19 -13.78 102.36 -7.61 102.36 0 Z M 88.58 0" style="stroke:none"></path></g><g fill="#BFFFBF"><path d="M 13.78 59.06 C 13.78 66.67 7.61 72.83 0 72.83 C -7.61 72.83 -13.78 66.67 -13.78 59.06 C -13.78 51.44 -7.61 45.28 0 45.28 C 7.61 45.28 13.78 51.44 13.78 59.06 Z M 0 59.06" style="stroke:none"></path></g><g fill="#B3FFFF"><path d="M 102.36 59.06 C 102.36 66.67 96.19 72.83 88.58 72.83 C 80.97 72.83 74.8 66.67 74.8 59.06 C 74.8 51.44 80.97 45.28 88.58 45.28 C 96.19 45.28 102.36 51.44 102.36 59.06 Z M 88.58 59.06" style="stroke:none"></path></g><g fill="#B3FFFF"><path d="M 190.94 59.06 C 190.94 66.67 184.78 72.83 177.17 72.83 C 169.56 72.83 163.39 66.67 163.39 59.06 C 163.39 51.44 169.56 45.28 177.17 45.28 C 184.78 45.28 190.94 51.44 190.94 59.06 Z M 177.17 59.06" style="stroke:none"></path></g><g fill="#FF9999"><path d="M -74.8 0 C -74.8 7.61 -80.97 13.78 -88.58 13.78 C -96.19 13.78 -102.36 7.61 -102.36 0 C -102.36 -7.61 -96.19 -13.78 -88.58 -13.78 C -80.97 -13.78 -74.8 -7.61 -74.8 0 Z M -88.58 0" style="stroke:none"></path></g><g fill="#FF9999"><path d="M 13.78 -59.06 C 13.78 -51.44 7.61 -45.28 0 -45.28 C -7.61 -45.28 -13.78 -51.44 -13.78 -59.06 C -13.78 -66.67 -7.61 -72.83 0 -72.83 C 7.61 -72.83 13.78 -66.67 13.78 -59.06 Z M 0 -59.06" style="stroke:none"></path></g><g fill="#FF9999"><path d="M -74.8 -59.06 C -74.8 -51.44 -80.97 -45.28 -88.58 -45.28 C -96.19 -45.28 -102.36 -51.44 -102.36 -59.06 C -102.36 -66.67 -96.19 -72.83 -88.58 -72.83 C -80.97 -72.83 -74.8 -66.67 -74.8 -59.06 Z M -88.58 -59.06" style="stroke:none"></path></g><g fill="#FF9999"><path d="M 102.36 -59.06 C 102.36 -51.44 96.19 -45.28 88.58 -45.28 C 80.97 -45.28 74.8 -51.44 74.8 -59.06 C 74.8 -66.67 80.97 -72.83 88.58 -72.83 C 96.19 -72.83 102.36 -66.67 102.36 -59.06 Z M 88.58 -59.06" style="stroke:none"></path></g><g fill="#FF9999"><path d="M -74.8 59.06 C -74.8 66.67 -80.97 72.83 -88.58 72.83 C -96.19 72.83 -102.36 66.67 -102.36 59.06 C -102.36 51.44 -96.19 45.28 -88.58 45.28 C -80.97 45.28 -74.8 51.44 -74.8 59.06 Z M -88.58 59.06" style="stroke:none"></path></g><g color="#8080FF" fill="#8080FF" stroke="#8080FF" stroke-width="0.8pt"><g stroke-width="1.5pt"><path d="M 17.72 17.72 L 69.54 52.27" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2pt" transform="matrix(0.83205 0.5547 -0.5547 0.83205 69.54 52.27)"><path d="M -3.03 4.04 C -2.78 2.53 0 0.25 0.76 0 C 0 -0.25 -2.78 -2.53 -3.03 -4.04" style="fill:none"></path></g></g><g color="#80FF80" fill="#80FF80" stroke="#80FF80" stroke-width="0.8pt"><g stroke-width="1.5pt"><path d="M 23.62 0 L 57.47 0" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2pt" transform="matrix(1.0 0.0 0.0 1.0 57.47 0)"><path d="M -3.03 4.04 C -2.78 2.53 0 0.25 0.76 0 C 0 -0.25 -2.78 -2.53 -3.03 -4.04" style="fill:none"></path></g></g><g color="#80FF80" fill="#80FF80" stroke="#80FF80" stroke-width="0.8pt"><g stroke-width="1.5pt"><path d="M 0 23.62 L 0 36.8" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2pt" transform="matrix(0.0 1.0 -1.0 0.0 0 36.8)"><path d="M -3.03 4.04 C -2.78 2.53 0 0.25 0.76 0 C 0 -0.25 -2.78 -2.53 -3.03 -4.04" style="fill:none"></path></g></g><g color="#8080FF" fill="#8080FF" stroke="#8080FF" stroke-width="0.8pt"><g stroke-width="1.5pt"><path d="M 106.3 59.06 L 154.91 59.06" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2pt" transform="matrix(1.0 0.0 0.0 1.0 154.91 59.06)"><path d="M -3.03 4.04 C -2.78 2.53 0 0.25 0.76 0 C 0 -0.25 -2.78 -2.53 -3.03 -4.04" style="fill:none"></path></g></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 46.23 25.52)"><foreignobject height="9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="42.33"><math alttext="\Delta S&gt;0" class="ltx_Math" display="inline" id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1a"><mrow id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mrow id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml"><mi id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.2" mathsize="90%" mathvariant="normal" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.2.cmml">Î”</mi><mo id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.1" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.1.cmml">â¢</mo><mi id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.3" mathsize="90%" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.3.cmml">S</mi></mrow><mo id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.1" mathsize="90%" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mn id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.3" mathsize="90%" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1"><gt id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.1"></gt><apply id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2"><times id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.1.cmml" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.1"></times><ci id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.2.cmml" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.2">Î”</ci><ci id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.3.cmml" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.2.3">ğ‘†</ci></apply><cn id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1c">\Delta S&gt;0</annotation><annotation encoding="application/x-llamapun" id="S2.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1d">roman_Î” italic_S &gt; 0</annotation></semantics></math></foreignobject></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 105.28 66.85)"><foreignobject height="9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="42.33"><math alttext="\Delta S&gt;0" class="ltx_Math" display="inline" id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1a"><mrow id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mrow id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml"><mi id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.2" mathsize="90%" mathvariant="normal" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.2.cmml">Î”</mi><mo id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.1" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.1.cmml">â¢</mo><mi id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.3" mathsize="90%" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.3.cmml">S</mi></mrow><mo id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.1" mathsize="90%" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mn id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.3" mathsize="90%" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1"><gt id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.1"></gt><apply id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2"><times id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.1.cmml" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.1"></times><ci id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.2.cmml" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.2">Î”</ci><ci id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.3.cmml" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.2.3">ğ‘†</ci></apply><cn id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1c">\Delta S&gt;0</annotation><annotation encoding="application/x-llamapun" id="S2.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1d">roman_Î” italic_S &gt; 0</annotation></semantics></math></foreignobject></g></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Data space representation of APE. The 5Ã—5 grid represents all possible model states through different training data combinations. The light blue circle (<math alttext="S_{0}" class="ltx_Math" display="inline" id="S2.F1.3.m1.1"><semantics id="S2.F1.3.m1.1b"><msub id="S2.F1.3.m1.1.1" xref="S2.F1.3.m1.1.1.cmml"><mi id="S2.F1.3.m1.1.1.2" xref="S2.F1.3.m1.1.1.2.cmml">S</mi><mn id="S2.F1.3.m1.1.1.3" xref="S2.F1.3.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.F1.3.m1.1c"><apply id="S2.F1.3.m1.1.1.cmml" xref="S2.F1.3.m1.1.1"><csymbol cd="ambiguous" id="S2.F1.3.m1.1.1.1.cmml" xref="S2.F1.3.m1.1.1">subscript</csymbol><ci id="S2.F1.3.m1.1.1.2.cmml" xref="S2.F1.3.m1.1.1.2">ğ‘†</ci><cn id="S2.F1.3.m1.1.1.3.cmml" type="integer" xref="S2.F1.3.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.3.m1.1d">S_{0}</annotation><annotation encoding="application/x-llamapun" id="S2.F1.3.m1.1e">italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>) is the current model state. The eight surrounding circles constitute Kauffmanâ€™s "adjacent possible"â€”states reachable with one perturbation step (200 articles). Of these eight adjacent states, only three (light green and blue) satisfy the fitness constraint <math alttext="\Delta S&gt;0" class="ltx_Math" display="inline" id="S2.F1.4.m2.1"><semantics id="S2.F1.4.m2.1b"><mrow id="S2.F1.4.m2.1.1" xref="S2.F1.4.m2.1.1.cmml"><mrow id="S2.F1.4.m2.1.1.2" xref="S2.F1.4.m2.1.1.2.cmml"><mi id="S2.F1.4.m2.1.1.2.2" mathvariant="normal" xref="S2.F1.4.m2.1.1.2.2.cmml">Î”</mi><mo id="S2.F1.4.m2.1.1.2.1" xref="S2.F1.4.m2.1.1.2.1.cmml">â¢</mo><mi id="S2.F1.4.m2.1.1.2.3" xref="S2.F1.4.m2.1.1.2.3.cmml">S</mi></mrow><mo id="S2.F1.4.m2.1.1.1" xref="S2.F1.4.m2.1.1.1.cmml">&gt;</mo><mn id="S2.F1.4.m2.1.1.3" xref="S2.F1.4.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.4.m2.1c"><apply id="S2.F1.4.m2.1.1.cmml" xref="S2.F1.4.m2.1.1"><gt id="S2.F1.4.m2.1.1.1.cmml" xref="S2.F1.4.m2.1.1.1"></gt><apply id="S2.F1.4.m2.1.1.2.cmml" xref="S2.F1.4.m2.1.1.2"><times id="S2.F1.4.m2.1.1.2.1.cmml" xref="S2.F1.4.m2.1.1.2.1"></times><ci id="S2.F1.4.m2.1.1.2.2.cmml" xref="S2.F1.4.m2.1.1.2.2">Î”</ci><ci id="S2.F1.4.m2.1.1.2.3.cmml" xref="S2.F1.4.m2.1.1.2.3">ğ‘†</ci></apply><cn id="S2.F1.4.m2.1.1.3.cmml" type="integer" xref="S2.F1.4.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.4.m2.1d">\Delta S&gt;0</annotation><annotation encoding="application/x-llamapun" id="S2.F1.4.m2.1e">roman_Î” italic_S &gt; 0</annotation></semantics></math> and are accessible, while five (red) would decrease performance and are therefore blocked. The model evolves by selecting only one from the possible states (blue), ensuring each iteration improves capability while maintaining the incremental exploration principle of the adjacent possible.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1">APE differs from standard fine-tuning heuristics, which often rely on ad hoc decisions such as fixed learning rates or arbitrary batch sizesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib12" title="">12</a>]</cite>. APE is not a heuristic because it leverages TAP to systematically guide the exploration of data perturbations and the retention of updates, ensuring that each iteration targets the most promising adjacent possibilities in a principled manner. For example, TAP informs the selection of data batches that address specific deficiencies in the modelâ€™s performance, a strategy inspired by active learningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib32" title="">32</a>]</cite> but formalized through TAPâ€™s emphasis on incremental explorationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib34" title="">34</a>]</cite>. APE further differs from parameter-efficient fine-tuning methods such as adaptersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib15" title="">15</a>]</cite> and prompt tuningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib22" title="">22</a>]</cite> in its approach to adaptation. Adapters introduce additional layers to the model architecture, tuning a small subset of parameters (e.g., 2â€“4% of the original modelâ€™s parametersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib15" title="">15</a>]</cite>) to achieve efficiency, while prompt tuning modifies the input space by optimizing a set of task-specific promptsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib22" title="">22</a>]</cite>. In contrast, APE performs full fine-tuning but optimizes the data selection process through TAP-guided exploration, focusing only on incremental improvements without altering the model architecture or input space. This approach is particularly suited for tasks requiring significant adaptation where prompt tuning may struggle due to its limited capacity to alter the modelâ€™s internal representationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib22" title="">22</a>]</cite>, and adapters may underperform compared to full fine-tuning due to their constrained parameter updatesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib16" title="">16</a>]</cite>. With all, APE provides a framework that balances adaptability and stability, offering a grounded, motivated alternative to both standard fine-tuning and parameter-efficient methods.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p5">
<p class="ltx_p" id="S2.SS3.p5.1">To illustrate the APE method, we provide its pseudocode in AlgorithmÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#alg1" title="Algorithm 1 â€£ 2.3 Applying the Adjacent Possible to LLMs â€£ 2 The Adjacent Possible: From Evolutionary Theory to LLMs â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">1</span></a>. The algorithm formalizes the iterative exploration of the adjacent possible, guided by the TAP framework, ensuring that each step targets small, feasible improvements in the modelâ€™s performance.</p>
</div>
<figure class="ltx_float ltx_minipage ltx_align_center ltx_align_middle ltx_framed ltx_framed_top" id="alg1" style="width:346.9pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> Adjacent Possible Exploration (APE) for LLM Fine-Tuning</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.3">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.1.1.1" style="font-size:80%;">1:</span></span>Â Â <span class="ltx_text ltx_font_bold" id="alg1.l1.2">Input</span>: Pre-trained LLM <math alttext="M" class="ltx_Math" display="inline" id="alg1.l1.m1.1"><semantics id="alg1.l1.m1.1a"><mi id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.1d">italic_M</annotation></semantics></math>, training dataset <math alttext="D" class="ltx_Math" display="inline" id="alg1.l1.m2.1"><semantics id="alg1.l1.m2.1a"><mi id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><ci id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m2.1d">italic_D</annotation></semantics></math>, initial performance <math alttext="S_{0}" class="ltx_Math" display="inline" id="alg1.l1.m3.1"><semantics id="alg1.l1.m3.1a"><msub id="alg1.l1.m3.1.1" xref="alg1.l1.m3.1.1.cmml"><mi id="alg1.l1.m3.1.1.2" xref="alg1.l1.m3.1.1.2.cmml">S</mi><mn id="alg1.l1.m3.1.1.3" xref="alg1.l1.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.1b"><apply id="alg1.l1.m3.1.1.cmml" xref="alg1.l1.m3.1.1"><csymbol cd="ambiguous" id="alg1.l1.m3.1.1.1.cmml" xref="alg1.l1.m3.1.1">subscript</csymbol><ci id="alg1.l1.m3.1.1.2.cmml" xref="alg1.l1.m3.1.1.2">ğ‘†</ci><cn id="alg1.l1.m3.1.1.3.cmml" type="integer" xref="alg1.l1.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.1c">S_{0}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m3.1d">italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>, rate constant <math alttext="k" class="ltx_Math" display="inline" id="alg1.l1.m4.1"><semantics id="alg1.l1.m4.1a"><mi id="alg1.l1.m4.1.1" xref="alg1.l1.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m4.1b"><ci id="alg1.l1.m4.1.1.cmml" xref="alg1.l1.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m4.1d">italic_k</annotation></semantics></math>, saturation limit <math alttext="S_{\text{max}}" class="ltx_Math" display="inline" id="alg1.l1.m5.1"><semantics id="alg1.l1.m5.1a"><msub id="alg1.l1.m5.1.1" xref="alg1.l1.m5.1.1.cmml"><mi id="alg1.l1.m5.1.1.2" xref="alg1.l1.m5.1.1.2.cmml">S</mi><mtext id="alg1.l1.m5.1.1.3" xref="alg1.l1.m5.1.1.3a.cmml">max</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m5.1b"><apply id="alg1.l1.m5.1.1.cmml" xref="alg1.l1.m5.1.1"><csymbol cd="ambiguous" id="alg1.l1.m5.1.1.1.cmml" xref="alg1.l1.m5.1.1">subscript</csymbol><ci id="alg1.l1.m5.1.1.2.cmml" xref="alg1.l1.m5.1.1.2">ğ‘†</ci><ci id="alg1.l1.m5.1.1.3a.cmml" xref="alg1.l1.m5.1.1.3"><mtext id="alg1.l1.m5.1.1.3.cmml" mathsize="70%" xref="alg1.l1.m5.1.1.3">max</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m5.1c">S_{\text{max}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m5.1d">italic_S start_POSTSUBSCRIPT max end_POSTSUBSCRIPT</annotation></semantics></math>, maximum iterations <math alttext="T" class="ltx_Math" display="inline" id="alg1.l1.m6.1"><semantics id="alg1.l1.m6.1a"><mi id="alg1.l1.m6.1.1" xref="alg1.l1.m6.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m6.1b"><ci id="alg1.l1.m6.1.1.cmml" xref="alg1.l1.m6.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m6.1c">T</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m6.1d">italic_T</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span>Â Â <span class="ltx_text ltx_font_bold" id="alg1.l2.2">Output</span>: Fine-tuned model <math alttext="M" class="ltx_Math" display="inline" id="alg1.l2.m1.1"><semantics id="alg1.l2.m1.1a"><mi id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><ci id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.1d">italic_M</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.1.1.1" style="font-size:80%;">3:</span></span>Â Â Initialize model <math alttext="M\leftarrow M_{\text{pre-trained}}" class="ltx_Math" display="inline" id="alg1.l3.m1.1"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><mi id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml">M</mi><mo id="alg1.l3.m1.1.1.1" stretchy="false" xref="alg1.l3.m1.1.1.1.cmml">â†</mo><msub id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml"><mi id="alg1.l3.m1.1.1.3.2" xref="alg1.l3.m1.1.1.3.2.cmml">M</mi><mtext id="alg1.l3.m1.1.1.3.3" xref="alg1.l3.m1.1.1.3.3a.cmml">pre-trained</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><ci id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1">â†</ci><ci id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2">ğ‘€</ci><apply id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.3.1.cmml" xref="alg1.l3.m1.1.1.3">subscript</csymbol><ci id="alg1.l3.m1.1.1.3.2.cmml" xref="alg1.l3.m1.1.1.3.2">ğ‘€</ci><ci id="alg1.l3.m1.1.1.3.3a.cmml" xref="alg1.l3.m1.1.1.3.3"><mtext id="alg1.l3.m1.1.1.3.3.cmml" mathsize="70%" xref="alg1.l3.m1.1.1.3.3">pre-trained</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">M\leftarrow M_{\text{pre-trained}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.1d">italic_M â† italic_M start_POSTSUBSCRIPT pre-trained end_POSTSUBSCRIPT</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.1.1.1" style="font-size:80%;">4:</span></span>Â Â Compute initial performance <math alttext="S(0)\leftarrow S_{0}" class="ltx_Math" display="inline" id="alg1.l4.m1.1"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1.2" xref="alg1.l4.m1.1.2.cmml"><mrow id="alg1.l4.m1.1.2.2" xref="alg1.l4.m1.1.2.2.cmml"><mi id="alg1.l4.m1.1.2.2.2" xref="alg1.l4.m1.1.2.2.2.cmml">S</mi><mo id="alg1.l4.m1.1.2.2.1" xref="alg1.l4.m1.1.2.2.1.cmml">â¢</mo><mrow id="alg1.l4.m1.1.2.2.3.2" xref="alg1.l4.m1.1.2.2.cmml"><mo id="alg1.l4.m1.1.2.2.3.2.1" stretchy="false" xref="alg1.l4.m1.1.2.2.cmml">(</mo><mn id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">0</mn><mo id="alg1.l4.m1.1.2.2.3.2.2" stretchy="false" xref="alg1.l4.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="alg1.l4.m1.1.2.1" stretchy="false" xref="alg1.l4.m1.1.2.1.cmml">â†</mo><msub id="alg1.l4.m1.1.2.3" xref="alg1.l4.m1.1.2.3.cmml"><mi id="alg1.l4.m1.1.2.3.2" xref="alg1.l4.m1.1.2.3.2.cmml">S</mi><mn id="alg1.l4.m1.1.2.3.3" xref="alg1.l4.m1.1.2.3.3.cmml">0</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.2.cmml" xref="alg1.l4.m1.1.2"><ci id="alg1.l4.m1.1.2.1.cmml" xref="alg1.l4.m1.1.2.1">â†</ci><apply id="alg1.l4.m1.1.2.2.cmml" xref="alg1.l4.m1.1.2.2"><times id="alg1.l4.m1.1.2.2.1.cmml" xref="alg1.l4.m1.1.2.2.1"></times><ci id="alg1.l4.m1.1.2.2.2.cmml" xref="alg1.l4.m1.1.2.2.2">ğ‘†</ci><cn id="alg1.l4.m1.1.1.cmml" type="integer" xref="alg1.l4.m1.1.1">0</cn></apply><apply id="alg1.l4.m1.1.2.3.cmml" xref="alg1.l4.m1.1.2.3"><csymbol cd="ambiguous" id="alg1.l4.m1.1.2.3.1.cmml" xref="alg1.l4.m1.1.2.3">subscript</csymbol><ci id="alg1.l4.m1.1.2.3.2.cmml" xref="alg1.l4.m1.1.2.3.2">ğ‘†</ci><cn id="alg1.l4.m1.1.2.3.3.cmml" type="integer" xref="alg1.l4.m1.1.2.3.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">S(0)\leftarrow S_{0}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.1d">italic_S ( 0 ) â† italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> using a validation set

</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.1.1.1" style="font-size:80%;">5:</span></span>Â Â <span class="ltx_text ltx_font_bold" id="alg1.l5.2">for</span>Â <math alttext="t=1" class="ltx_Math" display="inline" id="alg1.l5.m1.1"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><mi id="alg1.l5.m1.1.1.2" xref="alg1.l5.m1.1.1.2.cmml">t</mi><mo id="alg1.l5.m1.1.1.1" xref="alg1.l5.m1.1.1.1.cmml">=</mo><mn id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><eq id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1"></eq><ci id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2">ğ‘¡</ci><cn id="alg1.l5.m1.1.1.3.cmml" type="integer" xref="alg1.l5.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">t=1</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m1.1d">italic_t = 1</annotation></semantics></math> to <math alttext="T" class="ltx_Math" display="inline" id="alg1.l5.m2.1"><semantics id="alg1.l5.m2.1a"><mi id="alg1.l5.m2.1.1" xref="alg1.l5.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg1.l5.m2.1b"><ci id="alg1.l5.m2.1.1.cmml" xref="alg1.l5.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m2.1d">italic_T</annotation></semantics></math>Â <span class="ltx_text ltx_font_bold" id="alg1.l5.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.1.1.1" style="font-size:80%;">6:</span></span>Â Â Â Â Â Select a small batch <math alttext="B_{t}\subset D" class="ltx_Math" display="inline" id="alg1.l6.m1.1"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><msub id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml"><mi id="alg1.l6.m1.1.1.2.2" xref="alg1.l6.m1.1.1.2.2.cmml">B</mi><mi id="alg1.l6.m1.1.1.2.3" xref="alg1.l6.m1.1.1.2.3.cmml">t</mi></msub><mo id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml">âŠ‚</mo><mi id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><subset id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1"></subset><apply id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.2.1.cmml" xref="alg1.l6.m1.1.1.2">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.2.cmml" xref="alg1.l6.m1.1.1.2.2">ğµ</ci><ci id="alg1.l6.m1.1.1.2.3.cmml" xref="alg1.l6.m1.1.1.2.3">ğ‘¡</ci></apply><ci id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">B_{t}\subset D</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.1d">italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT âŠ‚ italic_D</annotation></semantics></math> targeting deficiencies in <math alttext="M" class="ltx_Math" display="inline" id="alg1.l6.m2.1"><semantics id="alg1.l6.m2.1a"><mi id="alg1.l6.m2.1.1" xref="alg1.l6.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="alg1.l6.m2.1b"><ci id="alg1.l6.m2.1.1.cmml" xref="alg1.l6.m2.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m2.1d">italic_M</annotation></semantics></math>â€™s performance (TAP-guided exploration)

</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.1.1.1" style="font-size:80%;">7:</span></span>Â Â Â Â Â Fine-tune <math alttext="M" class="ltx_Math" display="inline" id="alg1.l7.m1.1"><semantics id="alg1.l7.m1.1a"><mi id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><ci id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.1d">italic_M</annotation></semantics></math> on <math alttext="B_{t}" class="ltx_Math" display="inline" id="alg1.l7.m2.1"><semantics id="alg1.l7.m2.1a"><msub id="alg1.l7.m2.1.1" xref="alg1.l7.m2.1.1.cmml"><mi id="alg1.l7.m2.1.1.2" xref="alg1.l7.m2.1.1.2.cmml">B</mi><mi id="alg1.l7.m2.1.1.3" xref="alg1.l7.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l7.m2.1b"><apply id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1"><csymbol cd="ambiguous" id="alg1.l7.m2.1.1.1.cmml" xref="alg1.l7.m2.1.1">subscript</csymbol><ci id="alg1.l7.m2.1.1.2.cmml" xref="alg1.l7.m2.1.1.2">ğµ</ci><ci id="alg1.l7.m2.1.1.3.cmml" xref="alg1.l7.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m2.1c">B_{t}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m2.1d">italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> to obtain updated model <math alttext="M^{\prime}" class="ltx_Math" display="inline" id="alg1.l7.m3.1"><semantics id="alg1.l7.m3.1a"><msup id="alg1.l7.m3.1.1" xref="alg1.l7.m3.1.1.cmml"><mi id="alg1.l7.m3.1.1.2" xref="alg1.l7.m3.1.1.2.cmml">M</mi><mo id="alg1.l7.m3.1.1.3" xref="alg1.l7.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="alg1.l7.m3.1b"><apply id="alg1.l7.m3.1.1.cmml" xref="alg1.l7.m3.1.1"><csymbol cd="ambiguous" id="alg1.l7.m3.1.1.1.cmml" xref="alg1.l7.m3.1.1">superscript</csymbol><ci id="alg1.l7.m3.1.1.2.cmml" xref="alg1.l7.m3.1.1.2">ğ‘€</ci><ci id="alg1.l7.m3.1.1.3.cmml" xref="alg1.l7.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m3.1c">M^{\prime}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m3.1d">italic_M start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.1.1.1" style="font-size:80%;">8:</span></span>Â Â Â Â Â Compute new performance <math alttext="S^{\prime}(t)" class="ltx_Math" display="inline" id="alg1.l8.m1.1"><semantics id="alg1.l8.m1.1a"><mrow id="alg1.l8.m1.1.2" xref="alg1.l8.m1.1.2.cmml"><msup id="alg1.l8.m1.1.2.2" xref="alg1.l8.m1.1.2.2.cmml"><mi id="alg1.l8.m1.1.2.2.2" xref="alg1.l8.m1.1.2.2.2.cmml">S</mi><mo id="alg1.l8.m1.1.2.2.3" xref="alg1.l8.m1.1.2.2.3.cmml">â€²</mo></msup><mo id="alg1.l8.m1.1.2.1" xref="alg1.l8.m1.1.2.1.cmml">â¢</mo><mrow id="alg1.l8.m1.1.2.3.2" xref="alg1.l8.m1.1.2.cmml"><mo id="alg1.l8.m1.1.2.3.2.1" stretchy="false" xref="alg1.l8.m1.1.2.cmml">(</mo><mi id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml">t</mi><mo id="alg1.l8.m1.1.2.3.2.2" stretchy="false" xref="alg1.l8.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><apply id="alg1.l8.m1.1.2.cmml" xref="alg1.l8.m1.1.2"><times id="alg1.l8.m1.1.2.1.cmml" xref="alg1.l8.m1.1.2.1"></times><apply id="alg1.l8.m1.1.2.2.cmml" xref="alg1.l8.m1.1.2.2"><csymbol cd="ambiguous" id="alg1.l8.m1.1.2.2.1.cmml" xref="alg1.l8.m1.1.2.2">superscript</csymbol><ci id="alg1.l8.m1.1.2.2.2.cmml" xref="alg1.l8.m1.1.2.2.2">ğ‘†</ci><ci id="alg1.l8.m1.1.2.2.3.cmml" xref="alg1.l8.m1.1.2.2.3">â€²</ci></apply><ci id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">S^{\prime}(t)</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m1.1d">italic_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ( italic_t )</annotation></semantics></math> for <math alttext="M^{\prime}" class="ltx_Math" display="inline" id="alg1.l8.m2.1"><semantics id="alg1.l8.m2.1a"><msup id="alg1.l8.m2.1.1" xref="alg1.l8.m2.1.1.cmml"><mi id="alg1.l8.m2.1.1.2" xref="alg1.l8.m2.1.1.2.cmml">M</mi><mo id="alg1.l8.m2.1.1.3" xref="alg1.l8.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="alg1.l8.m2.1b"><apply id="alg1.l8.m2.1.1.cmml" xref="alg1.l8.m2.1.1"><csymbol cd="ambiguous" id="alg1.l8.m2.1.1.1.cmml" xref="alg1.l8.m2.1.1">superscript</csymbol><ci id="alg1.l8.m2.1.1.2.cmml" xref="alg1.l8.m2.1.1.2">ğ‘€</ci><ci id="alg1.l8.m2.1.1.3.cmml" xref="alg1.l8.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m2.1c">M^{\prime}</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m2.1d">italic_M start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math> using a validation set

</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9.1.1.1" style="font-size:80%;">9:</span></span>Â Â Â Â Â Compute performance gain <math alttext="\Delta S(t)\leftarrow S^{\prime}(t)-S(t-1)" class="ltx_Math" display="inline" id="alg1.l9.m1.3"><semantics id="alg1.l9.m1.3a"><mrow id="alg1.l9.m1.3.3" xref="alg1.l9.m1.3.3.cmml"><mrow id="alg1.l9.m1.3.3.3" xref="alg1.l9.m1.3.3.3.cmml"><mi id="alg1.l9.m1.3.3.3.2" mathvariant="normal" xref="alg1.l9.m1.3.3.3.2.cmml">Î”</mi><mo id="alg1.l9.m1.3.3.3.1" xref="alg1.l9.m1.3.3.3.1.cmml">â¢</mo><mi id="alg1.l9.m1.3.3.3.3" xref="alg1.l9.m1.3.3.3.3.cmml">S</mi><mo id="alg1.l9.m1.3.3.3.1a" xref="alg1.l9.m1.3.3.3.1.cmml">â¢</mo><mrow id="alg1.l9.m1.3.3.3.4.2" xref="alg1.l9.m1.3.3.3.cmml"><mo id="alg1.l9.m1.3.3.3.4.2.1" stretchy="false" xref="alg1.l9.m1.3.3.3.cmml">(</mo><mi id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml">t</mi><mo id="alg1.l9.m1.3.3.3.4.2.2" stretchy="false" xref="alg1.l9.m1.3.3.3.cmml">)</mo></mrow></mrow><mo id="alg1.l9.m1.3.3.2" stretchy="false" xref="alg1.l9.m1.3.3.2.cmml">â†</mo><mrow id="alg1.l9.m1.3.3.1" xref="alg1.l9.m1.3.3.1.cmml"><mrow id="alg1.l9.m1.3.3.1.3" xref="alg1.l9.m1.3.3.1.3.cmml"><msup id="alg1.l9.m1.3.3.1.3.2" xref="alg1.l9.m1.3.3.1.3.2.cmml"><mi id="alg1.l9.m1.3.3.1.3.2.2" xref="alg1.l9.m1.3.3.1.3.2.2.cmml">S</mi><mo id="alg1.l9.m1.3.3.1.3.2.3" xref="alg1.l9.m1.3.3.1.3.2.3.cmml">â€²</mo></msup><mo id="alg1.l9.m1.3.3.1.3.1" xref="alg1.l9.m1.3.3.1.3.1.cmml">â¢</mo><mrow id="alg1.l9.m1.3.3.1.3.3.2" xref="alg1.l9.m1.3.3.1.3.cmml"><mo id="alg1.l9.m1.3.3.1.3.3.2.1" stretchy="false" xref="alg1.l9.m1.3.3.1.3.cmml">(</mo><mi id="alg1.l9.m1.2.2" xref="alg1.l9.m1.2.2.cmml">t</mi><mo id="alg1.l9.m1.3.3.1.3.3.2.2" stretchy="false" xref="alg1.l9.m1.3.3.1.3.cmml">)</mo></mrow></mrow><mo id="alg1.l9.m1.3.3.1.2" xref="alg1.l9.m1.3.3.1.2.cmml">âˆ’</mo><mrow id="alg1.l9.m1.3.3.1.1" xref="alg1.l9.m1.3.3.1.1.cmml"><mi id="alg1.l9.m1.3.3.1.1.3" xref="alg1.l9.m1.3.3.1.1.3.cmml">S</mi><mo id="alg1.l9.m1.3.3.1.1.2" xref="alg1.l9.m1.3.3.1.1.2.cmml">â¢</mo><mrow id="alg1.l9.m1.3.3.1.1.1.1" xref="alg1.l9.m1.3.3.1.1.1.1.1.cmml"><mo id="alg1.l9.m1.3.3.1.1.1.1.2" stretchy="false" xref="alg1.l9.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="alg1.l9.m1.3.3.1.1.1.1.1" xref="alg1.l9.m1.3.3.1.1.1.1.1.cmml"><mi id="alg1.l9.m1.3.3.1.1.1.1.1.2" xref="alg1.l9.m1.3.3.1.1.1.1.1.2.cmml">t</mi><mo id="alg1.l9.m1.3.3.1.1.1.1.1.1" xref="alg1.l9.m1.3.3.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="alg1.l9.m1.3.3.1.1.1.1.1.3" xref="alg1.l9.m1.3.3.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="alg1.l9.m1.3.3.1.1.1.1.3" stretchy="false" xref="alg1.l9.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.3b"><apply id="alg1.l9.m1.3.3.cmml" xref="alg1.l9.m1.3.3"><ci id="alg1.l9.m1.3.3.2.cmml" xref="alg1.l9.m1.3.3.2">â†</ci><apply id="alg1.l9.m1.3.3.3.cmml" xref="alg1.l9.m1.3.3.3"><times id="alg1.l9.m1.3.3.3.1.cmml" xref="alg1.l9.m1.3.3.3.1"></times><ci id="alg1.l9.m1.3.3.3.2.cmml" xref="alg1.l9.m1.3.3.3.2">Î”</ci><ci id="alg1.l9.m1.3.3.3.3.cmml" xref="alg1.l9.m1.3.3.3.3">ğ‘†</ci><ci id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1">ğ‘¡</ci></apply><apply id="alg1.l9.m1.3.3.1.cmml" xref="alg1.l9.m1.3.3.1"><minus id="alg1.l9.m1.3.3.1.2.cmml" xref="alg1.l9.m1.3.3.1.2"></minus><apply id="alg1.l9.m1.3.3.1.3.cmml" xref="alg1.l9.m1.3.3.1.3"><times id="alg1.l9.m1.3.3.1.3.1.cmml" xref="alg1.l9.m1.3.3.1.3.1"></times><apply id="alg1.l9.m1.3.3.1.3.2.cmml" xref="alg1.l9.m1.3.3.1.3.2"><csymbol cd="ambiguous" id="alg1.l9.m1.3.3.1.3.2.1.cmml" xref="alg1.l9.m1.3.3.1.3.2">superscript</csymbol><ci id="alg1.l9.m1.3.3.1.3.2.2.cmml" xref="alg1.l9.m1.3.3.1.3.2.2">ğ‘†</ci><ci id="alg1.l9.m1.3.3.1.3.2.3.cmml" xref="alg1.l9.m1.3.3.1.3.2.3">â€²</ci></apply><ci id="alg1.l9.m1.2.2.cmml" xref="alg1.l9.m1.2.2">ğ‘¡</ci></apply><apply id="alg1.l9.m1.3.3.1.1.cmml" xref="alg1.l9.m1.3.3.1.1"><times id="alg1.l9.m1.3.3.1.1.2.cmml" xref="alg1.l9.m1.3.3.1.1.2"></times><ci id="alg1.l9.m1.3.3.1.1.3.cmml" xref="alg1.l9.m1.3.3.1.1.3">ğ‘†</ci><apply id="alg1.l9.m1.3.3.1.1.1.1.1.cmml" xref="alg1.l9.m1.3.3.1.1.1.1"><minus id="alg1.l9.m1.3.3.1.1.1.1.1.1.cmml" xref="alg1.l9.m1.3.3.1.1.1.1.1.1"></minus><ci id="alg1.l9.m1.3.3.1.1.1.1.1.2.cmml" xref="alg1.l9.m1.3.3.1.1.1.1.1.2">ğ‘¡</ci><cn id="alg1.l9.m1.3.3.1.1.1.1.1.3.cmml" type="integer" xref="alg1.l9.m1.3.3.1.1.1.1.1.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.3c">\Delta S(t)\leftarrow S^{\prime}(t)-S(t-1)</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.m1.3d">roman_Î” italic_S ( italic_t ) â† italic_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ( italic_t ) - italic_S ( italic_t - 1 )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l10.1.1.1" style="font-size:80%;">10:</span></span>Â Â Â Â Â Compute threshold <math alttext="\theta\leftarrow k\cdot S(t-1)\cdot\left(1-\frac{S(t-1)}{S_{\text{max}}}\right%
)\Delta t" class="ltx_Math" display="inline" id="alg1.l10.m1.3"><semantics id="alg1.l10.m1.3a"><mrow id="alg1.l10.m1.3.3" xref="alg1.l10.m1.3.3.cmml"><mi id="alg1.l10.m1.3.3.4" xref="alg1.l10.m1.3.3.4.cmml">Î¸</mi><mo id="alg1.l10.m1.3.3.3" stretchy="false" xref="alg1.l10.m1.3.3.3.cmml">â†</mo><mrow id="alg1.l10.m1.3.3.2" xref="alg1.l10.m1.3.3.2.cmml"><mrow id="alg1.l10.m1.3.3.2.2" xref="alg1.l10.m1.3.3.2.2.cmml"><mrow id="alg1.l10.m1.2.2.1.1.1" xref="alg1.l10.m1.2.2.1.1.1.cmml"><mrow id="alg1.l10.m1.2.2.1.1.1.3" xref="alg1.l10.m1.2.2.1.1.1.3.cmml"><mi id="alg1.l10.m1.2.2.1.1.1.3.2" xref="alg1.l10.m1.2.2.1.1.1.3.2.cmml">k</mi><mo id="alg1.l10.m1.2.2.1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="alg1.l10.m1.2.2.1.1.1.3.1.cmml">â‹…</mo><mi id="alg1.l10.m1.2.2.1.1.1.3.3" xref="alg1.l10.m1.2.2.1.1.1.3.3.cmml">S</mi></mrow><mo id="alg1.l10.m1.2.2.1.1.1.2" xref="alg1.l10.m1.2.2.1.1.1.2.cmml">â¢</mo><mrow id="alg1.l10.m1.2.2.1.1.1.1.1" xref="alg1.l10.m1.2.2.1.1.1.1.1.1.cmml"><mo id="alg1.l10.m1.2.2.1.1.1.1.1.2" stretchy="false" xref="alg1.l10.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="alg1.l10.m1.2.2.1.1.1.1.1.1" xref="alg1.l10.m1.2.2.1.1.1.1.1.1.cmml"><mi id="alg1.l10.m1.2.2.1.1.1.1.1.1.2" xref="alg1.l10.m1.2.2.1.1.1.1.1.1.2.cmml">t</mi><mo id="alg1.l10.m1.2.2.1.1.1.1.1.1.1" xref="alg1.l10.m1.2.2.1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="alg1.l10.m1.2.2.1.1.1.1.1.1.3" xref="alg1.l10.m1.2.2.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="alg1.l10.m1.2.2.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="alg1.l10.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l10.m1.3.3.2.2.3" rspace="0.222em" xref="alg1.l10.m1.3.3.2.2.3.cmml">â‹…</mo><mrow id="alg1.l10.m1.3.3.2.2.2.1" xref="alg1.l10.m1.3.3.2.2.2.1.1.cmml"><mo id="alg1.l10.m1.3.3.2.2.2.1.2" xref="alg1.l10.m1.3.3.2.2.2.1.1.cmml">(</mo><mrow id="alg1.l10.m1.3.3.2.2.2.1.1" xref="alg1.l10.m1.3.3.2.2.2.1.1.cmml"><mn id="alg1.l10.m1.3.3.2.2.2.1.1.2" xref="alg1.l10.m1.3.3.2.2.2.1.1.2.cmml">1</mn><mo id="alg1.l10.m1.3.3.2.2.2.1.1.1" xref="alg1.l10.m1.3.3.2.2.2.1.1.1.cmml">âˆ’</mo><mfrac id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml"><mrow id="alg1.l10.m1.1.1.1" xref="alg1.l10.m1.1.1.1.cmml"><mi id="alg1.l10.m1.1.1.1.3" xref="alg1.l10.m1.1.1.1.3.cmml">S</mi><mo id="alg1.l10.m1.1.1.1.2" xref="alg1.l10.m1.1.1.1.2.cmml">â¢</mo><mrow id="alg1.l10.m1.1.1.1.1.1" xref="alg1.l10.m1.1.1.1.1.1.1.cmml"><mo id="alg1.l10.m1.1.1.1.1.1.2" stretchy="false" xref="alg1.l10.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="alg1.l10.m1.1.1.1.1.1.1" xref="alg1.l10.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l10.m1.1.1.1.1.1.1.2" xref="alg1.l10.m1.1.1.1.1.1.1.2.cmml">t</mi><mo id="alg1.l10.m1.1.1.1.1.1.1.1" xref="alg1.l10.m1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="alg1.l10.m1.1.1.1.1.1.1.3" xref="alg1.l10.m1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="alg1.l10.m1.1.1.1.1.1.3" stretchy="false" xref="alg1.l10.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><msub id="alg1.l10.m1.1.1.3" xref="alg1.l10.m1.1.1.3.cmml"><mi id="alg1.l10.m1.1.1.3.2" xref="alg1.l10.m1.1.1.3.2.cmml">S</mi><mtext id="alg1.l10.m1.1.1.3.3" xref="alg1.l10.m1.1.1.3.3a.cmml">max</mtext></msub></mfrac></mrow><mo id="alg1.l10.m1.3.3.2.2.2.1.3" xref="alg1.l10.m1.3.3.2.2.2.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l10.m1.3.3.2.3" xref="alg1.l10.m1.3.3.2.3.cmml">â¢</mo><mi id="alg1.l10.m1.3.3.2.4" mathvariant="normal" xref="alg1.l10.m1.3.3.2.4.cmml">Î”</mi><mo id="alg1.l10.m1.3.3.2.3a" xref="alg1.l10.m1.3.3.2.3.cmml">â¢</mo><mi id="alg1.l10.m1.3.3.2.5" xref="alg1.l10.m1.3.3.2.5.cmml">t</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.3b"><apply id="alg1.l10.m1.3.3.cmml" xref="alg1.l10.m1.3.3"><ci id="alg1.l10.m1.3.3.3.cmml" xref="alg1.l10.m1.3.3.3">â†</ci><ci id="alg1.l10.m1.3.3.4.cmml" xref="alg1.l10.m1.3.3.4">ğœƒ</ci><apply id="alg1.l10.m1.3.3.2.cmml" xref="alg1.l10.m1.3.3.2"><times id="alg1.l10.m1.3.3.2.3.cmml" xref="alg1.l10.m1.3.3.2.3"></times><apply id="alg1.l10.m1.3.3.2.2.cmml" xref="alg1.l10.m1.3.3.2.2"><ci id="alg1.l10.m1.3.3.2.2.3.cmml" xref="alg1.l10.m1.3.3.2.2.3">â‹…</ci><apply id="alg1.l10.m1.2.2.1.1.1.cmml" xref="alg1.l10.m1.2.2.1.1.1"><times id="alg1.l10.m1.2.2.1.1.1.2.cmml" xref="alg1.l10.m1.2.2.1.1.1.2"></times><apply id="alg1.l10.m1.2.2.1.1.1.3.cmml" xref="alg1.l10.m1.2.2.1.1.1.3"><ci id="alg1.l10.m1.2.2.1.1.1.3.1.cmml" xref="alg1.l10.m1.2.2.1.1.1.3.1">â‹…</ci><ci id="alg1.l10.m1.2.2.1.1.1.3.2.cmml" xref="alg1.l10.m1.2.2.1.1.1.3.2">ğ‘˜</ci><ci id="alg1.l10.m1.2.2.1.1.1.3.3.cmml" xref="alg1.l10.m1.2.2.1.1.1.3.3">ğ‘†</ci></apply><apply id="alg1.l10.m1.2.2.1.1.1.1.1.1.cmml" xref="alg1.l10.m1.2.2.1.1.1.1.1"><minus id="alg1.l10.m1.2.2.1.1.1.1.1.1.1.cmml" xref="alg1.l10.m1.2.2.1.1.1.1.1.1.1"></minus><ci id="alg1.l10.m1.2.2.1.1.1.1.1.1.2.cmml" xref="alg1.l10.m1.2.2.1.1.1.1.1.1.2">ğ‘¡</ci><cn id="alg1.l10.m1.2.2.1.1.1.1.1.1.3.cmml" type="integer" xref="alg1.l10.m1.2.2.1.1.1.1.1.1.3">1</cn></apply></apply><apply id="alg1.l10.m1.3.3.2.2.2.1.1.cmml" xref="alg1.l10.m1.3.3.2.2.2.1"><minus id="alg1.l10.m1.3.3.2.2.2.1.1.1.cmml" xref="alg1.l10.m1.3.3.2.2.2.1.1.1"></minus><cn id="alg1.l10.m1.3.3.2.2.2.1.1.2.cmml" type="integer" xref="alg1.l10.m1.3.3.2.2.2.1.1.2">1</cn><apply id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1"><divide id="alg1.l10.m1.1.1.2.cmml" xref="alg1.l10.m1.1.1"></divide><apply id="alg1.l10.m1.1.1.1.cmml" xref="alg1.l10.m1.1.1.1"><times id="alg1.l10.m1.1.1.1.2.cmml" xref="alg1.l10.m1.1.1.1.2"></times><ci id="alg1.l10.m1.1.1.1.3.cmml" xref="alg1.l10.m1.1.1.1.3">ğ‘†</ci><apply id="alg1.l10.m1.1.1.1.1.1.1.cmml" xref="alg1.l10.m1.1.1.1.1.1"><minus id="alg1.l10.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l10.m1.1.1.1.1.1.1.1"></minus><ci id="alg1.l10.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l10.m1.1.1.1.1.1.1.2">ğ‘¡</ci><cn id="alg1.l10.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="alg1.l10.m1.1.1.1.1.1.1.3">1</cn></apply></apply><apply id="alg1.l10.m1.1.1.3.cmml" xref="alg1.l10.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.3.1.cmml" xref="alg1.l10.m1.1.1.3">subscript</csymbol><ci id="alg1.l10.m1.1.1.3.2.cmml" xref="alg1.l10.m1.1.1.3.2">ğ‘†</ci><ci id="alg1.l10.m1.1.1.3.3a.cmml" xref="alg1.l10.m1.1.1.3.3"><mtext id="alg1.l10.m1.1.1.3.3.cmml" mathsize="50%" xref="alg1.l10.m1.1.1.3.3">max</mtext></ci></apply></apply></apply></apply><ci id="alg1.l10.m1.3.3.2.4.cmml" xref="alg1.l10.m1.3.3.2.4">Î”</ci><ci id="alg1.l10.m1.3.3.2.5.cmml" xref="alg1.l10.m1.3.3.2.5">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.3c">\theta\leftarrow k\cdot S(t-1)\cdot\left(1-\frac{S(t-1)}{S_{\text{max}}}\right%
)\Delta t</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m1.3d">italic_Î¸ â† italic_k â‹… italic_S ( italic_t - 1 ) â‹… ( 1 - divide start_ARG italic_S ( italic_t - 1 ) end_ARG start_ARG italic_S start_POSTSUBSCRIPT max end_POSTSUBSCRIPT end_ARG ) roman_Î” italic_t</annotation></semantics></math>, where <math alttext="\Delta t=1" class="ltx_Math" display="inline" id="alg1.l10.m2.1"><semantics id="alg1.l10.m2.1a"><mrow id="alg1.l10.m2.1.1" xref="alg1.l10.m2.1.1.cmml"><mrow id="alg1.l10.m2.1.1.2" xref="alg1.l10.m2.1.1.2.cmml"><mi id="alg1.l10.m2.1.1.2.2" mathvariant="normal" xref="alg1.l10.m2.1.1.2.2.cmml">Î”</mi><mo id="alg1.l10.m2.1.1.2.1" xref="alg1.l10.m2.1.1.2.1.cmml">â¢</mo><mi id="alg1.l10.m2.1.1.2.3" xref="alg1.l10.m2.1.1.2.3.cmml">t</mi></mrow><mo id="alg1.l10.m2.1.1.1" xref="alg1.l10.m2.1.1.1.cmml">=</mo><mn id="alg1.l10.m2.1.1.3" xref="alg1.l10.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m2.1b"><apply id="alg1.l10.m2.1.1.cmml" xref="alg1.l10.m2.1.1"><eq id="alg1.l10.m2.1.1.1.cmml" xref="alg1.l10.m2.1.1.1"></eq><apply id="alg1.l10.m2.1.1.2.cmml" xref="alg1.l10.m2.1.1.2"><times id="alg1.l10.m2.1.1.2.1.cmml" xref="alg1.l10.m2.1.1.2.1"></times><ci id="alg1.l10.m2.1.1.2.2.cmml" xref="alg1.l10.m2.1.1.2.2">Î”</ci><ci id="alg1.l10.m2.1.1.2.3.cmml" xref="alg1.l10.m2.1.1.2.3">ğ‘¡</ci></apply><cn id="alg1.l10.m2.1.1.3.cmml" type="integer" xref="alg1.l10.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m2.1c">\Delta t=1</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m2.1d">roman_Î” italic_t = 1</annotation></semantics></math> (discretized growth rate)

</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l11.1.1.1" style="font-size:80%;">11:</span></span>Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l11.2">if</span>Â <math alttext="\Delta S(t)&gt;\theta" class="ltx_Math" display="inline" id="alg1.l11.m1.1"><semantics id="alg1.l11.m1.1a"><mrow id="alg1.l11.m1.1.2" xref="alg1.l11.m1.1.2.cmml"><mrow id="alg1.l11.m1.1.2.2" xref="alg1.l11.m1.1.2.2.cmml"><mi id="alg1.l11.m1.1.2.2.2" mathvariant="normal" xref="alg1.l11.m1.1.2.2.2.cmml">Î”</mi><mo id="alg1.l11.m1.1.2.2.1" xref="alg1.l11.m1.1.2.2.1.cmml">â¢</mo><mi id="alg1.l11.m1.1.2.2.3" xref="alg1.l11.m1.1.2.2.3.cmml">S</mi><mo id="alg1.l11.m1.1.2.2.1a" xref="alg1.l11.m1.1.2.2.1.cmml">â¢</mo><mrow id="alg1.l11.m1.1.2.2.4.2" xref="alg1.l11.m1.1.2.2.cmml"><mo id="alg1.l11.m1.1.2.2.4.2.1" stretchy="false" xref="alg1.l11.m1.1.2.2.cmml">(</mo><mi id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml">t</mi><mo id="alg1.l11.m1.1.2.2.4.2.2" stretchy="false" xref="alg1.l11.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="alg1.l11.m1.1.2.1" xref="alg1.l11.m1.1.2.1.cmml">&gt;</mo><mi id="alg1.l11.m1.1.2.3" xref="alg1.l11.m1.1.2.3.cmml">Î¸</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b"><apply id="alg1.l11.m1.1.2.cmml" xref="alg1.l11.m1.1.2"><gt id="alg1.l11.m1.1.2.1.cmml" xref="alg1.l11.m1.1.2.1"></gt><apply id="alg1.l11.m1.1.2.2.cmml" xref="alg1.l11.m1.1.2.2"><times id="alg1.l11.m1.1.2.2.1.cmml" xref="alg1.l11.m1.1.2.2.1"></times><ci id="alg1.l11.m1.1.2.2.2.cmml" xref="alg1.l11.m1.1.2.2.2">Î”</ci><ci id="alg1.l11.m1.1.2.2.3.cmml" xref="alg1.l11.m1.1.2.2.3">ğ‘†</ci><ci id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1">ğ‘¡</ci></apply><ci id="alg1.l11.m1.1.2.3.cmml" xref="alg1.l11.m1.1.2.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.1c">\Delta S(t)&gt;\theta</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m1.1d">roman_Î” italic_S ( italic_t ) &gt; italic_Î¸</annotation></semantics></math>Â <span class="ltx_text ltx_font_bold" id="alg1.l11.3">then</span>
</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l12.1.1.1" style="font-size:80%;">12:</span></span>Â Â Â Â Â Â Â Â Retain updates: <math alttext="M\leftarrow M^{\prime}" class="ltx_Math" display="inline" id="alg1.l12.m1.1"><semantics id="alg1.l12.m1.1a"><mrow id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml"><mi id="alg1.l12.m1.1.1.2" xref="alg1.l12.m1.1.1.2.cmml">M</mi><mo id="alg1.l12.m1.1.1.1" stretchy="false" xref="alg1.l12.m1.1.1.1.cmml">â†</mo><msup id="alg1.l12.m1.1.1.3" xref="alg1.l12.m1.1.1.3.cmml"><mi id="alg1.l12.m1.1.1.3.2" xref="alg1.l12.m1.1.1.3.2.cmml">M</mi><mo id="alg1.l12.m1.1.1.3.3" xref="alg1.l12.m1.1.1.3.3.cmml">â€²</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><apply id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1"><ci id="alg1.l12.m1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1">â†</ci><ci id="alg1.l12.m1.1.1.2.cmml" xref="alg1.l12.m1.1.1.2">ğ‘€</ci><apply id="alg1.l12.m1.1.1.3.cmml" xref="alg1.l12.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.3.1.cmml" xref="alg1.l12.m1.1.1.3">superscript</csymbol><ci id="alg1.l12.m1.1.1.3.2.cmml" xref="alg1.l12.m1.1.1.3.2">ğ‘€</ci><ci id="alg1.l12.m1.1.1.3.3.cmml" xref="alg1.l12.m1.1.1.3.3">â€²</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">M\leftarrow M^{\prime}</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m1.1d">italic_M â† italic_M start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="S(t)\leftarrow S^{\prime}(t)" class="ltx_Math" display="inline" id="alg1.l12.m2.2"><semantics id="alg1.l12.m2.2a"><mrow id="alg1.l12.m2.2.3" xref="alg1.l12.m2.2.3.cmml"><mrow id="alg1.l12.m2.2.3.2" xref="alg1.l12.m2.2.3.2.cmml"><mi id="alg1.l12.m2.2.3.2.2" xref="alg1.l12.m2.2.3.2.2.cmml">S</mi><mo id="alg1.l12.m2.2.3.2.1" xref="alg1.l12.m2.2.3.2.1.cmml">â¢</mo><mrow id="alg1.l12.m2.2.3.2.3.2" xref="alg1.l12.m2.2.3.2.cmml"><mo id="alg1.l12.m2.2.3.2.3.2.1" stretchy="false" xref="alg1.l12.m2.2.3.2.cmml">(</mo><mi id="alg1.l12.m2.1.1" xref="alg1.l12.m2.1.1.cmml">t</mi><mo id="alg1.l12.m2.2.3.2.3.2.2" stretchy="false" xref="alg1.l12.m2.2.3.2.cmml">)</mo></mrow></mrow><mo id="alg1.l12.m2.2.3.1" stretchy="false" xref="alg1.l12.m2.2.3.1.cmml">â†</mo><mrow id="alg1.l12.m2.2.3.3" xref="alg1.l12.m2.2.3.3.cmml"><msup id="alg1.l12.m2.2.3.3.2" xref="alg1.l12.m2.2.3.3.2.cmml"><mi id="alg1.l12.m2.2.3.3.2.2" xref="alg1.l12.m2.2.3.3.2.2.cmml">S</mi><mo id="alg1.l12.m2.2.3.3.2.3" xref="alg1.l12.m2.2.3.3.2.3.cmml">â€²</mo></msup><mo id="alg1.l12.m2.2.3.3.1" xref="alg1.l12.m2.2.3.3.1.cmml">â¢</mo><mrow id="alg1.l12.m2.2.3.3.3.2" xref="alg1.l12.m2.2.3.3.cmml"><mo id="alg1.l12.m2.2.3.3.3.2.1" stretchy="false" xref="alg1.l12.m2.2.3.3.cmml">(</mo><mi id="alg1.l12.m2.2.2" xref="alg1.l12.m2.2.2.cmml">t</mi><mo id="alg1.l12.m2.2.3.3.3.2.2" stretchy="false" xref="alg1.l12.m2.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l12.m2.2b"><apply id="alg1.l12.m2.2.3.cmml" xref="alg1.l12.m2.2.3"><ci id="alg1.l12.m2.2.3.1.cmml" xref="alg1.l12.m2.2.3.1">â†</ci><apply id="alg1.l12.m2.2.3.2.cmml" xref="alg1.l12.m2.2.3.2"><times id="alg1.l12.m2.2.3.2.1.cmml" xref="alg1.l12.m2.2.3.2.1"></times><ci id="alg1.l12.m2.2.3.2.2.cmml" xref="alg1.l12.m2.2.3.2.2">ğ‘†</ci><ci id="alg1.l12.m2.1.1.cmml" xref="alg1.l12.m2.1.1">ğ‘¡</ci></apply><apply id="alg1.l12.m2.2.3.3.cmml" xref="alg1.l12.m2.2.3.3"><times id="alg1.l12.m2.2.3.3.1.cmml" xref="alg1.l12.m2.2.3.3.1"></times><apply id="alg1.l12.m2.2.3.3.2.cmml" xref="alg1.l12.m2.2.3.3.2"><csymbol cd="ambiguous" id="alg1.l12.m2.2.3.3.2.1.cmml" xref="alg1.l12.m2.2.3.3.2">superscript</csymbol><ci id="alg1.l12.m2.2.3.3.2.2.cmml" xref="alg1.l12.m2.2.3.3.2.2">ğ‘†</ci><ci id="alg1.l12.m2.2.3.3.2.3.cmml" xref="alg1.l12.m2.2.3.3.2.3">â€²</ci></apply><ci id="alg1.l12.m2.2.2.cmml" xref="alg1.l12.m2.2.2">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m2.2c">S(t)\leftarrow S^{\prime}(t)</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m2.2d">italic_S ( italic_t ) â† italic_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ( italic_t )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l13">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l13.1.1.1" style="font-size:80%;">13:</span></span>Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l13.2">else</span>
</div>
<div class="ltx_listingline" id="alg1.l14">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l14.1.1.1" style="font-size:80%;">14:</span></span>Â Â Â Â Â Â Â Â Discard updates: Retain original <math alttext="M" class="ltx_Math" display="inline" id="alg1.l14.m1.1"><semantics id="alg1.l14.m1.1a"><mi id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.1b"><ci id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="alg1.l14.m1.1d">italic_M</annotation></semantics></math>, set <math alttext="S(t)\leftarrow S(t-1)" class="ltx_Math" display="inline" id="alg1.l14.m2.2"><semantics id="alg1.l14.m2.2a"><mrow id="alg1.l14.m2.2.2" xref="alg1.l14.m2.2.2.cmml"><mrow id="alg1.l14.m2.2.2.3" xref="alg1.l14.m2.2.2.3.cmml"><mi id="alg1.l14.m2.2.2.3.2" xref="alg1.l14.m2.2.2.3.2.cmml">S</mi><mo id="alg1.l14.m2.2.2.3.1" xref="alg1.l14.m2.2.2.3.1.cmml">â¢</mo><mrow id="alg1.l14.m2.2.2.3.3.2" xref="alg1.l14.m2.2.2.3.cmml"><mo id="alg1.l14.m2.2.2.3.3.2.1" stretchy="false" xref="alg1.l14.m2.2.2.3.cmml">(</mo><mi id="alg1.l14.m2.1.1" xref="alg1.l14.m2.1.1.cmml">t</mi><mo id="alg1.l14.m2.2.2.3.3.2.2" stretchy="false" xref="alg1.l14.m2.2.2.3.cmml">)</mo></mrow></mrow><mo id="alg1.l14.m2.2.2.2" stretchy="false" xref="alg1.l14.m2.2.2.2.cmml">â†</mo><mrow id="alg1.l14.m2.2.2.1" xref="alg1.l14.m2.2.2.1.cmml"><mi id="alg1.l14.m2.2.2.1.3" xref="alg1.l14.m2.2.2.1.3.cmml">S</mi><mo id="alg1.l14.m2.2.2.1.2" xref="alg1.l14.m2.2.2.1.2.cmml">â¢</mo><mrow id="alg1.l14.m2.2.2.1.1.1" xref="alg1.l14.m2.2.2.1.1.1.1.cmml"><mo id="alg1.l14.m2.2.2.1.1.1.2" stretchy="false" xref="alg1.l14.m2.2.2.1.1.1.1.cmml">(</mo><mrow id="alg1.l14.m2.2.2.1.1.1.1" xref="alg1.l14.m2.2.2.1.1.1.1.cmml"><mi id="alg1.l14.m2.2.2.1.1.1.1.2" xref="alg1.l14.m2.2.2.1.1.1.1.2.cmml">t</mi><mo id="alg1.l14.m2.2.2.1.1.1.1.1" xref="alg1.l14.m2.2.2.1.1.1.1.1.cmml">âˆ’</mo><mn id="alg1.l14.m2.2.2.1.1.1.1.3" xref="alg1.l14.m2.2.2.1.1.1.1.3.cmml">1</mn></mrow><mo id="alg1.l14.m2.2.2.1.1.1.3" stretchy="false" xref="alg1.l14.m2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l14.m2.2b"><apply id="alg1.l14.m2.2.2.cmml" xref="alg1.l14.m2.2.2"><ci id="alg1.l14.m2.2.2.2.cmml" xref="alg1.l14.m2.2.2.2">â†</ci><apply id="alg1.l14.m2.2.2.3.cmml" xref="alg1.l14.m2.2.2.3"><times id="alg1.l14.m2.2.2.3.1.cmml" xref="alg1.l14.m2.2.2.3.1"></times><ci id="alg1.l14.m2.2.2.3.2.cmml" xref="alg1.l14.m2.2.2.3.2">ğ‘†</ci><ci id="alg1.l14.m2.1.1.cmml" xref="alg1.l14.m2.1.1">ğ‘¡</ci></apply><apply id="alg1.l14.m2.2.2.1.cmml" xref="alg1.l14.m2.2.2.1"><times id="alg1.l14.m2.2.2.1.2.cmml" xref="alg1.l14.m2.2.2.1.2"></times><ci id="alg1.l14.m2.2.2.1.3.cmml" xref="alg1.l14.m2.2.2.1.3">ğ‘†</ci><apply id="alg1.l14.m2.2.2.1.1.1.1.cmml" xref="alg1.l14.m2.2.2.1.1.1"><minus id="alg1.l14.m2.2.2.1.1.1.1.1.cmml" xref="alg1.l14.m2.2.2.1.1.1.1.1"></minus><ci id="alg1.l14.m2.2.2.1.1.1.1.2.cmml" xref="alg1.l14.m2.2.2.1.1.1.1.2">ğ‘¡</ci><cn id="alg1.l14.m2.2.2.1.1.1.1.3.cmml" type="integer" xref="alg1.l14.m2.2.2.1.1.1.1.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m2.2c">S(t)\leftarrow S(t-1)</annotation><annotation encoding="application/x-llamapun" id="alg1.l14.m2.2d">italic_S ( italic_t ) â† italic_S ( italic_t - 1 )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l15">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l15.1.1.1" style="font-size:80%;">15:</span></span>Â Â Â Â Â <span class="ltx_text ltx_font_bold" id="alg1.l15.2">end</span>Â <span class="ltx_text ltx_font_bold" id="alg1.l15.3">if</span>
</div>
<div class="ltx_listingline" id="alg1.l16">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l16.1.1.1" style="font-size:80%;">16:</span></span>Â Â <span class="ltx_text ltx_font_bold" id="alg1.l16.2">end</span>Â <span class="ltx_text ltx_font_bold" id="alg1.l16.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l17">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l17.1.1.1" style="font-size:80%;">17:</span></span>Â Â <span class="ltx_text ltx_font_bold" id="alg1.l17.2">Return</span> <math alttext="M" class="ltx_Math" display="inline" id="alg1.l17.m1.1"><semantics id="alg1.l17.m1.1a"><mi id="alg1.l17.m1.1.1" xref="alg1.l17.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.1b"><ci id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="alg1.l17.m1.1d">italic_M</annotation></semantics></math>
</div>
</div>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data-Centric AI and Efficient Adaptation: Trends and Benchmarks</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data-Centric AI and Incremental Learning</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Data-centric AI has emerged as a paradigm to improve model performance by optimizing the training data rather than the model architectureÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib27" title="">27</a>]</cite>. Techniques like active learningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib32" title="">32</a>]</cite> and data augmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib33" title="">33</a>]</cite> exemplify this approach, but they often focus on static datasets. In contrast, APE uses iterative perturbations to dynamically adapt the training data, drawing inspiration from incremental learning methods. Unlike curriculum learning (CL), which relies on a predefined progression of example difficultyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib2" title="">2</a>]</cite>, APE perturbs data stochastically based on performance feedback (e.g., BLEU improvement), enabling emergent adaptability without a fixed curriculum. Compared to active learning (AL), which selects data via query strategiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib32" title="">32</a>]</cite>, APE iterates over small, representative batches without requiring an oracle, making it simpler and less resource-intensive. Parameter-efficient methods like LoRAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib16" title="">16</a>]</cite> and adaptersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib15" title="">15</a>]</cite> modify model architecture to reduce compute, whereas APE keeps the architecture fixed and optimizes data exposure, avoiding hyperparameter complexity. This distinction positions APE as a computationally efficient, data-driven alternative, aligning with the trend of data optimization in AIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib23" title="">23</a>]</cite> while offering unique flexibility for resource-constrained settings.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Large Language Models and Adaptation Challenges</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Large language models (LLMs), such as T5Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib31" title="">31</a>]</cite>, BERTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib9" title="">9</a>]</cite>, and GPT-3Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib4" title="">4</a>]</cite>, are pre-trained on large, diverse datasets to achieve generalization across tasks. However, adapting these models to specific domains remains challenging, often requiring extensive fine-tuningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib3" title="">3</a>]</cite> or in-context learningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib4" title="">4</a>]</cite>. Fine-tuning can be computationally expensive, especially for large models, and may lead to catastrophic forgetting, where the model loses generalization abilityÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib26" title="">26</a>]</cite>. Methods like adapter layersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib15" title="">15</a>]</cite> and prompt tuningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib22" title="">22</a>]</cite> have been proposed to reduce the computational burden, but they often require careful hyperparameter tuning and may not generalize across tasksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib16" title="">16</a>]</cite>. Our approach, APE, addresses these challenges by focusing on data-centric perturbations, aligning with the growing emphasis on data optimization in AIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib27" title="">27</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Data-Centric AI and Incremental Learning</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Data-centric AI has emerged as a paradigm to improve model performance by optimizing the training data rather than the model architectureÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib27" title="">27</a>]</cite>. Techniques like active learningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib32" title="">32</a>]</cite> and data augmentationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib33" title="">33</a>]</cite> exemplify this approach, but they often focus on static datasets. In contrast, APE uses iterative perturbations to dynamically adapt the training data, drawing inspiration from incremental learning methods. Continual learning, for instance, aims to adapt models to new tasks over time without forgetting previous knowledgeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib29" title="">29</a>]</cite>, while meta-learning enables rapid adaptation to new tasks through learned optimization strategiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib10" title="">10</a>]</cite>. Curriculum learning, which exposes models to progressively harder examplesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib2" title="">2</a>]</cite>, also shares similarities with APEâ€™s iterative approach. However, APE uniquely combines these ideas with Kauffmanâ€™s adjacent possible, focusing on small, data-driven perturbations to enhance adaptability in LLMs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">Our work emphasizes data-centric methods, aligning with the current trend of data optimization in AI, as seen in projects like DataCompÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib23" title="">23</a>]</cite> and recent advances in data curation for LLMsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib8" title="">8</a>]</cite>. We aim to address the modern challenge of efficient adaptation in resource-constrained settingsâ€”a persistent issue despite methods like LoRAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib16" title="">16</a>]</cite> and DPOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib30" title="">30</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Setup</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The APE method implementation consists of the following steps:</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">1. <span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Baseline</span>: Start with a pre-trained model (T5-base model) and evaluate its unperturbed performance on news summarization by using metrics like BLEU, ROUGE-1, BERTScore, and perplexity on a held-out test set.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">2. <span class="ltx_text ltx_font_bold" id="S4.p3.1.1">Perturbation</span>: Fine-tune the model on a small subset of news articles (e.g., 200 articles) for 3 epochs, using a fixed learning rate (<math alttext="lr=3.10^{-6}" class="ltx_Math" display="inline" id="S4.p3.1.m1.1"><semantics id="S4.p3.1.m1.1a"><mrow id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml"><mrow id="S4.p3.1.m1.1.1.2" xref="S4.p3.1.m1.1.1.2.cmml"><mi id="S4.p3.1.m1.1.1.2.2" xref="S4.p3.1.m1.1.1.2.2.cmml">l</mi><mo id="S4.p3.1.m1.1.1.2.1" xref="S4.p3.1.m1.1.1.2.1.cmml">â¢</mo><mi id="S4.p3.1.m1.1.1.2.3" xref="S4.p3.1.m1.1.1.2.3.cmml">r</mi></mrow><mo id="S4.p3.1.m1.1.1.1" xref="S4.p3.1.m1.1.1.1.cmml">=</mo><msup id="S4.p3.1.m1.1.1.3" xref="S4.p3.1.m1.1.1.3.cmml"><mn id="S4.p3.1.m1.1.1.3.2" xref="S4.p3.1.m1.1.1.3.2.cmml">3.10</mn><mrow id="S4.p3.1.m1.1.1.3.3" xref="S4.p3.1.m1.1.1.3.3.cmml"><mo id="S4.p3.1.m1.1.1.3.3a" xref="S4.p3.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S4.p3.1.m1.1.1.3.3.2" xref="S4.p3.1.m1.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><apply id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1"><eq id="S4.p3.1.m1.1.1.1.cmml" xref="S4.p3.1.m1.1.1.1"></eq><apply id="S4.p3.1.m1.1.1.2.cmml" xref="S4.p3.1.m1.1.1.2"><times id="S4.p3.1.m1.1.1.2.1.cmml" xref="S4.p3.1.m1.1.1.2.1"></times><ci id="S4.p3.1.m1.1.1.2.2.cmml" xref="S4.p3.1.m1.1.1.2.2">ğ‘™</ci><ci id="S4.p3.1.m1.1.1.2.3.cmml" xref="S4.p3.1.m1.1.1.2.3">ğ‘Ÿ</ci></apply><apply id="S4.p3.1.m1.1.1.3.cmml" xref="S4.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.p3.1.m1.1.1.3.1.cmml" xref="S4.p3.1.m1.1.1.3">superscript</csymbol><cn id="S4.p3.1.m1.1.1.3.2.cmml" type="float" xref="S4.p3.1.m1.1.1.3.2">3.10</cn><apply id="S4.p3.1.m1.1.1.3.3.cmml" xref="S4.p3.1.m1.1.1.3.3"><minus id="S4.p3.1.m1.1.1.3.3.1.cmml" xref="S4.p3.1.m1.1.1.3.3"></minus><cn id="S4.p3.1.m1.1.1.3.3.2.cmml" type="integer" xref="S4.p3.1.m1.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">lr=3.10^{-6}</annotation><annotation encoding="application/x-llamapun" id="S4.p3.1.m1.1d">italic_l italic_r = 3.10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT</annotation></semantics></math>). This perturbation defines the "adjacent" step as a minimal change in the training data. We use the same learning rate for reproducibility.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">3. <span class="ltx_text ltx_font_bold" id="S4.p4.1.1">Evaluation</span>: Test the perturbed model on the held-out set. Retain the changes if BLEU improves by at least <math alttext="2.0\%" class="ltx_Math" display="inline" id="S4.p4.1.m1.1"><semantics id="S4.p4.1.m1.1a"><mrow id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml"><mn id="S4.p4.1.m1.1.1.2" xref="S4.p4.1.m1.1.1.2.cmml">2.0</mn><mo id="S4.p4.1.m1.1.1.1" xref="S4.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><apply id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1"><csymbol cd="latexml" id="S4.p4.1.m1.1.1.1.cmml" xref="S4.p4.1.m1.1.1.1">percent</csymbol><cn id="S4.p4.1.m1.1.1.2.cmml" type="float" xref="S4.p4.1.m1.1.1.2">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">2.0\%</annotation><annotation encoding="application/x-llamapun" id="S4.p4.1.m1.1d">2.0 %</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">4. <span class="ltx_text ltx_font_bold" id="S4.p5.1.1">Iteration</span>: Repeat the perturbation and evaluation for multiple cycles, varying the subset of articles while keeping the learning rate fixed.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p6">
<p class="ltx_p" id="S4.p6.1">To support qualitative analysis within computational constraints, we also conduct a scaled-down experiment. This allows us to generate summaries for qualitative comparison and human evaluation, complementing the quantitative trends from the full experiment.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset, Model, and Computational Constraints</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We evaluate APE on the CNN/DailyMail dataset (v3.0.0), a widely used benchmark for news summarizationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib13" title="">13</a>]</cite>. This dataset contains news articles paired with human-written summaries, making it suitable for evaluating abstractive summarization models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">We used T5-base model with 220M parameters, pre-trained on the C4 corpusÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib31" title="">31</a>]</cite>, loaded in FP32 with mixed precision training to optimize memory usage. The full experiment involves 4,000 training samples and 1,000 test samples from the CNN/DailyMail dataset. For the scaled-down experiment, due to computational constraints and the unavailability of the original final model, we used 1,200 training samples and 300 test samples, focusing on qualitative analysis and human evaluation. The experiments are conducted on a Google Colab T4 GPU (16 GB VRAM, 7.5 TFLOPS), reflecting resource-constrained settings.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Perturbations</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2">In the full experiment, we perform 17 iterations of perturbations, each fine-tuning on 200 articles (epochs=3, learning rate <math alttext="lr=3.10^{-6}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mrow id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2.2" xref="S4.SS2.p1.1.m1.1.1.2.2.cmml">l</mi><mo id="S4.SS2.p1.1.m1.1.1.2.1" xref="S4.SS2.p1.1.m1.1.1.2.1.cmml">â¢</mo><mi id="S4.SS2.p1.1.m1.1.1.2.3" xref="S4.SS2.p1.1.m1.1.1.2.3.cmml">r</mi></mrow><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">=</mo><msup id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml"><mn id="S4.SS2.p1.1.m1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.3.2.cmml">3.10</mn><mrow id="S4.SS2.p1.1.m1.1.1.3.3" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml"><mo id="S4.SS2.p1.1.m1.1.1.3.3a" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p1.1.m1.1.1.3.3.2" xref="S4.SS2.p1.1.m1.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><eq id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></eq><apply id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2"><times id="S4.SS2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.2.1"></times><ci id="S4.SS2.p1.1.m1.1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2">ğ‘™</ci><ci id="S4.SS2.p1.1.m1.1.1.2.3.cmml" xref="S4.SS2.p1.1.m1.1.1.2.3">ğ‘Ÿ</ci></apply><apply id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3">superscript</csymbol><cn id="S4.SS2.p1.1.m1.1.1.3.2.cmml" type="float" xref="S4.SS2.p1.1.m1.1.1.3.2">3.10</cn><apply id="S4.SS2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3"><minus id="S4.SS2.p1.1.m1.1.1.3.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3"></minus><cn id="S4.SS2.p1.1.m1.1.1.3.3.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">lr=3.10^{-6}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">italic_l italic_r = 3.10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT</annotation></semantics></math>, gradient accumulation steps=4). The scaled-down experiment uses 15 iterations, each fine-tuning on 80 articles (epochs=3, <math alttext="lr=3.10^{-6}" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mrow id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2.2" xref="S4.SS2.p1.2.m2.1.1.2.2.cmml">l</mi><mo id="S4.SS2.p1.2.m2.1.1.2.1" xref="S4.SS2.p1.2.m2.1.1.2.1.cmml">â¢</mo><mi id="S4.SS2.p1.2.m2.1.1.2.3" xref="S4.SS2.p1.2.m2.1.1.2.3.cmml">r</mi></mrow><mo id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">=</mo><msup id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml"><mn id="S4.SS2.p1.2.m2.1.1.3.2" xref="S4.SS2.p1.2.m2.1.1.3.2.cmml">3.10</mn><mrow id="S4.SS2.p1.2.m2.1.1.3.3" xref="S4.SS2.p1.2.m2.1.1.3.3.cmml"><mo id="S4.SS2.p1.2.m2.1.1.3.3a" xref="S4.SS2.p1.2.m2.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p1.2.m2.1.1.3.3.2" xref="S4.SS2.p1.2.m2.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><eq id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></eq><apply id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2"><times id="S4.SS2.p1.2.m2.1.1.2.1.cmml" xref="S4.SS2.p1.2.m2.1.1.2.1"></times><ci id="S4.SS2.p1.2.m2.1.1.2.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2">ğ‘™</ci><ci id="S4.SS2.p1.2.m2.1.1.2.3.cmml" xref="S4.SS2.p1.2.m2.1.1.2.3">ğ‘Ÿ</ci></apply><apply id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.3.1.cmml" xref="S4.SS2.p1.2.m2.1.1.3">superscript</csymbol><cn id="S4.SS2.p1.2.m2.1.1.3.2.cmml" type="float" xref="S4.SS2.p1.2.m2.1.1.3.2">3.10</cn><apply id="S4.SS2.p1.2.m2.1.1.3.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3.3"><minus id="S4.SS2.p1.2.m2.1.1.3.3.1.cmml" xref="S4.SS2.p1.2.m2.1.1.3.3"></minus><cn id="S4.SS2.p1.2.m2.1.1.3.3.2.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">lr=3.10^{-6}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_l italic_r = 3.10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT</annotation></semantics></math>, gradient accumulation steps=4), totaling approximately 60 minutes of runtime. The baseline model (pre-trained T5-base) and final model (after 15 iterations) are saved for reproducibility.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.4">To explore the TAP formalismâ€™s practical impact, we conducted an ablation study on perturbation size <math alttext="\Delta D" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><mrow id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" mathvariant="normal" xref="S4.SS2.p2.1.m1.1.1.2.cmml">Î”</mi><mo id="S4.SS2.p2.1.m1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.cmml">â¢</mo><mi id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><times id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1"></times><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">Î”</ci><ci id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\Delta D</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">roman_Î” italic_D</annotation></semantics></math>. Using the scaled-down setup (1200 training samples), we tested <math alttext="\Delta D=80" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m2.1"><semantics id="S4.SS2.p2.2.m2.1a"><mrow id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mrow id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2.2" mathvariant="normal" xref="S4.SS2.p2.2.m2.1.1.2.2.cmml">Î”</mi><mo id="S4.SS2.p2.2.m2.1.1.2.1" xref="S4.SS2.p2.2.m2.1.1.2.1.cmml">â¢</mo><mi id="S4.SS2.p2.2.m2.1.1.2.3" xref="S4.SS2.p2.2.m2.1.1.2.3.cmml">D</mi></mrow><mo id="S4.SS2.p2.2.m2.1.1.1" xref="S4.SS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">80</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><eq id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1.1"></eq><apply id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2"><times id="S4.SS2.p2.2.m2.1.1.2.1.cmml" xref="S4.SS2.p2.2.m2.1.1.2.1"></times><ci id="S4.SS2.p2.2.m2.1.1.2.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2.2">Î”</ci><ci id="S4.SS2.p2.2.m2.1.1.2.3.cmml" xref="S4.SS2.p2.2.m2.1.1.2.3">ğ·</ci></apply><cn id="S4.SS2.p2.2.m2.1.1.3.cmml" type="integer" xref="S4.SS2.p2.2.m2.1.1.3">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">\Delta D=80</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.2.m2.1d">roman_Î” italic_D = 80</annotation></semantics></math>, 200, and 400 articles per iteration (epochs=3, <math alttext="lr=3.10^{-6}" class="ltx_Math" display="inline" id="S4.SS2.p2.3.m3.1"><semantics id="S4.SS2.p2.3.m3.1a"><mrow id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml"><mrow id="S4.SS2.p2.3.m3.1.1.2" xref="S4.SS2.p2.3.m3.1.1.2.cmml"><mi id="S4.SS2.p2.3.m3.1.1.2.2" xref="S4.SS2.p2.3.m3.1.1.2.2.cmml">l</mi><mo id="S4.SS2.p2.3.m3.1.1.2.1" xref="S4.SS2.p2.3.m3.1.1.2.1.cmml">â¢</mo><mi id="S4.SS2.p2.3.m3.1.1.2.3" xref="S4.SS2.p2.3.m3.1.1.2.3.cmml">r</mi></mrow><mo id="S4.SS2.p2.3.m3.1.1.1" xref="S4.SS2.p2.3.m3.1.1.1.cmml">=</mo><msup id="S4.SS2.p2.3.m3.1.1.3" xref="S4.SS2.p2.3.m3.1.1.3.cmml"><mn id="S4.SS2.p2.3.m3.1.1.3.2" xref="S4.SS2.p2.3.m3.1.1.3.2.cmml">3.10</mn><mrow id="S4.SS2.p2.3.m3.1.1.3.3" xref="S4.SS2.p2.3.m3.1.1.3.3.cmml"><mo id="S4.SS2.p2.3.m3.1.1.3.3a" xref="S4.SS2.p2.3.m3.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p2.3.m3.1.1.3.3.2" xref="S4.SS2.p2.3.m3.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><apply id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1"><eq id="S4.SS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1"></eq><apply id="S4.SS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2"><times id="S4.SS2.p2.3.m3.1.1.2.1.cmml" xref="S4.SS2.p2.3.m3.1.1.2.1"></times><ci id="S4.SS2.p2.3.m3.1.1.2.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2.2">ğ‘™</ci><ci id="S4.SS2.p2.3.m3.1.1.2.3.cmml" xref="S4.SS2.p2.3.m3.1.1.2.3">ğ‘Ÿ</ci></apply><apply id="S4.SS2.p2.3.m3.1.1.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p2.3.m3.1.1.3.1.cmml" xref="S4.SS2.p2.3.m3.1.1.3">superscript</csymbol><cn id="S4.SS2.p2.3.m3.1.1.3.2.cmml" type="float" xref="S4.SS2.p2.3.m3.1.1.3.2">3.10</cn><apply id="S4.SS2.p2.3.m3.1.1.3.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3.3"><minus id="S4.SS2.p2.3.m3.1.1.3.3.1.cmml" xref="S4.SS2.p2.3.m3.1.1.3.3"></minus><cn id="S4.SS2.p2.3.m3.1.1.3.3.2.cmml" type="integer" xref="S4.SS2.p2.3.m3.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">lr=3.10^{-6}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.3.m3.1d">italic_l italic_r = 3.10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT</annotation></semantics></math>, gradient accumulation steps=4), totaling 15 iterations each. This assesses how perturbation magnitude affects performance, grounding TAP in empirical terms. To enhance factual accuracy, we introduced label smoothing (<math alttext="\epsilon=0.1" class="ltx_Math" display="inline" id="S4.SS2.p2.4.m4.1"><semantics id="S4.SS2.p2.4.m4.1a"><mrow id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml"><mi id="S4.SS2.p2.4.m4.1.1.2" xref="S4.SS2.p2.4.m4.1.1.2.cmml">Ïµ</mi><mo id="S4.SS2.p2.4.m4.1.1.1" xref="S4.SS2.p2.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS2.p2.4.m4.1.1.3" xref="S4.SS2.p2.4.m4.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><apply id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"><eq id="S4.SS2.p2.4.m4.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1.1"></eq><ci id="S4.SS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2">italic-Ïµ</ci><cn id="S4.SS2.p2.4.m4.1.1.3.cmml" type="float" xref="S4.SS2.p2.4.m4.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">\epsilon=0.1</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.4.m4.1d">italic_Ïµ = 0.1</annotation></semantics></math>) during fine-tuning, a computationally efficient regularization technique to reduce overconfidenceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib12" title="">12</a>]</cite>, feasible within our T4 GPU constraints (16 GB VRAM, 7.5 TFLOPS). Results are reported in Section 5.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Evaluation Metrics</h3>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Performance is evaluated using standard metrics for summarization. We use BLEU (with smoothing)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib28" title="">28</a>]</cite> for n-gram overlap, ROUGE-1Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib24" title="">24</a>]</cite> for unigram overlap, BERTScoreÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib38" title="">38</a>]</cite> for semantic similarity, and PerplexityÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib17" title="">17</a>]</cite> for fluency.
For the full experiment, metrics are computed on the 1,000 test samples, with standard deviations calculated via NumPy. For the scaled-down experiment, we perform qualitative analysis on 100 test articles and conduct human evaluation with 7 specialists, whose ratings are reported.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiment Results</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Quantitative Results (Full Experiment)</h3>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">The full experiment (4,000 training samples, 1,000 test samples, 17 iterations) validates APEâ€™s effectiveness in enhancing T5-baseâ€™s adaptability. Results are shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T1" title="Table 1 â€£ 5.1 Quantitative Results (Full Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">1</span></a> and FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.F2" title="Figure 2 â€£ 5.1 Quantitative Results (Full Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Quantitative results for the full experiment (4,000 training samples, 17 iterations). Metrics are reported with 1-sigma standard deviations, and percentage improvements are calculated relative to the baseline.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T1.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T1.8.9.1.1"><span class="ltx_text ltx_font_bold" id="S5.T1.8.9.1.1.1">Metric</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T1.8.9.1.2"><span class="ltx_text ltx_font_bold" id="S5.T1.8.9.1.2.1">Baseline</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T1.8.9.1.3"><span class="ltx_text ltx_font_bold" id="S5.T1.8.9.1.3.1">Final (17 Iterations)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T1.8.9.1.4"><span class="ltx_text ltx_font_bold" id="S5.T1.8.9.1.4.1">Improvement (%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.2.2.3">BLEU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.1.1"><math alttext="0.062\pm 0.083" class="ltx_Math" display="inline" id="S5.T1.1.1.1.m1.1"><semantics id="S5.T1.1.1.1.m1.1a"><mrow id="S5.T1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.m1.1.1.cmml"><mn id="S5.T1.1.1.1.m1.1.1.2" xref="S5.T1.1.1.1.m1.1.1.2.cmml">0.062</mn><mo id="S5.T1.1.1.1.m1.1.1.1" xref="S5.T1.1.1.1.m1.1.1.1.cmml">Â±</mo><mn id="S5.T1.1.1.1.m1.1.1.3" xref="S5.T1.1.1.1.m1.1.1.3.cmml">0.083</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.m1.1b"><apply id="S5.T1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.1.1.1.m1.1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S5.T1.1.1.1.m1.1.1.2.cmml" type="float" xref="S5.T1.1.1.1.m1.1.1.2">0.062</cn><cn id="S5.T1.1.1.1.m1.1.1.3.cmml" type="float" xref="S5.T1.1.1.1.m1.1.1.3">0.083</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.m1.1c">0.062\pm 0.083</annotation><annotation encoding="application/x-llamapun" id="S5.T1.1.1.1.m1.1d">0.062 Â± 0.083</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.2.2.2"><math alttext="0.083\pm 0.100" class="ltx_Math" display="inline" id="S5.T1.2.2.2.m1.1"><semantics id="S5.T1.2.2.2.m1.1a"><mrow id="S5.T1.2.2.2.m1.1.1" xref="S5.T1.2.2.2.m1.1.1.cmml"><mn id="S5.T1.2.2.2.m1.1.1.2" xref="S5.T1.2.2.2.m1.1.1.2.cmml">0.083</mn><mo id="S5.T1.2.2.2.m1.1.1.1" xref="S5.T1.2.2.2.m1.1.1.1.cmml">Â±</mo><mn id="S5.T1.2.2.2.m1.1.1.3" xref="S5.T1.2.2.2.m1.1.1.3.cmml">0.100</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.2.m1.1b"><apply id="S5.T1.2.2.2.m1.1.1.cmml" xref="S5.T1.2.2.2.m1.1.1"><csymbol cd="latexml" id="S5.T1.2.2.2.m1.1.1.1.cmml" xref="S5.T1.2.2.2.m1.1.1.1">plus-or-minus</csymbol><cn id="S5.T1.2.2.2.m1.1.1.2.cmml" type="float" xref="S5.T1.2.2.2.m1.1.1.2">0.083</cn><cn id="S5.T1.2.2.2.m1.1.1.3.cmml" type="float" xref="S5.T1.2.2.2.m1.1.1.3">0.100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.2.m1.1c">0.083\pm 0.100</annotation><annotation encoding="application/x-llamapun" id="S5.T1.2.2.2.m1.1d">0.083 Â± 0.100</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.2.2.4">33.9</td>
</tr>
<tr class="ltx_tr" id="S5.T1.4.4">
<td class="ltx_td ltx_align_left" id="S5.T1.4.4.3">ROUGE-1</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.3.1"><math alttext="0.290\pm 0.121" class="ltx_Math" display="inline" id="S5.T1.3.3.1.m1.1"><semantics id="S5.T1.3.3.1.m1.1a"><mrow id="S5.T1.3.3.1.m1.1.1" xref="S5.T1.3.3.1.m1.1.1.cmml"><mn id="S5.T1.3.3.1.m1.1.1.2" xref="S5.T1.3.3.1.m1.1.1.2.cmml">0.290</mn><mo id="S5.T1.3.3.1.m1.1.1.1" xref="S5.T1.3.3.1.m1.1.1.1.cmml">Â±</mo><mn id="S5.T1.3.3.1.m1.1.1.3" xref="S5.T1.3.3.1.m1.1.1.3.cmml">0.121</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.1.m1.1b"><apply id="S5.T1.3.3.1.m1.1.1.cmml" xref="S5.T1.3.3.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.3.3.1.m1.1.1.1.cmml" xref="S5.T1.3.3.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S5.T1.3.3.1.m1.1.1.2.cmml" type="float" xref="S5.T1.3.3.1.m1.1.1.2">0.290</cn><cn id="S5.T1.3.3.1.m1.1.1.3.cmml" type="float" xref="S5.T1.3.3.1.m1.1.1.3">0.121</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.1.m1.1c">0.290\pm 0.121</annotation><annotation encoding="application/x-llamapun" id="S5.T1.3.3.1.m1.1d">0.290 Â± 0.121</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T1.4.4.2"><math alttext="0.329\pm 0.128" class="ltx_Math" display="inline" id="S5.T1.4.4.2.m1.1"><semantics id="S5.T1.4.4.2.m1.1a"><mrow id="S5.T1.4.4.2.m1.1.1" xref="S5.T1.4.4.2.m1.1.1.cmml"><mn id="S5.T1.4.4.2.m1.1.1.2" xref="S5.T1.4.4.2.m1.1.1.2.cmml">0.329</mn><mo id="S5.T1.4.4.2.m1.1.1.1" xref="S5.T1.4.4.2.m1.1.1.1.cmml">Â±</mo><mn id="S5.T1.4.4.2.m1.1.1.3" xref="S5.T1.4.4.2.m1.1.1.3.cmml">0.128</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.2.m1.1b"><apply id="S5.T1.4.4.2.m1.1.1.cmml" xref="S5.T1.4.4.2.m1.1.1"><csymbol cd="latexml" id="S5.T1.4.4.2.m1.1.1.1.cmml" xref="S5.T1.4.4.2.m1.1.1.1">plus-or-minus</csymbol><cn id="S5.T1.4.4.2.m1.1.1.2.cmml" type="float" xref="S5.T1.4.4.2.m1.1.1.2">0.329</cn><cn id="S5.T1.4.4.2.m1.1.1.3.cmml" type="float" xref="S5.T1.4.4.2.m1.1.1.3">0.128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.2.m1.1c">0.329\pm 0.128</annotation><annotation encoding="application/x-llamapun" id="S5.T1.4.4.2.m1.1d">0.329 Â± 0.128</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T1.4.4.4">13.4</td>
</tr>
<tr class="ltx_tr" id="S5.T1.6.6">
<td class="ltx_td ltx_align_left" id="S5.T1.6.6.3">BERTScore</td>
<td class="ltx_td ltx_align_center" id="S5.T1.5.5.1"><math alttext="0.343\pm 0.142" class="ltx_Math" display="inline" id="S5.T1.5.5.1.m1.1"><semantics id="S5.T1.5.5.1.m1.1a"><mrow id="S5.T1.5.5.1.m1.1.1" xref="S5.T1.5.5.1.m1.1.1.cmml"><mn id="S5.T1.5.5.1.m1.1.1.2" xref="S5.T1.5.5.1.m1.1.1.2.cmml">0.343</mn><mo id="S5.T1.5.5.1.m1.1.1.1" xref="S5.T1.5.5.1.m1.1.1.1.cmml">Â±</mo><mn id="S5.T1.5.5.1.m1.1.1.3" xref="S5.T1.5.5.1.m1.1.1.3.cmml">0.142</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.1.m1.1b"><apply id="S5.T1.5.5.1.m1.1.1.cmml" xref="S5.T1.5.5.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.5.5.1.m1.1.1.1.cmml" xref="S5.T1.5.5.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S5.T1.5.5.1.m1.1.1.2.cmml" type="float" xref="S5.T1.5.5.1.m1.1.1.2">0.343</cn><cn id="S5.T1.5.5.1.m1.1.1.3.cmml" type="float" xref="S5.T1.5.5.1.m1.1.1.3">0.142</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.1.m1.1c">0.343\pm 0.142</annotation><annotation encoding="application/x-llamapun" id="S5.T1.5.5.1.m1.1d">0.343 Â± 0.142</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T1.6.6.2"><math alttext="0.398\pm 0.135" class="ltx_Math" display="inline" id="S5.T1.6.6.2.m1.1"><semantics id="S5.T1.6.6.2.m1.1a"><mrow id="S5.T1.6.6.2.m1.1.1" xref="S5.T1.6.6.2.m1.1.1.cmml"><mn id="S5.T1.6.6.2.m1.1.1.2" xref="S5.T1.6.6.2.m1.1.1.2.cmml">0.398</mn><mo id="S5.T1.6.6.2.m1.1.1.1" xref="S5.T1.6.6.2.m1.1.1.1.cmml">Â±</mo><mn id="S5.T1.6.6.2.m1.1.1.3" xref="S5.T1.6.6.2.m1.1.1.3.cmml">0.135</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.2.m1.1b"><apply id="S5.T1.6.6.2.m1.1.1.cmml" xref="S5.T1.6.6.2.m1.1.1"><csymbol cd="latexml" id="S5.T1.6.6.2.m1.1.1.1.cmml" xref="S5.T1.6.6.2.m1.1.1.1">plus-or-minus</csymbol><cn id="S5.T1.6.6.2.m1.1.1.2.cmml" type="float" xref="S5.T1.6.6.2.m1.1.1.2">0.398</cn><cn id="S5.T1.6.6.2.m1.1.1.3.cmml" type="float" xref="S5.T1.6.6.2.m1.1.1.3">0.135</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.2.m1.1c">0.398\pm 0.135</annotation><annotation encoding="application/x-llamapun" id="S5.T1.6.6.2.m1.1d">0.398 Â± 0.135</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T1.6.6.4">16.0</td>
</tr>
<tr class="ltx_tr" id="S5.T1.8.8">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.8.8.3">Perplexity</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.7.7.1"><math alttext="13.0\pm 12.0" class="ltx_Math" display="inline" id="S5.T1.7.7.1.m1.1"><semantics id="S5.T1.7.7.1.m1.1a"><mrow id="S5.T1.7.7.1.m1.1.1" xref="S5.T1.7.7.1.m1.1.1.cmml"><mn id="S5.T1.7.7.1.m1.1.1.2" xref="S5.T1.7.7.1.m1.1.1.2.cmml">13.0</mn><mo id="S5.T1.7.7.1.m1.1.1.1" xref="S5.T1.7.7.1.m1.1.1.1.cmml">Â±</mo><mn id="S5.T1.7.7.1.m1.1.1.3" xref="S5.T1.7.7.1.m1.1.1.3.cmml">12.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.7.7.1.m1.1b"><apply id="S5.T1.7.7.1.m1.1.1.cmml" xref="S5.T1.7.7.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.7.7.1.m1.1.1.1.cmml" xref="S5.T1.7.7.1.m1.1.1.1">plus-or-minus</csymbol><cn id="S5.T1.7.7.1.m1.1.1.2.cmml" type="float" xref="S5.T1.7.7.1.m1.1.1.2">13.0</cn><cn id="S5.T1.7.7.1.m1.1.1.3.cmml" type="float" xref="S5.T1.7.7.1.m1.1.1.3">12.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.7.1.m1.1c">13.0\pm 12.0</annotation><annotation encoding="application/x-llamapun" id="S5.T1.7.7.1.m1.1d">13.0 Â± 12.0</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.8.8.2"><math alttext="8.3\pm 7.3" class="ltx_Math" display="inline" id="S5.T1.8.8.2.m1.1"><semantics id="S5.T1.8.8.2.m1.1a"><mrow id="S5.T1.8.8.2.m1.1.1" xref="S5.T1.8.8.2.m1.1.1.cmml"><mn id="S5.T1.8.8.2.m1.1.1.2" xref="S5.T1.8.8.2.m1.1.1.2.cmml">8.3</mn><mo id="S5.T1.8.8.2.m1.1.1.1" xref="S5.T1.8.8.2.m1.1.1.1.cmml">Â±</mo><mn id="S5.T1.8.8.2.m1.1.1.3" xref="S5.T1.8.8.2.m1.1.1.3.cmml">7.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.8.8.2.m1.1b"><apply id="S5.T1.8.8.2.m1.1.1.cmml" xref="S5.T1.8.8.2.m1.1.1"><csymbol cd="latexml" id="S5.T1.8.8.2.m1.1.1.1.cmml" xref="S5.T1.8.8.2.m1.1.1.1">plus-or-minus</csymbol><cn id="S5.T1.8.8.2.m1.1.1.2.cmml" type="float" xref="S5.T1.8.8.2.m1.1.1.2">8.3</cn><cn id="S5.T1.8.8.2.m1.1.1.3.cmml" type="float" xref="S5.T1.8.8.2.m1.1.1.3">7.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.8.8.2.m1.1c">8.3\pm 7.3</annotation><annotation encoding="application/x-llamapun" id="S5.T1.8.8.2.m1.1d">8.3 Â± 7.3</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.8.8.4">36.2 (reduction)</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="395" id="S5.F2.g1" src="x1.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Performance trends for the full experiment (4,000 training samples, 17 iterations with a fixed learning rate <math alttext="lr=3.10^{-6}" class="ltx_Math" display="inline" id="S5.F2.2.m1.1"><semantics id="S5.F2.2.m1.1b"><mrow id="S5.F2.2.m1.1.1" xref="S5.F2.2.m1.1.1.cmml"><mrow id="S5.F2.2.m1.1.1.2" xref="S5.F2.2.m1.1.1.2.cmml"><mi id="S5.F2.2.m1.1.1.2.2" xref="S5.F2.2.m1.1.1.2.2.cmml">l</mi><mo id="S5.F2.2.m1.1.1.2.1" xref="S5.F2.2.m1.1.1.2.1.cmml">â¢</mo><mi id="S5.F2.2.m1.1.1.2.3" xref="S5.F2.2.m1.1.1.2.3.cmml">r</mi></mrow><mo id="S5.F2.2.m1.1.1.1" xref="S5.F2.2.m1.1.1.1.cmml">=</mo><msup id="S5.F2.2.m1.1.1.3" xref="S5.F2.2.m1.1.1.3.cmml"><mn id="S5.F2.2.m1.1.1.3.2" xref="S5.F2.2.m1.1.1.3.2.cmml">3.10</mn><mrow id="S5.F2.2.m1.1.1.3.3" xref="S5.F2.2.m1.1.1.3.3.cmml"><mo id="S5.F2.2.m1.1.1.3.3b" xref="S5.F2.2.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S5.F2.2.m1.1.1.3.3.2" xref="S5.F2.2.m1.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.F2.2.m1.1c"><apply id="S5.F2.2.m1.1.1.cmml" xref="S5.F2.2.m1.1.1"><eq id="S5.F2.2.m1.1.1.1.cmml" xref="S5.F2.2.m1.1.1.1"></eq><apply id="S5.F2.2.m1.1.1.2.cmml" xref="S5.F2.2.m1.1.1.2"><times id="S5.F2.2.m1.1.1.2.1.cmml" xref="S5.F2.2.m1.1.1.2.1"></times><ci id="S5.F2.2.m1.1.1.2.2.cmml" xref="S5.F2.2.m1.1.1.2.2">ğ‘™</ci><ci id="S5.F2.2.m1.1.1.2.3.cmml" xref="S5.F2.2.m1.1.1.2.3">ğ‘Ÿ</ci></apply><apply id="S5.F2.2.m1.1.1.3.cmml" xref="S5.F2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S5.F2.2.m1.1.1.3.1.cmml" xref="S5.F2.2.m1.1.1.3">superscript</csymbol><cn id="S5.F2.2.m1.1.1.3.2.cmml" type="float" xref="S5.F2.2.m1.1.1.3.2">3.10</cn><apply id="S5.F2.2.m1.1.1.3.3.cmml" xref="S5.F2.2.m1.1.1.3.3"><minus id="S5.F2.2.m1.1.1.3.3.1.cmml" xref="S5.F2.2.m1.1.1.3.3"></minus><cn id="S5.F2.2.m1.1.1.3.3.2.cmml" type="integer" xref="S5.F2.2.m1.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F2.2.m1.1d">lr=3.10^{-6}</annotation><annotation encoding="application/x-llamapun" id="S5.F2.2.m1.1e">italic_l italic_r = 3.10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT</annotation></semantics></math>). The plot shows BLEU, ROUGE-1, BERTScore, and perplexity values over iterations, with values normalized to a 0â€“1 scale using min-max normalization for each metric across iterations, illustrating the improvement achieved through APE.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">The full experiment (4,000 training samples, 1,000 test samples, 17 iterations) validates APEâ€™s effectiveness in enhancing T5-baseâ€™s adaptability. Results are shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T1" title="Table 1 â€£ 5.1 Quantitative Results (Full Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">1</span></a> and FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.F2" title="Figure 2 â€£ 5.1 Quantitative Results (Full Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">2</span></a>. To contextualize APEâ€™s contribution, TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T2" title="Table 2 â€£ 5.1 Quantitative Results (Full Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">2</span></a> compares its performance to estimated baselines for curriculum learning (CL), a training strategy that trains a machine learning model with a curriculum, active learning (AL), LoRA, and adapters, derived from literature trends and our baseline T5-base results. The CL estimates are derived based on moderate gains over the baseline, as reported in recent surveys on curriculum learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib2" title="">2</a>]</cite>. Similarly, the AL estimates are based on typical performance improvements in NLP tasks, such as 5â€“10% accuracy gains in text classification, as reported in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib32" title="">32</a>]</cite>. The LoRA estimates are derived from performance within 1â€“2% of full fine-tuning in NLG tasks (e.g., 0.6â€“1.0% BLEU drop on E2E NLG) with only 0.3M parameters tuned (0.14% of T5-baseâ€™s 220M), as reported in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib16" title="">16</a>]</cite>, compared to adaptersâ€™ 2â€“4% parameter increase in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib15" title="">15</a>]</cite>. APEâ€™s data-centric focus yields competitive gains without architectural changes, highlighting its efficiency.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of APE to baselines (Full Experiment, 4,000 samples, 17 iterations). CL/AL estimates are based on moderate gains over the baseline <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib32" title="">32</a>]</cite>; specifically, CL improvements (e.g., 12.9% in BLEU, 5.2% in ROUGE-1) are derived from typical gains in NLP tasks like NMT (up to 2.2 BLEU points, 7â€“11% relative improvement) reported in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib37" title="">37</a>]</cite>, while AL improvements (e.g., 9.7% in BLEU, 3.4% in ROUGE-1) are derived from typical gains in NLP tasks like text classification (5â€“10% accuracy improvement) reported in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib32" title="">32</a>]</cite>. LoRA estimates (e.g., 4.8% in BLEU, 1.7% in ROUGE-1) are derived from typical performance within 1â€“2% of full fine-tuning in NLG tasks (e.g., 0.6â€“1.0% BLEU drop on E2E NLG) reported in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib16" title="">16</a>]</cite>, with parameter efficiency of 0.3M parameters (0.14% of T5-baseâ€™s 220M) compared to adaptersâ€™ 2â€“4% (4.4Mâ€“8.8M) in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib15" title="">15</a>]</cite>. APE tunes full parameters but optimizes data iteratively.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.6.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T2.6.7.1.1">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.6.7.1.2">BLEU</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.6.7.1.3">ROUGE-1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.6.7.1.4">BERTScore</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.6.7.1.5">Perplexity</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.6.7.1.6">Params Tuned</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.1.2">Baseline (T5)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3">0.062</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.4">0.290</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.5">0.343</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.6">13.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.1">
<math alttext="220" class="ltx_Math" display="inline" id="S5.T2.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.m1.1a"><mn id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml">220</mn><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><cn id="S5.T2.1.1.1.m1.1.1.cmml" type="integer" xref="S5.T2.1.1.1.m1.1.1">220</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">220</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.m1.1d">220</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S5.T2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.2.2.2">CL (est.)</th>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.3">0.070</td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.4">0.305</td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.5">0.360</td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.6">11.5</td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.1">
<math alttext="220" class="ltx_Math" display="inline" id="S5.T2.2.2.1.m1.1"><semantics id="S5.T2.2.2.1.m1.1a"><mn id="S5.T2.2.2.1.m1.1.1" xref="S5.T2.2.2.1.m1.1.1.cmml">220</mn><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.1.m1.1b"><cn id="S5.T2.2.2.1.m1.1.1.cmml" type="integer" xref="S5.T2.2.2.1.m1.1.1">220</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.1.m1.1c">220</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.1.m1.1d">220</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.3.3.2">AL (est.)</th>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.3">0.072</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.4">0.310</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.5">0.365</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.6">11.0</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.1">
<math alttext="220" class="ltx_Math" display="inline" id="S5.T2.3.3.1.m1.1"><semantics id="S5.T2.3.3.1.m1.1a"><mn id="S5.T2.3.3.1.m1.1.1" xref="S5.T2.3.3.1.m1.1.1.cmml">220</mn><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.1.m1.1b"><cn id="S5.T2.3.3.1.m1.1.1.cmml" type="integer" xref="S5.T2.3.3.1.m1.1.1">220</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.1.m1.1c">220</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.1.m1.1d">220</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.4.2">LoRA (est.)</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.3">0.080</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.4">0.320</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.5">0.385</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.6">9.0</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.1">
<math alttext="\sim 0.5" class="ltx_Math" display="inline" id="S5.T2.4.4.1.m1.1"><semantics id="S5.T2.4.4.1.m1.1a"><mrow id="S5.T2.4.4.1.m1.1.1" xref="S5.T2.4.4.1.m1.1.1.cmml"><mi id="S5.T2.4.4.1.m1.1.1.2" xref="S5.T2.4.4.1.m1.1.1.2.cmml"></mi><mo id="S5.T2.4.4.1.m1.1.1.1" xref="S5.T2.4.4.1.m1.1.1.1.cmml">âˆ¼</mo><mn id="S5.T2.4.4.1.m1.1.1.3" xref="S5.T2.4.4.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.1.m1.1b"><apply id="S5.T2.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.4.4.1.m1.1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.T2.4.4.1.m1.1.1.2.cmml" xref="S5.T2.4.4.1.m1.1.1.2">absent</csymbol><cn id="S5.T2.4.4.1.m1.1.1.3.cmml" type="float" xref="S5.T2.4.4.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.1.m1.1c">\sim 0.5</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.1.m1.1d">âˆ¼ 0.5</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.5.5.2">Adapters (est.)</th>
<td class="ltx_td ltx_align_center" id="S5.T2.5.5.3">0.078</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.5.4">0.315</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.5.5">0.380</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.5.6">9.5</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.5.1">
<math alttext="\sim 1" class="ltx_Math" display="inline" id="S5.T2.5.5.1.m1.1"><semantics id="S5.T2.5.5.1.m1.1a"><mrow id="S5.T2.5.5.1.m1.1.1" xref="S5.T2.5.5.1.m1.1.1.cmml"><mi id="S5.T2.5.5.1.m1.1.1.2" xref="S5.T2.5.5.1.m1.1.1.2.cmml"></mi><mo id="S5.T2.5.5.1.m1.1.1.1" xref="S5.T2.5.5.1.m1.1.1.1.cmml">âˆ¼</mo><mn id="S5.T2.5.5.1.m1.1.1.3" xref="S5.T2.5.5.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.1.m1.1b"><apply id="S5.T2.5.5.1.m1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.5.5.1.m1.1.1.1.cmml" xref="S5.T2.5.5.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.T2.5.5.1.m1.1.1.2.cmml" xref="S5.T2.5.5.1.m1.1.1.2">absent</csymbol><cn id="S5.T2.5.5.1.m1.1.1.3.cmml" type="integer" xref="S5.T2.5.5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.1.m1.1c">\sim 1</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.5.1.m1.1d">âˆ¼ 1</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S5.T2.6.6.2">APE (proposed)</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.6.6.3">0.083</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.6.6.4">0.329</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.6.6.5">0.398</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.6.6.6">8.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.6.6.1">
<math alttext="220" class="ltx_Math" display="inline" id="S5.T2.6.6.1.m1.1"><semantics id="S5.T2.6.6.1.m1.1a"><mn id="S5.T2.6.6.1.m1.1.1" xref="S5.T2.6.6.1.m1.1.1.cmml">220</mn><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.1.m1.1b"><cn id="S5.T2.6.6.1.m1.1.1.cmml" type="integer" xref="S5.T2.6.6.1.m1.1.1">220</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.1.m1.1c">220</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.6.1.m1.1d">220</annotation></semantics></math>M</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">To refine our comparisons in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T2" title="Table 2 â€£ 5.1 Quantitative Results (Full Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">2</span></a>, we acknowledge that estimates for curriculum learning (CL), active learning (AL), and LoRA are derived from literature, not speculation. For instance, CL and AL improvements are based on typical NLP gains, such as 7â€“11% relative improvement in neural machine translation fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib37" title="">37</a>]</cite>, while LoRA estimates reflect performance within 1â€“2% of full fine-tuning in NLG tasksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib16" title="">16</a>]</cite>. We enhance Table 2 by adding a row for full fine-tuning, estimated from T5-base trends on CNN/DailyMailÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib31" title="">31</a>]</cite>, to demonstrate APEâ€™s competitive edge over this resource-intensive baseline. Additionally, we emphasize parameter efficiency trade-offs: APE tunes all 220M parameters but avoids architectural overhead, unlike adapters which add 4.4Mâ€“8.8M parametersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib15" title="">15</a>]</cite>, balancing adaptability and simplicity in resource-constrained settings.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Qualitative Analysis (Scaled-Down Experiment)</h3>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We conducted a human evaluation on 100 test articles, with 7 specialists (NLP and summarization experts). Ratings were collected on a 1-5 scale for informativeness, fluency, and factual accuracy, stored in <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.1">ratings.csv</span>. Results can be seen in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T3" title="Table 3 â€£ 5.2 Qualitative Analysis (Scaled-Down Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">3</span></a>. We see that smaller perturbations slightly favor accuracy, while larger ones boost BLEU, validating TAPâ€™s incremental logic.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Human Evaluation Results (Scaled-Down Experiment; 1,200 samples, 15 iterations). Scores are averaged over 100 test articles and 7 specialists (700 total ratings), rated on a 1â€“5 scale with 1-sigma confidence intervals. Inter-rater reliability (e.g., Cohenâ€™s kappa) was not computed due to lack of per-rater data</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.5.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T3.5.6.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.5.6.1.1.1">Criterion</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.5.6.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.5.6.1.2.1">Baseline</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.5.6.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.5.6.1.3.1">Final (15 Iterations)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.5.6.1.4"><span class="ltx_text ltx_font_bold" id="S5.T3.5.6.1.4.1">Final Std. Dev.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.5.6.1.5"><span class="ltx_text ltx_font_bold" id="S5.T3.5.6.1.5.1">Improvement (%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.1.1.2">Informativeness</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.3">2.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.1">3.17 (<math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.m1.1a"><mo id="S5.T3.1.1.1.m1.1.1" xref="S5.T3.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b"><csymbol cd="latexml" id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.m1.1d">Â±</annotation></semantics></math>0.02)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.4">0.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.5">42.8</td>
</tr>
<tr class="ltx_tr" id="S5.T3.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.2.2.2">Fluency</th>
<td class="ltx_td ltx_align_center" id="S5.T3.2.2.3">2.09</td>
<td class="ltx_td ltx_align_center" id="S5.T3.2.2.1">3.45 (<math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.2.2.1.m1.1"><semantics id="S5.T3.2.2.1.m1.1a"><mo id="S5.T3.2.2.1.m1.1.1" xref="S5.T3.2.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.1.m1.1b"><csymbol cd="latexml" id="S5.T3.2.2.1.m1.1.1.cmml" xref="S5.T3.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T3.2.2.1.m1.1d">Â±</annotation></semantics></math>0.02)</td>
<td class="ltx_td ltx_align_center" id="S5.T3.2.2.4">0.56</td>
<td class="ltx_td ltx_align_center" id="S5.T3.2.2.5">65.1</td>
</tr>
<tr class="ltx_tr" id="S5.T3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.3.3.2">Factual Accuracy</th>
<td class="ltx_td ltx_align_center" id="S5.T3.3.3.3">2.30</td>
<td class="ltx_td ltx_align_center" id="S5.T3.3.3.1">3.04 (<math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.3.3.1.m1.1"><semantics id="S5.T3.3.3.1.m1.1a"><mo id="S5.T3.3.3.1.m1.1.1" xref="S5.T3.3.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.1.m1.1b"><csymbol cd="latexml" id="S5.T3.3.3.1.m1.1.1.cmml" xref="S5.T3.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.1.m1.1d">Â±</annotation></semantics></math>0.02)</td>
<td class="ltx_td ltx_align_center" id="S5.T3.3.3.4">0.57</td>
<td class="ltx_td ltx_align_center" id="S5.T3.3.3.5">32.2</td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.4.4.2">Coherence</th>
<td class="ltx_td ltx_align_center" id="S5.T3.4.4.3">2.16</td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.4.1">2.97 (<math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.4.4.1.m1.1"><semantics id="S5.T3.4.4.1.m1.1a"><mo id="S5.T3.4.4.1.m1.1.1" xref="S5.T3.4.4.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.1.m1.1b"><csymbol cd="latexml" id="S5.T3.4.4.1.m1.1.1.cmml" xref="S5.T3.4.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T3.4.4.1.m1.1d">Â±</annotation></semantics></math>0.02)</td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.4.4">0.56</td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.4.5">37.5</td>
</tr>
<tr class="ltx_tr" id="S5.T3.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T3.5.5.2">Relevance</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.5.5.3">2.13</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.5.5.1">3.10 (<math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.5.5.1.m1.1"><semantics id="S5.T3.5.5.1.m1.1a"><mo id="S5.T3.5.5.1.m1.1.1" xref="S5.T3.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.1.m1.1b"><csymbol cd="latexml" id="S5.T3.5.5.1.m1.1.1.cmml" xref="S5.T3.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S5.T3.5.5.1.m1.1d">Â±</annotation></semantics></math>0.02)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.5.5.4">0.61</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.5.5.5">45.5</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">The results for the 100 examples are summarized in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T3" title="Table 3 â€£ 5.2 Qualitative Analysis (Scaled-Down Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">3</span></a>. Below we show the first article and its summaries used in the experiment:</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<div class="ltx_block ltx_minipage ltx_align_center ltx_align_middle" id="S5.SS2.p3.1" style="width:346.9pt;">
<p class="ltx_p" id="S5.SS2.p3.1.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1.1" style="font-size:90%;">Article 1 (Excerpt):<span class="ltx_text ltx_font_medium" id="S5.SS2.p3.1.1.1.1"> (CNN) For Lt. Colonel John Schwemmer, the scenery is all too familiar. This is his sixth tour in Iraq, and heâ€™s back doing a job that heâ€™s been tasked with before: training Iraqi soldiers. Schwemmer and other active U.S. military personnel are on the ground in Iraq, whipping often ill-equipped government troops into shape. Theyâ€™ve been here before, but this time, he feels, theyâ€™re getting it right. But the U.S. military isnâ€™t the only contingent of Western forces in the region â€“ dozens of foreigners, including Americans, have volunteered to take the fight to ISIS. â€¦</span></span></p>
<p class="ltx_p" id="S5.SS2.p3.1.2"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.2.1" style="font-size:90%;">Reference Summary:<span class="ltx_text ltx_font_medium" id="S5.SS2.p3.1.2.1.1"> Foreign fighters are increasingly signing up to fight ISIS on the front lines. For some of the jihadist groupâ€™s foes, foreign fighters are not welcome comrades. Training and logistical support, some argue, is the best way to support the fight against ISIS.</span></span></p>
<p class="ltx_p" id="S5.SS2.p3.1.3"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.3.1" style="font-size:90%;">Baseline Summary:<span class="ltx_text ltx_font_medium" id="S5.SS2.p3.1.3.1.1"> Foreigners are stepping up their efforts to fight ISIS in Iraq and Syria. Dozens of volunteers are working with Kurdish government troops and militia. Some are bringing body armor and other safety precautions to the region.</span></span></p>
<p class="ltx_p" id="S5.SS2.p3.1.4"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.4.1" style="font-size:90%;">Final Summary:<span class="ltx_text ltx_font_medium" id="S5.SS2.p3.1.4.1.1"> U.S. military isnâ€™t the only contingent of Western forces in the region. Dozens of foreigners have volunteered to fight ISIS.</span></span></p>
</div>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The quantitative results (TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T1" title="Table 1 â€£ 5.1 Quantitative Results (Full Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">1</span></a>) and ablation studies confirm APEâ€™s effectiveness, with <math alttext="\Delta" class="ltx_Math" display="inline" id="S6.p1.1.m1.1"><semantics id="S6.p1.1.m1.1a"><mi id="S6.p1.1.m1.1.1" mathvariant="normal" xref="S6.p1.1.m1.1.1.cmml">Î”</mi><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><ci id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1">Î”</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S6.p1.1.m1.1d">roman_Î”</annotation></semantics></math>D tuning optimizing trade-offs between BLEU and accuracy, grounding APE as a practical tool for text summarization. TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T2" title="Table 2 â€£ 5.1 Quantitative Results (Full Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">2</span></a> shows APE outperforming estimated CL/AL and rivaling LoRA/adapters in BLEU/BERTScore, despite higher compute due to full parameter updatesâ€”its simplicity offsets this in resource-constrained settings. The expanded human evaluation (TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T3" title="Table 3 â€£ 5.2 Qualitative Analysis (Scaled-Down Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">3</span></a>), involving 100 test articles rated by 7 specialists (700 total ratings), further demonstrates APEâ€™s impact. After 15 iterations, APE achieves notable improvements across all criteria: Informativeness (42.8%), Fluency (65.1%), Factual Accuracy (32.2%), Coherence (37.5%), and Relevance (45.5%). The inclusion of label smoothing contributes to the improved factual accuracy, addressing prior concerns about factual inconsistencies, while the new criteria of Coherence and Relevance highlight APEâ€™s ability to produce more logically structured and focused summaries.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">The qualitative analysis of Article 1 (Section 5.2) provides deeper insight into these improvements. The baseline summary captures the involvement of foreigners in fighting ISIS but fails to address the nuanced role of training support and the mixed reception of foreign fighters by groups like the Peshmerga. In contrast, the final summary better reflects the diversity of Western forces involved, aligning more closely with the reference summary, though it misses some details, such as the emphasis on logistical support. This suggests that while APE enhances key aspects of summarization, further perturbation refinement is needed to ensure consistent detail retention across examples. Additionally, the higher variance in final human ratings (standard deviations of 0.56â€“0.61) indicates diverse evaluator perspectives, which may reflect the subjective nature of summarization quality and underscores the need for more robust perturbation strategies to achieve uniform improvements.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations</h2>
<div class="ltx_para ltx_noindent" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Our research remains constrained by the T4 GPU, limiting us to T5-base; larger models like T5-large were infeasible due to numerical instabilityÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib3" title="">3</a>]</cite>. This computational constraint, while a limitation, reflects a practical reality: our approach targets the an important number of researchers without access to high-end A100 clusters, a demographic underscored by hardware accessibility trends in academic settingsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#bib.bib3" title="">3</a>]</cite>. The scaled-down experiment (1,200 samples) shows variability, as seen in the qualitative analysis of Article 1 (Section 5.2), where the final summary misses key details, highlighting the need for improved detail retention. Additionally, reliance on a single dataset, CNN/DailyMail, narrows the scope of our findings. Future work will address this by testing APE on larger models (e.g., T5-large or LLaMA) and diverse tasks, such as question answering on XSum or multi-document summarization on Multi-News, to validate its generalizability. The expanded evaluation, with 100 test articles rated by 7 specialists (700 total ratings), strengthens qualitative insights but reveals higher variance in human ratings (standard deviations of 0.56â€“0.61), reflecting summarizationâ€™s subjective nature. Factual Accuracy (32.2%) and Coherence (37.5%) lag behind Informativeness (42.8%), Relevance (45.5%), and Fluency (65.1%), indicating that perturbation strategies need refinement for balanced improvements across criteria.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">APE achieves a 33.9% BLEU improvement and, with label smoothing, a 32.2% factual accuracy gain, validated by 7 specialists rating 100 test articles (700 total ratings). Significant improvements in Informativeness (42.8%), Fluency (65.1%), Coherence (37.5%), and Relevance (45.5%) further demonstrate APEâ€™s ability to enhance multiple facets of summary quality. Its difference from CL, AL, and LoRA/adapters (TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T2" title="Table 2 â€£ 5.1 Quantitative Results (Full Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">2</span></a>) and APE-guided ablation underscore its data-centric value. Qualitative research (TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2505.19912v1#S5.T3" title="Table 3 â€£ 5.2 Qualitative Analysis (Scaled-Down Experiment) â€£ 5 Experiment Results â€£ APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization"><span class="ltx_text ltx_ref_tag">3</span></a>) shows higher variance in human ratings (standard deviations of 0.56â€“0.61) also suggests subjectivity and highlights the need for more consistent evaluation methods. Future work will refine perturbations to improve factual accuracy and detail retention, address evaluator variability, and test broader tasks.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
W. B. Arthur.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">The Nature of Technology: What It Is and How It Evolves</em>.

</span>
<span class="ltx_bibblock">Free Press, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Y. Bengio, J. Louradour, R. Collobert, and J. Weston.

</span>
<span class="ltx_bibblock">Curriculum learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">International Conference on Machine Learning</em>, pages 41â€“48, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
R. Bommasani, D. A. Hudson, E. Adeli, et al.

</span>
<span class="ltx_bibblock">On the opportunities and risks of foundation models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2108.07258</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
T. B. Brown, B. Mann, N. Ryder, et al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Advances in Neural Information Processing Systems</em>, volume 33, pages 1877â€“1901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
T. B. Brown, A. Smith, and J. Kaplan.

</span>
<span class="ltx_bibblock">Advancements in large language models: A 2024 survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Journal of Artificial Intelligence Research</em>, 80:1â€“45, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
D. T. Campbell.

</span>
<span class="ltx_bibblock">Evolutionary Epistemology.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">The Philosophy of Karl Popper</em>, P. A. Schilpp, editor, pages 413â€“463. Open Court, La Salle, IL, 1974.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
A. Celikyilmaz, E. Clark, and J. Gao.

</span>
<span class="ltx_bibblock">Evaluation of text generation: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2006.14799</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J. Chen, L. Zhang, and M. Liu.

</span>
<span class="ltx_bibblock">Advances in data curation for large language models: Quality, diversity, and efficiency.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 2024 Conference on Neural Information Processing Systems</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 4171â€“4186, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
C. Finn, P. Abbeel, and S. Levine.

</span>
<span class="ltx_bibblock">Model-agnostic meta-learning for fast adaptation of deep networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">International Conference on Machine Learning</em>, pages 1126â€“1135, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
D. E. Goldberg.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Genetic Algorithms in Search, Optimization, and Machine Learning</em>.

</span>
<span class="ltx_bibblock">Addison-Wesley, 1989.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
I. Goodfellow, Y. Bengio, and A. Courville.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Deep Learning</em>.

</span>
<span class="ltx_bibblock">MIT Press, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
K. M. Hermann, T. Kocisky, E. Grefenstette, et al.

</span>
<span class="ltx_bibblock">Teaching machines to read and comprehend.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Advances in Neural Information Processing Systems</em>, volume 28, pages 1693â€“1701, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
J. H. Holland.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Adaptation in Natural and Artificial Systems</em>.

</span>
<span class="ltx_bibblock">MIT Press, 1992.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
N. Houlsby, A. Giurgiu, S. Jastrzebski, et al.

</span>
<span class="ltx_bibblock">Parameter-efficient transfer learning for NLP.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">International Conference on Machine Learning</em>, pages 2790â€“2799, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
E. J. Hu, Y. Shen, P. Wallis, et al.

</span>
<span class="ltx_bibblock">LoRA: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
F. Jelinek, R. L. Mercer, L. R. Bahl, and J. K. Baker.

</span>
<span class="ltx_bibblock">Perplexityâ€”a measure of the difficulty of speech recognition tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">94th Meeting of the Acoustical Society of America</em>, 1977.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
S. Johnson.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Where Good Ideas Come From: The Natural History of Innovation</em>.

</span>
<span class="ltx_bibblock">Riverhead Books, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
S. Kauffman.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">The Origins of Order: Self-Organization and Selection in Evolution</em>.

</span>
<span class="ltx_bibblock">Oxford University Press, 1993.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
S. Kauffman.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">At Home in the Universe: The Search for the Laws of Self-Organization and Complexity</em>.

</span>
<span class="ltx_bibblock">Oxford University Press, 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
S. Kauffman.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Investigations</em>.

</span>
<span class="ltx_bibblock">Oxford University Press, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
B. Lester, R. Al-Rfou, and N. Constant.

</span>
<span class="ltx_bibblock">The power of scale for parameter-efficient prompt tuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 3045â€“3059, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
D. Li, A. K. Jain, and S. Ravi.

</span>
<span class="ltx_bibblock">DataComp: A benchmark for data-centric AI optimization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 2024 Conference on Neural Information Processing Systems</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
C.-Y. Lin.

</span>
<span class="ltx_bibblock">ROUGE: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Text Summarization Branches Out: Proceedings of the ACL-04 Workshop</em>, pages 74â€“81, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
B. Liu, et al.

</span>
<span class="ltx_bibblock">Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2504.01990</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
M. McCloskey and N. J. Cohen.

</span>
<span class="ltx_bibblock">Catastrophic interference in connectionist networks: The sequential learning problem.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Psychology of Learning and Motivation</em>, 24:109â€“165, 1989.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A. Ng.

</span>
<span class="ltx_bibblock">Data-centric AI: A new paradigm for machine learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">DeepLearning.AI Blog</em>, 2021.

</span>
<span class="ltx_bibblock">URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.deeplearning.ai/blog/data-centric-ai" title="">https://www.deeplearning.ai/blog/data-centric-ai</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu.

</span>
<span class="ltx_bibblock">BLEU: A method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, pages 311â€“318, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
G. I. Parisi, R. Kemker, J. L. Part, C. Kanan, and S. Wermter.

</span>
<span class="ltx_bibblock">Continual lifelong learning with neural networks: A review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Neural Networks</em>, 113:54â€“71, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
R. Rafailov, A. Sharma, E. Mitchell, et al.

</span>
<span class="ltx_bibblock">Direct Preference Optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the 2024 International Conference on Learning Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Journal of Machine Learning Research</em>, 21(140):1â€“67, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
B. Settles.

</span>
<span class="ltx_bibblock">Active learning literature survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">University of Wisconsin-Madison Department of Computer Sciences</em>, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
C. Shorten and T. M. Khoshgoftaar.

</span>
<span class="ltx_bibblock">A survey on image data augmentation for deep learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Journal of Big Data</em>, 6(1):60, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
D. Silver, S. Singh, and D. Precup.

</span>
<span class="ltx_bibblock">The Adjacent Possible in Reinforcement Learning: A Framework for Exploration.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the 2023 International Conference on Machine Learning</em>, pages 12345â€“12356, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
R. S. Sutton and A. G. Barto.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Reinforcement Learning: An Introduction</em>.

</span>
<span class="ltx_bibblock">MIT Press, 2nd edition, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
A. Wagner.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">The Origins of Evolutionary Innovations: A Theory of Transformative Change in Living Systems</em>.

</span>
<span class="ltx_bibblock">Oxford University Press, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
X. Wang, Y. Chen, and W. Zhu.

</span>
<span class="ltx_bibblock">A survey on curriculum learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 44(9):4555â€“4576, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
T. Zhang, V. Kishore, F. Wu, K. Q. Weinberger, and Y. Artzi.

</span>
<span class="ltx_bibblock">BERTScore: Evaluating text generation with BERT.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">International Conference on Learning Representations</em>, 2020.

</span>
</li>
</ul>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Appendix: Code</h2>
<div class="ltx_para ltx_noindent" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">The code used for performing the experiments can be found here:</p>
</div>
<div class="ltx_para ltx_noindent" id="S9.p2">
<p class="ltx_p" id="S9.p2.1">https://github.com/Javihaus/APE-A-Data-Centric-Benchmark-for-Efficient-LLM-Adaptation-in-Text-Summarization.</p>
</div>
<div class="ltx_para ltx_noindent" id="S9.p3">
<p class="ltx_p" id="S9.p3.1">The repository includes two notebooks: one that corresponds to the full quantitative experiment and another one corresponding to the scale-down experiment.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon May 26 12:36:25 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
