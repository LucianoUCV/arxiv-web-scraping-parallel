<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>The Many Challenges of Human-Like Agents in Virtual Game Environments</title>
<!--Generated on Mon May 26 13:47:27 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Intelligent Agents; Human-Like AI; Believable Agents; ML Model for Turing Test" lang="en" name="keywords"/>
<base href="/html/2505.20011v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S1" title="In The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S2" title="In The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Discussion of the Challenges</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S3" title="In The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiment Environment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S3.SS1" title="In 3. Experiment Environment ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Method Behind AI Agents</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S4" title="In The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Method Behind Human-Likeness Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S4.SS1" title="In 4. Method Behind Human-Likeness Evaluation ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S5" title="In The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusions</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\setcopyright</span>
<p class="ltx_p" id="p1.2">ifaamas
<span class="ltx_ERROR undefined" id="p1.2.1">\acmConference</span>[AAMAS ’25]Proc. of the 24th International Conference
on Autonomous Agents and Multiagent Systems (AAMAS 2025)May 19 – 23, 2025
Detroit, Michigan, USAY. Vorobeychik, S. Das, A. Nowé (eds.)
<span class="ltx_ERROR undefined" id="p1.2.2">\copyrightyear</span>2025
<span class="ltx_ERROR undefined" id="p1.2.3">\acmYear</span>2025
<span class="ltx_ERROR undefined" id="p1.2.4">\acmDOI</span>
<span class="ltx_ERROR undefined" id="p1.2.5">\acmPrice</span>
<span class="ltx_ERROR undefined" id="p1.2.6">\acmISBN</span>
<span class="ltx_ERROR undefined" id="p1.2.7">\acmSubmissionID</span>499

 <span class="ltx_ERROR undefined" id="p1.2.8">\affiliation</span>
<span class="ltx_ERROR undefined" id="p1.2.9">\institution</span>QED Software
<span class="ltx_ERROR undefined" id="p1.2.10">\city</span>Warsaw
<span class="ltx_ERROR undefined" id="p1.2.11">\country</span>Poland

 <span class="ltx_ERROR undefined" id="p1.2.12">\affiliation</span>
<span class="ltx_ERROR undefined" id="p1.2.13">\institution</span>University of Warsaw
<span class="ltx_ERROR undefined" id="p1.2.14">\city</span>Warsaw
<span class="ltx_ERROR undefined" id="p1.2.15">\country</span>Poland</p>
</div>
<h1 class="ltx_title ltx_title_document">The Many Challenges of Human-Like Agents 
<br class="ltx_break"/>in Virtual Game Environments</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Maciej Świechowski
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:maciej.swiechowski@qed.pl">maciej.swiechowski@qed.pl</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dominik Śl<span class="ltx_ERROR undefined" id="id1.1.id1">\k</span>ezak
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:slezak@mimuw.edu.pl">slezak@mimuw.edu.pl</a>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id2.id1">Human-like agents are an increasingly important topic in games and beyond. Believable non-player characters enhance the gaming experience by improving immersion and providing entertainment. They also offer players the opportunity to engage with AI entities that can function as opponents, teachers, or cooperating partners. Additionally, in games where bots are prohibited – and even more so in non-game environments – there is a need for methods capable of identifying whether digital interactions occur with bots or humans. This leads to two fundamental research questions: (1) how to model and implement human-like AI, and (2) how to measure its degree of human likeness.</p>
<p class="ltx_p" id="id3.id2">This article offers two contributions. The first one is a survey of the most significant challenges in implementing human-like AI in games (or any virtual environment featuring simulated agents, although this article specifically focuses on games). Thirteen such challenges, both conceptual and technical, are discussed in detail.</p>
<p class="ltx_p" id="id4.id3">The second is an empirical study performed in a tactical video game that addresses the research question: “Is it possible to distinguish human players from bots (AI agents) based on empirical data?” A machine-learning approach using a custom deep recurrent convolutional neural network is presented.</p>
<p class="ltx_p" id="id5.id4">We hypothesize that the more challenging it is to create human-like AI for a given game, the easier it becomes to develop a method for distinguishing humans from AI-driven players.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Key words and phrases: </h6>Intelligent Agents; Human-Like AI; Believable Agents; ML Model for Turing Test
</div>
<div class="ltx_para" id="p2">
<p class="ltx_p" id="p2.1">Copyright © 2025 by International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS). Permission to make digital or hard copies of portions of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyright for components of this work owned by others than IFAAMAS must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.</p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1">BibTeX:</p>
</div>
<div class="ltx_para" id="p4">
<pre class="ltx_verbatim ltx_font_typewriter" id="p4.1">
@inproceedings{humanLike2025,
  title={{The Many Challenges of Human-Like Agents in Virtual Game Environments}},
  author={{\’S}wiechowski, Maciej and {\’S}l{\k{e}}zak, Dominik},
  booktitle={Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems (AAMAS-2025)},
  year={2025},
  organization={IFAAMAS},
 publisher={IFAAMAS},
  pages={1996--2005},
}
</pre>
<p class="ltx_p" id="p4.2">The DOI will be assigned to this paper at a later stage.</p>
</div>
<div class="ltx_para" id="p5">
<span class="ltx_ERROR undefined" id="p5.1">{acks}</span>
<p class="ltx_p" id="p5.2">This research was co-funded by the Smart Growth Operational Programme 2014-2020, financed by the European Regional Development Fund under a GameINN project POIR.01.02.00-00-0207/20, operated by The National Centre for Research and Development.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Games have been an integral part of human civilization since ancient times <cite class="ltx_cite ltx_citemacro_cite">Kurke (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib24" title="">1999</a>)</cite>. In the essay “Homo Ludens”, the author examines games as a fundamental condition for the evolution of culture <cite class="ltx_cite ltx_citemacro_cite">Ehrmann et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib12" title="">1968</a>)</cite>. Besides providing entertainment, some games help in training the mind, enhancing eye-brain coordination, and improving reflexes.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Since the advent of Artificial Intelligence (AI), games have served as a testbed for its development. Initially, AI research focused primarily on <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">chess</em> <cite class="ltx_cite ltx_citemacro_cite">McCarthy (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib32" title="">1990</a>)</cite> and <em class="ltx_emph ltx_font_italic" id="S1.p2.1.2">checkers</em> <cite class="ltx_cite ltx_citemacro_cite">Samuel (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib42" title="">1959</a>)</cite>. However, with recent advancements that have sparked debates about the human-likeness of AI, video games have become increasingly attractive as research environments. Unlike abstract combinatorial games such as <em class="ltx_emph ltx_font_italic" id="S1.p2.1.3">chess</em>, <em class="ltx_emph ltx_font_italic" id="S1.p2.1.4">checkers</em>, or <em class="ltx_emph ltx_font_italic" id="S1.p2.1.5">Go</em> <cite class="ltx_cite ltx_citemacro_cite">Gelly et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib15" title="">2012</a>)</cite>, video games typically offer a simplified model of the real world populated with numerous non-player characters (NPCs). They were named “<span class="ltx_text ltx_font_italic" id="S1.p2.1.6">human-level AI’s killer application</span>” <cite class="ltx_cite ltx_citemacro_cite">Laird and VanLent (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib26" title="">2001</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.5">The aim of this article is twofold and is divided into two parts.
The first part, contained in Section <a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S2" title="2. Discussion of the Challenges ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_tag">2</span></a>, provides a comprehensive and accessible review of the challenges related to creating human-like AI (characters, bots, players) for games. We discuss 13 challenges, drawing from both the literature and our years of professional experience in implementing artificial intelligence for video games. These challenges can be generalized to autonomous robots and any virtual environments with intelligent agents. We believe that the comments and insights provided mostly in this part can help researchers design AI that acts more human-like by addressing the issues related to creation and evaluation.
In our search for relevant papers, we queried popular bibliographic databases using terms from the following template: <math alttext="\langle" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mo id="S1.p3.1.m1.1.1" stretchy="false" xref="S1.p3.1.m1.1.1.cmml">⟨</mo><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">⟨</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">\langle</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">⟨</annotation></semantics></math> adjective <math alttext="\rangle" class="ltx_Math" display="inline" id="S1.p3.2.m2.1"><semantics id="S1.p3.2.m2.1a"><mo id="S1.p3.2.m2.1.1" stretchy="false" xref="S1.p3.2.m2.1.1.cmml">⟩</mo><annotation-xml encoding="MathML-Content" id="S1.p3.2.m2.1b"><ci id="S1.p3.2.m2.1.1.cmml" xref="S1.p3.2.m2.1.1">⟩</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">\rangle</annotation><annotation encoding="application/x-llamapun" id="S1.p3.2.m2.1d">⟩</annotation></semantics></math> <math alttext="\langle" class="ltx_Math" display="inline" id="S1.p3.3.m3.1"><semantics id="S1.p3.3.m3.1a"><mo id="S1.p3.3.m3.1.1" stretchy="false" xref="S1.p3.3.m3.1.1.cmml">⟨</mo><annotation-xml encoding="MathML-Content" id="S1.p3.3.m3.1b"><ci id="S1.p3.3.m3.1.1.cmml" xref="S1.p3.3.m3.1.1">⟨</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.3.m3.1c">\langle</annotation><annotation encoding="application/x-llamapun" id="S1.p3.3.m3.1d">⟨</annotation></semantics></math> noun <math alttext="\rangle" class="ltx_Math" display="inline" id="S1.p3.4.m4.1"><semantics id="S1.p3.4.m4.1a"><mo id="S1.p3.4.m4.1.1" stretchy="false" xref="S1.p3.4.m4.1.1.cmml">⟩</mo><annotation-xml encoding="MathML-Content" id="S1.p3.4.m4.1b"><ci id="S1.p3.4.m4.1.1.cmml" xref="S1.p3.4.m4.1.1">⟩</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.4.m4.1c">\rangle</annotation><annotation encoding="application/x-llamapun" id="S1.p3.4.m4.1d">⟩</annotation></semantics></math>.
The set of adjectives included “human-like”, “human-level”, “believable”, and the set of nouns contained: “agent(s)”, “player(s)”, “bot(s)”, “character(s)”, “behavior”, “AI”, and “Artificial Intelligence”. The complete set of terms was a Cartesian product of the sets of adjectives and nouns. Additionally, we included other selected articles such as <cite class="ltx_cite ltx_citemacro_cite">Silver et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib45" title="">2016</a>)</cite> that are seminal to the topic. Among all the papers matching the query, we read their abstracts and introductions to verify if their contents were related to creating or evaluating human-like AI in virtual environments. After this step, <math alttext="54" class="ltx_Math" display="inline" id="S1.p3.5.m5.1"><semantics id="S1.p3.5.m5.1a"><mn id="S1.p3.5.m5.1.1" xref="S1.p3.5.m5.1.1.cmml">54</mn><annotation-xml encoding="MathML-Content" id="S1.p3.5.m5.1b"><cn id="S1.p3.5.m5.1.1.cmml" type="integer" xref="S1.p3.5.m5.1.1">54</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.5.m5.1c">54</annotation><annotation encoding="application/x-llamapun" id="S1.p3.5.m5.1d">54</annotation></semantics></math> papers remained. We have analyzed them and distilled the most pertinent and common challenges.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Parallel to creating human-like autonomous agents, we also discuss the issue of assessing their human-likeness. These topics are closely intertwined. It is challenging to implement AI techniques without precisely setting the evaluation criteria—what constitutes human-likeness.
In 1950, Alan Turing posed the question “Can Machines Think?” <cite class="ltx_cite ltx_citemacro_cite">Warwick and Shah (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib56" title="">2016</a>)</cite>. He introduced the concept of the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">Imitation Game</em>, which laid the foundations for what would later be known as the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">Turing Test</em> <cite class="ltx_cite ltx_citemacro_cite">Moor (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib36" title="">1976</a>)</cite>. In the classic variant of the test, an interrogator (judge) interacts with two players, <em class="ltx_emph ltx_font_italic" id="S1.p4.1.3">A</em> and <em class="ltx_emph ltx_font_italic" id="S1.p4.1.4">B</em>, using a natural language chat interface in such a way that the players cannot be seen—only their responses can. The goal of the interrogator is to determine whether each participant is a human or a computer. The <em class="ltx_emph ltx_font_italic" id="S1.p4.1.5">Turing Test</em> has been a foundational concept in AI and has sparked a debate about whether machines can display human-like abilities, intelligence, and consciousness. This topic has been pursued by many prominent researchers, such as Lofti Zadeh <cite class="ltx_cite ltx_citemacro_cite">Zadeh (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib59" title="">2008</a>)</cite>.
Although there have been attempts to formalize believability <cite class="ltx_cite ltx_citemacro_cite">Bogdanovych et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib5" title="">2015</a>)</cite>, the most common approach is to propose a <em class="ltx_emph ltx_font_italic" id="S1.p4.1.6">Turing Test</em> analogy for video games <cite class="ltx_cite ltx_citemacro_cite">Świechowski (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib48" title="">2020</a>)</cite>. The first research framework to do so was the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.7">2K BotPrize</em> <cite class="ltx_cite ltx_citemacro_cite">Hingston (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib19" title="">2009</a>)</cite>, proposed in 2008 by Philip Hingston, based on the multi-player shooter game <em class="ltx_emph ltx_font_italic" id="S1.p4.1.8">Unreal Tournament 2004</em>. Since then, researchers have adopted the idea of the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.9">Turing Test</em> for more games, such as <em class="ltx_emph ltx_font_italic" id="S1.p4.1.10">Street Fighter</em> <cite class="ltx_cite ltx_citemacro_cite">Arzate Cruz and Ramirez Uresti (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib3" title="">2018</a>)</cite> and <em class="ltx_emph ltx_font_italic" id="S1.p4.1.11">Ms. Pacman</em> <cite class="ltx_cite ltx_citemacro_cite">Miranda et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib35" title="">2017</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.2">In the second part, we present a study concerning the automatic construction of a method capable of distinguishing human players from bots solely by learning from data. In Section <a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S3" title="3. Experiment Environment ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_tag">3</span></a>, the environment in which the experiments were conducted is presented—a tactical war video game with relatively high action-space complexity. Section <a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S4" title="4. Method Behind Human-Likeness Evaluation ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_tag">4</span></a> focuses on the machine learning algorithm proposed for this task. The training methodology combines recurrent and convolutional neural networks and utilizes multi-modal (numeric and spatial) data. The proposed solution achieves an F1-Score of <math alttext="0.92" class="ltx_Math" display="inline" id="S1.p5.1.m1.1"><semantics id="S1.p5.1.m1.1a"><mn id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml">0.92</mn><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><cn id="S1.p5.1.m1.1.1.cmml" type="float" xref="S1.p5.1.m1.1.1">0.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">0.92</annotation><annotation encoding="application/x-llamapun" id="S1.p5.1.m1.1d">0.92</annotation></semantics></math>, which is a significant improvement over the previous solution based on XGBoost with only numeric features, which had an F1-score of <math alttext="0.58" class="ltx_Math" display="inline" id="S1.p5.2.m2.1"><semantics id="S1.p5.2.m2.1a"><mn id="S1.p5.2.m2.1.1" xref="S1.p5.2.m2.1.1.cmml">0.58</mn><annotation-xml encoding="MathML-Content" id="S1.p5.2.m2.1b"><cn id="S1.p5.2.m2.1.1.cmml" type="float" xref="S1.p5.2.m2.1.1">0.58</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.2.m2.1c">0.58</annotation><annotation encoding="application/x-llamapun" id="S1.p5.2.m2.1d">0.58</annotation></semantics></math>. The last section is devoted to conclusions.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Discussion of the Challenges</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Humans are Diverse</span>. The first challenge we wish to highlight is the ambiguity and imprecision inherent in defining the goal of human-like AI. Following <cite class="ltx_cite ltx_citemacro_cite">Arzate Cruz and Ramirez Uresti (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib3" title="">2018</a>)</cite>, human-like AI is described as “behaving in a manner that makes it indistinguishable from human players”. The authors of <cite class="ltx_cite ltx_citemacro_cite">Tencé et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib51" title="">2010</a>)</cite> define it as “giving the feeling of being controlled by a (human) player”. Considering the vast diversity among humans, what exactly does it mean to play like a human player? The playing styles can vary significantly. An elderly individual often plays differently compared to a younger person or a child who just started playing video games. Similarly, a professional player’s approach will differ from that of an amateur. Even among seasoned players, there is a lot of variety. The authors in <cite class="ltx_cite ltx_citemacro_cite">Arinbjarnar and Kudenko (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib2" title="">2012</a>)</cite> identify seven distinct player types: <em class="ltx_emph ltx_font_italic" id="S2.p1.1.2">power gamer</em>, <em class="ltx_emph ltx_font_italic" id="S2.p1.1.3">butt-kicker</em>, <em class="ltx_emph ltx_font_italic" id="S2.p1.1.4">tactician</em>, <em class="ltx_emph ltx_font_italic" id="S2.p1.1.5">specialist</em>, <em class="ltx_emph ltx_font_italic" id="S2.p1.1.6">method actor</em>, <em class="ltx_emph ltx_font_italic" id="S2.p1.1.7">storyteller</em>, and <em class="ltx_emph ltx_font_italic" id="S2.p1.1.8">casual gamer</em>. Another example is the Bartle taxonomy, outlined in <cite class="ltx_cite ltx_citemacro_cite">Zuchowska et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib60" title="">2021</a>)</cite>, that categorizes players into four roles: <em class="ltx_emph ltx_font_italic" id="S2.p1.1.9">killer</em>, <em class="ltx_emph ltx_font_italic" id="S2.p1.1.10">socializer</em>, <em class="ltx_emph ltx_font_italic" id="S2.p1.1.11">achiever</em>, and <em class="ltx_emph ltx_font_italic" id="S2.p1.1.12">explorer</em>. Each category adjusts their gameplay in a unique manner to align with their personal objectives and maximize enjoyment.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_italic" id="S2.p2.1.1">Unreal Tournament 2004</span> serves as a popular choice among researchers for assessing human-like behavior in gameplay. According to <cite class="ltx_cite ltx_citemacro_cite">Gamez et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib14" title="">2012</a>)</cite>, one of the significant challenges for human judges is the wide range of human behaviors, which underscores the complexity due to player diversity. The authors investigated the topic further and commented that skill level is the most crucial factor distinguishing different playing patterns. In their study, less skilled players were identified as outliers in a statistical analysis of gameplay when matched with experts.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Additionally, implementing AI bots to mimic human behavior can be problematic if the game is still under development, because it might be unclear how human players will play the particular game. This becomes particularly challenging for novel games, i.e., not based on standard repeatable formats.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p4">
<p class="ltx_p" id="S2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.p4.1.1">The Complexity and Expressiveness of Action Space</span>. In short, complex high-dimensional action spaces pose a great challenge in implementing human-like AI, whereas simple, constrained ones complicate the evaluation of whether an AI is truly human-like. Let us elaborate on this.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.4">In complex environments, human-like behavior necessitates the simulation of thinking processes. These usually involve various forms of reasoning and strategic or tactical planning that anticipate multiple steps ahead. Humans often develop behavior patterns based on their experiences and can rely on their intuition. In contrast, AI-driven characters depend on computational techniques such as tree search (e.g., alpha-beta or Monte Carlo Tree Search (MCTS) <cite class="ltx_cite ltx_citemacro_cite">Świechowski et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib49" title="">2023</a>)</cite>), planning (such as Hierarchical Task Networks (HTN) <cite class="ltx_cite ltx_citemacro_cite">Nejati et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib38" title="">2006</a>)</cite>), or machine learning. The complexity of the environment significantly increases the computational resources required to create even a moderately proficient AI player compared to human players. This is clearly demonstrated by historical attempts to challenge top human players in various games, such as <em class="ltx_emph ltx_font_italic" id="S2.p5.4.1">Chinook</em> <cite class="ltx_cite ltx_citemacro_cite">Schaeffer et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib43" title="">2007</a>)</cite> (in checkers), <em class="ltx_emph ltx_font_italic" id="S2.p5.4.2">Deep Blue</em> <cite class="ltx_cite ltx_citemacro_cite">Campbell et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib8" title="">2002</a>)</cite> (in chess), <em class="ltx_emph ltx_font_italic" id="S2.p5.4.3">AlphaGo</em> <cite class="ltx_cite ltx_citemacro_cite">Silver et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib46" title="">2017</a>)</cite> (in Go), <em class="ltx_emph ltx_font_italic" id="S2.p5.4.4">AlphaStar</em> <cite class="ltx_cite ltx_citemacro_cite">Vinyals et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib53" title="">2019</a>)</cite> (in Starcraft II), and <em class="ltx_emph ltx_font_italic" id="S2.p5.4.5">OpenAI Five</em> <cite class="ltx_cite ltx_citemacro_cite">OpenAI et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib39" title="">2019</a>)</cite> (in Dota 2). These projects employed substantial computational resources. For instance, Deep Blue was ranked 259th on the top500 list of supercomputers, while OpenAI Five utilized 172,800 CPUs and 1536 GPUs simultaneously <cite class="ltx_cite ltx_citemacro_cite">OpenAI et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib39" title="">2019</a>)</cite> at a peak. Although creating a potent computer agent is not equivalent to developing human-like AI, these research projects began their efforts when the top programs were significantly inferior to the skills of amateur human players. In complex games, achieving a skill level comparable to an average human player also demands considerable computing power and/or extensive simulation times. The complexity originates from several aspects: the number of options available in each state (termed the branching factor), the length of the game (which necessitates longer simulations, thereby reducing the number that can be conducted within a given time), the diversity of game states (state-space complexity), and the total number of leaf nodes in a complete game tree (game-tree complexity). Chess, being the second least complex game in this context (after checkers), possesses an average branching factor of <math alttext="35" class="ltx_Math" display="inline" id="S2.p5.1.m1.1"><semantics id="S2.p5.1.m1.1a"><mn id="S2.p5.1.m1.1.1" xref="S2.p5.1.m1.1.1.cmml">35</mn><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.1b"><cn id="S2.p5.1.m1.1.1.cmml" type="integer" xref="S2.p5.1.m1.1.1">35</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">35</annotation><annotation encoding="application/x-llamapun" id="S2.p5.1.m1.1d">35</annotation></semantics></math>, a state-space complexity of <math alttext="10^{44}" class="ltx_Math" display="inline" id="S2.p5.2.m2.1"><semantics id="S2.p5.2.m2.1a"><msup id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml"><mn id="S2.p5.2.m2.1.1.2" xref="S2.p5.2.m2.1.1.2.cmml">10</mn><mn id="S2.p5.2.m2.1.1.3" xref="S2.p5.2.m2.1.1.3.cmml">44</mn></msup><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><apply id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p5.2.m2.1.1.1.cmml" xref="S2.p5.2.m2.1.1">superscript</csymbol><cn id="S2.p5.2.m2.1.1.2.cmml" type="integer" xref="S2.p5.2.m2.1.1.2">10</cn><cn id="S2.p5.2.m2.1.1.3.cmml" type="integer" xref="S2.p5.2.m2.1.1.3">44</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">10^{44}</annotation><annotation encoding="application/x-llamapun" id="S2.p5.2.m2.1d">10 start_POSTSUPERSCRIPT 44 end_POSTSUPERSCRIPT</annotation></semantics></math>, and a game-tree complexity of <math alttext="10^{123}" class="ltx_Math" display="inline" id="S2.p5.3.m3.1"><semantics id="S2.p5.3.m3.1a"><msup id="S2.p5.3.m3.1.1" xref="S2.p5.3.m3.1.1.cmml"><mn id="S2.p5.3.m3.1.1.2" xref="S2.p5.3.m3.1.1.2.cmml">10</mn><mn id="S2.p5.3.m3.1.1.3" xref="S2.p5.3.m3.1.1.3.cmml">123</mn></msup><annotation-xml encoding="MathML-Content" id="S2.p5.3.m3.1b"><apply id="S2.p5.3.m3.1.1.cmml" xref="S2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p5.3.m3.1.1.1.cmml" xref="S2.p5.3.m3.1.1">superscript</csymbol><cn id="S2.p5.3.m3.1.1.2.cmml" type="integer" xref="S2.p5.3.m3.1.1.2">10</cn><cn id="S2.p5.3.m3.1.1.3.cmml" type="integer" xref="S2.p5.3.m3.1.1.3">123</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.3.m3.1c">10^{123}</annotation><annotation encoding="application/x-llamapun" id="S2.p5.3.m3.1d">10 start_POSTSUPERSCRIPT 123 end_POSTSUPERSCRIPT</annotation></semantics></math>. To provide a sense of scale, it is estimated that there are <math alttext="10^{80}" class="ltx_Math" display="inline" id="S2.p5.4.m4.1"><semantics id="S2.p5.4.m4.1a"><msup id="S2.p5.4.m4.1.1" xref="S2.p5.4.m4.1.1.cmml"><mn id="S2.p5.4.m4.1.1.2" xref="S2.p5.4.m4.1.1.2.cmml">10</mn><mn id="S2.p5.4.m4.1.1.3" xref="S2.p5.4.m4.1.1.3.cmml">80</mn></msup><annotation-xml encoding="MathML-Content" id="S2.p5.4.m4.1b"><apply id="S2.p5.4.m4.1.1.cmml" xref="S2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p5.4.m4.1.1.1.cmml" xref="S2.p5.4.m4.1.1">superscript</csymbol><cn id="S2.p5.4.m4.1.1.2.cmml" type="integer" xref="S2.p5.4.m4.1.1.2">10</cn><cn id="S2.p5.4.m4.1.1.3.cmml" type="integer" xref="S2.p5.4.m4.1.1.3">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.4.m4.1c">10^{80}</annotation><annotation encoding="application/x-llamapun" id="S2.p5.4.m4.1d">10 start_POSTSUPERSCRIPT 80 end_POSTSUPERSCRIPT</annotation></semantics></math> atoms in the observable universe. The complexity escalates further in real-time games with continuous movement making the action space virtually infinite (as bots can go in any directions). In the study concerning believable navigation <cite class="ltx_cite ltx_citemacro_cite">Karpov et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib22" title="">2012</a>)</cite>, the authors found that AI players can get stuck on level geometry or fail to appear human when following the navigation graph. The authors of <cite class="ltx_cite ltx_citemacro_cite">Arzate Cruz and Ramirez Uresti (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib3" title="">2018</a>)</cite> emphasize the necessity of exploring high-dimensional action spaces as one of the two main challenges in creating human-like AI.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">The five aforementioned AI players were the outcomes of large-scale research projects focused on competing against top human players in dedicated matches. However, AI players integrated into commercial video games must operate within the constraints of a single consumer-level hardware system shared with other game functionalities such as rendering <cite class="ltx_cite ltx_citemacro_cite">Rabin (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib40" title="">2013</a>)</cite>. This restriction makes it particularly challenging to develop AI players equalling humans in skills without giving them an unfair advantage.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Now, let us focus on simple abstract game environments characterized by low complexities in both state space and action space. <em class="ltx_emph ltx_font_italic" id="S2.p7.1.1">Tic-Tac-Toe</em> serves as a good example. While it is straightforward to create competent or even exceptionally strong AI players for such games, differentiating whether a player is human-like proves challenging. If there are only a handful of actions and the game follow strict rules, e.g., players take turns and each turn the active player chooses one of the few available actions, then there are insufficient premises to distinguish humans from bots. This issue is even more pronounced in <em class="ltx_emph ltx_font_italic" id="S2.p7.1.2">Rock-Paper-Scissors</em>, where each action is equally viable, making even random choices a legitimate strategy. In the study <cite class="ltx_cite ltx_citemacro_cite">Miranda et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib35" title="">2017</a>)</cite>, the authors highlighted the difficulties in telling whether a player is human or a bot within the game <em class="ltx_emph ltx_font_italic" id="S2.p7.1.3">Ms. Pac-Man</em>, which is considerably more complex than <em class="ltx_emph ltx_font_italic" id="S2.p7.1.4">Tic-Tac-Toe</em>.</p>
</div>
<div class="ltx_para" id="S2.p8">
<p class="ltx_p" id="S2.p8.1">The underlying point is that a game or virtual environment must possess a sufficient level of expressiveness to enable feasible assessments of human-like behavior. The more open-ended an environment is, the easier it becomes to determine whether the behavior of agents within it is believable.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p9">
<p class="ltx_p" id="S2.p9.1"><span class="ltx_text ltx_font_bold" id="S2.p9.1.1">The Challenges of Scale.</span> As mentioned in the previous paragraph, creating human-like AI is extremely computationally demanding. Note that all examples of AI agents that achieved high efficacy were in 1-vs-1 player settings. In these cases, the AI, utilizing powerful hardware, controlled one player (or, at most, two during training via self-play).</p>
</div>
<div class="ltx_para" id="S2.p10">
<p class="ltx_p" id="S2.p10.1">Now, imagine a virtual city populated by a million NPC inhabitants, each individually controlled. These NPCs must take actions based on various circumstances such as their goals and both internal and external states. One of the models for simulating many agents is called Belief–Desire–Intention (BDI) <cite class="ltx_cite ltx_citemacro_cite">Georgeff et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib16" title="">1999</a>)</cite>. Scaling high-efficacy AI implementations to environments with many diverse agents presents a challenge that is multiple orders of magnitude greater <cite class="ltx_cite ltx_citemacro_cite">Bailey et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib4" title="">2012</a>)</cite>. Essentially, it requires multiplying the resources used to create a high-fidelity solution by the number of simulated agents. As of the time of this article, it is infeasible to apply <em class="ltx_emph ltx_font_italic" id="S2.p10.1.1">state-of-the-art</em> game-playing models to massively multiplayer games. Currently, dedicated, low-fidelity approaches known as “Crowd AI” are used in the industry. Nevertheless, there have been research attempts to tackle the problem of simulating a large number of believable bots, as discussed by <cite class="ltx_cite ltx_citemacro_cite">Rankin et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib41" title="">2010</a>)</cite>. This approach utilizes Utility AI, integrates the Observe-Orient-Decide-Act (OODA) decision cycle, and employs temporary roles that agents may assume.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p11">
<p class="ltx_p" id="S2.p11.1"><span class="ltx_text ltx_font_bold" id="S2.p11.1.1">Avoiding Superhuman Behavior</span>. Rational players must act towards their goals and posses a certain level of skill in order to be believable. In efforts to develop AI agents with sufficient competence, there is a risk that these agents may display superhuman abilities in certain aspects of a game, compromising their believability. Both <cite class="ltx_cite ltx_citemacro_cite">Cavazza (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib9" title="">2000</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">Livingstone (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib29" title="">2006</a>)</cite> highlight that precision in calculations, such as pixel-perfect aiming in shooter games, is a characteristic strongly associated with bots in scenarios analogous to the <em class="ltx_emph ltx_font_italic" id="S2.p11.1.2">Turing Test</em> for video games. Therefore, it is another feature that makes it easier to assess human-like behavior but more difficult to implement it. It is often the case, that the removal of such precise calculations from bots make them significantly weaker, to the point that they are not believable due to different reasons, i.e., their incapacity to perform competent actions.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p12">
<p class="ltx_p" id="S2.p12.1"><span class="ltx_text ltx_font_bold" id="S2.p12.1.1">Idle and Non-Relevant Actions</span>. Even when a game has a clearly defined objective, human players often engage in actions that are irrelevant from the perspective of this goal. Such behaviors are commonly described in the literature as roaming, idle, “for fun”, or for “own amusement” actions. Observing navigation in an open virtual world provides a particularly interesting context to study these patterns <cite class="ltx_cite ltx_citemacro_cite">Milani et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib33" title="">2023</a>)</cite>. For example, players exploring a city in an RPG might pause to admire specific 3D models within the game environment. The following example, based on the author’s experience in a <em class="ltx_emph ltx_font_italic" id="S2.p12.1.2">Diablo</em> game developed by <em class="ltx_emph ltx_font_italic" id="S2.p12.1.3">Blizzard Entertainment</em>, illustrates this point. Imagine a scenario where a player controls a character equipped with an artifact that leaves a trail of ice on the ground. Players might intentionally run in patterns to create specific shapes with this mechanic. This emergent behavior, stemming from human creativity and playfulness, is entirely disconnected from the game’s mechanics or objectives. Consequently, it presents significant challenges for implementing such behaviors in AI-controlled bots. Standard algorithms designed to enhance AI player proficiency, which is typically the primary focus, would likely treat these actions as noise – something irrelevant. The study mentioned in <cite class="ltx_cite ltx_citemacro_cite">Khalifa et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib23" title="">2016</a>)</cite> proposes a modification to the Monte Carlo Tree Search (MCTS) algorithm that biases action selection towards patterns observed in human gameplay to make it more human-like. Given that enough data is available from human players, this adaptation appears to be a promising strategy for developing more human-like AI behaviors.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p13">
<p class="ltx_p" id="S2.p13.1"><span class="ltx_text ltx_font_bold" id="S2.p13.1.1">Biological Constraints</span>. Equipping AI players with realistic biological constraints extends well beyond standard practices in the field <cite class="ltx_cite ltx_citemacro_cite">Rabin (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib40" title="">2013</a>); Millington (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib34" title="">2019</a>)</cite>. These constraints include:</p>
</div>
<div class="ltx_para" id="S2.p14">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.I1.i1.p1.1.1">Visual Perception</em>. Typically, AI-controlled players are fed information directly about game objects and other characters, without any simulation of actual perception. For example, one of the distinguishing factors between bots and humans in UT2004 is that bots often collect items not looking at them <cite class="ltx_cite ltx_citemacro_cite">Schrum et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib44" title="">2012</a>)</cite>. The article <cite class="ltx_cite ltx_citemacro_cite">Laird (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib25" title="">2002</a>)</cite> discusses the challenge of extracting spatial information about the physical environment – such as walls and doors – from the game’s internal data structures, which are just sets of polygons.</p>
</div>
<div class="ltx_para" id="S2.I1.i1.p2">
<p class="ltx_p" id="S2.I1.i1.p2.1">As an interesting side note, the authors of <cite class="ltx_cite ltx_citemacro_cite">Togelius et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib52" title="">2012</a>)</cite> provided an insightful finding in their paper. The assessment of a bot’s human-likeness, as judged by humans, showed significant variation depending on the observation perspective. The authors concluded that a more accurate assessment occurred when bots were observed from a third-person perspective, as opposed to a first-person perspective.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.I1.i2.p1.1.1">Sound Perception</em>. Simulating realistic sound perception is as challenging as visual perception. The detection of sounds by a bot should not be binary, it should involve some level of fuzziness and imperfection, similar to the senses of living organisms. For instance, the bot should be able to express uncertainty by saying, “I didn’t hear you.”</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.I1.i3.p1.1.1">Memory</em>. In the article “Do Non-Player Characters Dream of Electric Sheep?” <cite class="ltx_cite ltx_citemacro_cite">Johansson (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib21" title="">2013</a>)</cite>, the author emphasizes memory functions as a crucial component for creating believable NPCs. Designing a memory system that encompasses prioritization of information, realistic forgetting, and loss of detail while retaining key facts presents significant challenges. These aspects must be managed without undermining the goal-oriented performance of AI players, a recurring theme in this section.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.I1.i4.p1.1.1">Cognitive Load and Ability to Multitask</em>. In real-time video games, especially strategic ones, AI players often display less strategic reasoning than humans. However, they compensate by being able to oversee the entire map and control numerous units at once, which would be overwhelming and physically impossible for human players. Simulating realistic constraints related to attention focus and multitasking poses multiple challenges: determining appropriate game-specific limits, deciding which aspects of the game the AI should focus on, and the fact that imposing such constraints might diminish the AI’s effectiveness. Creating competent bots that operate on consumer-level hardware remains a significant challenge.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i5.p1">
<p class="ltx_p" id="S2.I1.i5.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.I1.i5.p1.1.1">Reaction Time</em>. Reaction time serves as another biological constraint. In video games, AI players frequently benefit from seemingly unlimited reaction times, a key feature distinguishing bots from human players <cite class="ltx_cite ltx_citemacro_cite">Mańdziuk and Szałaj (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib30" title="">2012</a>)</cite>. There have been propositions to limit the reaction time and action rate of AI players, as seen in <cite class="ltx_cite ltx_citemacro_cite">Vinyals et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib53" title="">2019</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i6.p1">
<p class="ltx_p" id="S2.I1.i6.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.I1.i6.p1.1.1">Other Constraints</em>. The article titled “Video Game Agents with Human-like Behavior using the Deep Q-Network and Biological Constraints” <cite class="ltx_cite ltx_citemacro_cite">Morita and Hosobe (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib37" title="">2023</a>)</cite> introduces additional constraints such as “confusion” (experienced when suddenly surrounded by many enemies), “fluctuation” (errors in operation), “delay” (akin to reaction time), and “tiredness”.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S2.p15">
<p class="ltx_p" id="S2.p15.1"><span class="ltx_text ltx_font_bold" id="S2.p15.1.1">Emotional Element.</span> The authors of <cite class="ltx_cite ltx_citemacro_cite">Elsayed and King (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib13" title="">2017</a>)</cite> wrote:</p>
</div>
<div class="ltx_para" id="S2.p16">
<blockquote class="ltx_quote" id="S2.p16.1">
<p class="ltx_p" id="S2.p16.1.1">“<span class="ltx_text ltx_font_italic" id="S2.p16.1.1.1">Problems of NPCs usually lie in their lack of convincing
social and emotional behaviour raising the need for a robust
affect module within the agent’s architecture. Developing an
integrated architecture would ideally require developing
models for the theory of emotion, social relation, and
behaviour, and combining the theories into an overall model.</span>”</p>
</blockquote>
<p class="ltx_p" id="S2.p16.2">In <cite class="ltx_cite ltx_citemacro_cite">Lee and Heeter (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib27" title="">2012</a>)</cite>, emotions are listed as one of the most critical qualities of believable bots, ranking just after goals. The authors of <cite class="ltx_cite ltx_citemacro_cite">Bogdanovych et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib6" title="">2016</a>)</cite> identify emotions as one of the seven believability characteristics, alongside personality, self-motivation, change, social relationships, consistency of expression, and illusion of life.</p>
</div>
<div class="ltx_para" id="S2.p17">
<p class="ltx_p" id="S2.p17.1">Emotions have been extensively studied in psychological research <cite class="ltx_cite ltx_citemacro_cite">Izard (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib20" title="">2013</a>)</cite>. However, there are currently no established computational models to accurately simulate emotions in video games, making this issue particularly challenging. There are many facets to emotions in games. An emotional response may lead to changes in a player’s behavior following specific in-game events. The next example will be from the game <em class="ltx_emph ltx_font_italic" id="S2.p17.1.1">Tactical Troops: Anthracite Shift</em>, discussed in a study in the next section of this article. In this game, a player wins after eliminating all enemy units. We observed a scenario where an AI-controlled player had two units remaining, and the opposing player had only one. One of the AI’s units had a clear shot at the enemy but was blocked by another friendly unit. The AI chose to fire anyway, eliminating both the friendly and the enemy unit, thus securing a win. This behavior, while effective, is rarely observed in games played by humans, who typically avoid harming their own units.</p>
</div>
<div class="ltx_para" id="S2.p18">
<p class="ltx_p" id="S2.p18.1">Another aspect of emotional display in gaming is the anger or “tilt” effect <cite class="ltx_cite ltx_citemacro_cite">Wu et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib58" title="">2021</a>)</cite>, which refers to a state of emotional frustration or upset that negatively impacts a player’s performance. This phenomenon occurs when players become agitated due to a series of losses, perceived unfairness, or other in-game setbacks, leading to increasingly poor decision-making and potentially aggressive behavior. The term “tilt” originates from poker but has become widely used across various competitive gaming genres.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p19">
<p class="ltx_p" id="S2.p19.1"><span class="ltx_text ltx_font_bold" id="S2.p19.1.1">Handling Uncertainty</span>. Uncertainty in games typically involves hidden information (asymmetric information between the players), randomness, or both. This already poses significant challenges for creating agents aimed at achieving effective play because it results in a combinatorial explosion of potential game states. In research related to game AI, this issue is generally addressed using determinization techniques <cite class="ltx_cite ltx_citemacro_cite">Cowling et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib11" title="">2012b</a>)</cite> and by replacing perfect information game states with information sets <cite class="ltx_cite ltx_citemacro_cite">Cowling et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib10" title="">2012a</a>)</cite>. In the video game industry, the amount of hidden information is often so vast that AI characters are usually given unfair access to it, albeit with some techniques implemented to make this less apparent <cite class="ltx_cite ltx_citemacro_cite">Lidén (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib28" title="">2003</a>)</cite>. For example, in real-time strategy (RTS) games, most of the map is concealed from the players by the so-called “fog of war.” Players can send units to anywhere on the map to scout and reveal the covered areas. AI players, however, are typically given hints about a few potential locations of the human player’s base, including the correct one, thereby reducing the amount of scouting required. The same applies to information about the resources and military capabilities the human player possesses.</p>
</div>
<div class="ltx_para" id="S2.p20">
<p class="ltx_p" id="S2.p20.1">Uncertainty introduces an additional layer of challenge when designing human-like bots. If bots perform too efficiently, for instance, by employing complex probability estimations, they might be perceived by human players as cheating AI <cite class="ltx_cite ltx_citemacro_cite">Laird (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib25" title="">2002</a>)</cite>, even if this is not the case. To counteract this, a solution is to integrate a human-like reasoning process for inferring hidden information <cite class="ltx_cite ltx_citemacro_cite">Marques et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib31" title="">2013</a>)</cite>. However, this approach is computationally intensive and requires significant trade-offs in terms of playing efficacy.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p21">
<p class="ltx_p" id="S2.p21.1"><span class="ltx_text ltx_font_bold" id="S2.p21.1.1">Adaptability.</span> The article <cite class="ltx_cite ltx_citemacro_cite">Livingstone (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib29" title="">2006</a>)</cite> hypothesizes that AI in commercial games is often exploitable due to its tendency to follow repetitive patterns, thereby allowing human players to recognize and adapt to these behaviors. Meanwhile, the authors of <cite class="ltx_cite ltx_citemacro_cite">Bryant and Miikkulainen (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib7" title="">2006</a>)</cite> assert that “adding some unpredictability can significantly enhance believability,” and the authors of <cite class="ltx_cite ltx_citemacro_cite">Soni and Hingston (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib47" title="">2008</a>)</cite> demonstrate a strong correlation between unpredictability and human-like behavior.</p>
</div>
<div class="ltx_para" id="S2.p22">
<p class="ltx_p" id="S2.p22.6">In <cite class="ltx_cite ltx_citemacro_cite">Arzate Cruz and Ramirez Uresti (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib3" title="">2018</a>)</cite>, the authors identify “adaptation” to the opponent’s style as one of the two primary challenges in developing human-like AI for the <em class="ltx_emph ltx_font_italic" id="S2.p22.6.1">Street Fighter IV</em> game. The other challenge they outline is exploring a high-dimensional state-action space. To address this, they implemented real-time reward transformations within their reinforcement learning framework. This strategy involved dynamically altering the reward definitions based on the performance of various playing styles. As a result, they achieved a human-likeness score of <math alttext="0.64" class="ltx_Math" display="inline" id="S2.p22.1.m1.1"><semantics id="S2.p22.1.m1.1a"><mn id="S2.p22.1.m1.1.1" xref="S2.p22.1.m1.1.1.cmml">0.64</mn><annotation-xml encoding="MathML-Content" id="S2.p22.1.m1.1b"><cn id="S2.p22.1.m1.1.1.cmml" type="float" xref="S2.p22.1.m1.1.1">0.64</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p22.1.m1.1c">0.64</annotation><annotation encoding="application/x-llamapun" id="S2.p22.1.m1.1d">0.64</annotation></semantics></math> on a scale from <math alttext="0" class="ltx_Math" display="inline" id="S2.p22.2.m2.1"><semantics id="S2.p22.2.m2.1a"><mn id="S2.p22.2.m2.1.1" xref="S2.p22.2.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S2.p22.2.m2.1b"><cn id="S2.p22.2.m2.1.1.cmml" type="integer" xref="S2.p22.2.m2.1.1">0</cn></annotation-xml></semantics></math> to <math alttext="1" class="ltx_Math" display="inline" id="S2.p22.3.m3.1"><semantics id="S2.p22.3.m3.1a"><mn id="S2.p22.3.m3.1.1" xref="S2.p22.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.p22.3.m3.1b"><cn id="S2.p22.3.m3.1.1.cmml" type="integer" xref="S2.p22.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p22.3.m3.1c">1</annotation><annotation encoding="application/x-llamapun" id="S2.p22.3.m3.1d">1</annotation></semantics></math>, slightly less than the top score of <math alttext="0.67" class="ltx_Math" display="inline" id="S2.p22.4.m4.1"><semantics id="S2.p22.4.m4.1a"><mn id="S2.p22.4.m4.1.1" xref="S2.p22.4.m4.1.1.cmml">0.67</mn><annotation-xml encoding="MathML-Content" id="S2.p22.4.m4.1b"><cn id="S2.p22.4.m4.1.1.cmml" type="float" xref="S2.p22.4.m4.1.1">0.67</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p22.4.m4.1c">0.67</annotation><annotation encoding="application/x-llamapun" id="S2.p22.4.m4.1d">0.67</annotation></semantics></math> achieved by a human player, significantly surpassing the baseline bots, which scored between <math alttext="0.28" class="ltx_Math" display="inline" id="S2.p22.5.m5.1"><semantics id="S2.p22.5.m5.1a"><mn id="S2.p22.5.m5.1.1" xref="S2.p22.5.m5.1.1.cmml">0.28</mn><annotation-xml encoding="MathML-Content" id="S2.p22.5.m5.1b"><cn id="S2.p22.5.m5.1.1.cmml" type="float" xref="S2.p22.5.m5.1.1">0.28</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p22.5.m5.1c">0.28</annotation><annotation encoding="application/x-llamapun" id="S2.p22.5.m5.1d">0.28</annotation></semantics></math> and <math alttext="0.30" class="ltx_Math" display="inline" id="S2.p22.6.m6.1"><semantics id="S2.p22.6.m6.1a"><mn id="S2.p22.6.m6.1.1" xref="S2.p22.6.m6.1.1.cmml">0.30</mn><annotation-xml encoding="MathML-Content" id="S2.p22.6.m6.1b"><cn id="S2.p22.6.m6.1.1.cmml" type="float" xref="S2.p22.6.m6.1.1">0.30</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p22.6.m6.1c">0.30</annotation><annotation encoding="application/x-llamapun" id="S2.p22.6.m6.1d">0.30</annotation></semantics></math>.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p23">
<p class="ltx_p" id="S2.p23.1"><span class="ltx_text ltx_font_bold" id="S2.p23.1.1">Making Mistakes.</span> The analysis of literature related to the creation and evaluation of human-like AI underscores that human players indeed make mistakes. As noted by the authors of <cite class="ltx_cite ltx_citemacro_cite">Elsayed and King (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib13" title="">2017</a>)</cite>:</p>
<blockquote class="ltx_quote" id="S2.p23.2">
<p class="ltx_p" id="S2.p23.2.1">“<span class="ltx_text ltx_font_italic" id="S2.p23.2.1.1">An intelligent agent model should not require producing a
“perfect” agent, but rather, for better human resemblance and
higher believability, it is more natural to have the flaws and
dysfunctionalities of the human affect phenomena
incorporated into the model.</span>”</p>
</blockquote>
</div>
<div class="ltx_para" id="S2.p24">
<p class="ltx_p" id="S2.p24.1">However, humans learn, and there is significantly less likelihood of repeating the same mistakes. In the <em class="ltx_emph ltx_font_italic" id="S2.p24.1.1">UT2004</em> competition, bots that repeated the same mistakes consistently were quickly judged as non-human-like <cite class="ltx_cite ltx_citemacro_cite">Schrum et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib44" title="">2012</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p25">
<p class="ltx_p" id="S2.p25.1">Implementing both the inclusion of mistakes and learning from them is challenging. Mistakes can emerge unintentionally without being explicitly programmed into bots, but these unintentional errors can be challenging to identify and incorporate with adaptation mechanisms. In addition, they can be of artificial nature such as bots getting stuck in level geometry <cite class="ltx_cite ltx_citemacro_cite">Schrum et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib44" title="">2012</a>)</cite>, which was a telling factor for judges responsible for the video game <em class="ltx_emph ltx_font_italic" id="S2.p25.1.1">Turing Test</em> in <em class="ltx_emph ltx_font_italic" id="S2.p25.1.2">UT2004</em>. Deciding which aspects of gameplay should intentionally involve mistakes in a believable manner remains a significant challenge.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p26">
<p class="ltx_p" id="S2.p26.1"><span class="ltx_text ltx_font_bold" id="S2.p26.1.1">Training Human-Like AI.</span> One of the most promising approaches to creating human-like AI agents is training them using machine learning methods (ML). When the objective is to develop the strongest agent possible, training can be conducted using reinforcement learning without human knowledge <cite class="ltx_cite ltx_citemacro_cite">Silver et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib46" title="">2017</a>); Wang et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib54" title="">2009</a>)</cite>. In this setup, agents compete against different versions of themselves, continually refining their skills. However, when aiming for human-likeness or believability, training – whether supervised or through reinforcement – using human games becomes a more suitable approach <cite class="ltx_cite ltx_citemacro_cite">Arzate Cruz and Ramirez Uresti (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib3" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p27">
<p class="ltx_p" id="S2.p27.1">Training believable agents from human data presents many of the already mentioned challenges:</p>
<ul class="ltx_itemize" id="S2.I2">
<li class="ltx_item" id="S2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I2.i1.p1">
<p class="ltx_p" id="S2.I2.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S2.I2.i1.p1.1.1">Humans are diverse</span>. Training can utilize games played by either a specific group of players or the general population. In the latter case, the resultant behavior will likely be an average.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I2.i2.p1">
<p class="ltx_p" id="S2.I2.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S2.I2.i2.p1.1.1">High computational demand</span>. Vast action spaces, especially in reinforcement learning, are known for their sample inefficiency and consequent computational expense <cite class="ltx_cite ltx_citemacro_cite">Hessel et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib18" title="">2018</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I2.i3.p1">
<p class="ltx_p" id="S2.I2.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S2.I2.i3.p1.1.1">The effect of scale</span>. The trained model must be inferred as often as there are intelligent agents in the environment. However, modern GPU-based ML models facilitate batch processing.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.p28">
<p class="ltx_p" id="S2.p28.1">Additional challenges specific to training include:</p>
<ul class="ltx_itemize" id="S2.I3">
<li class="ltx_item" id="S2.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I3.i1.p1">
<p class="ltx_p" id="S2.I3.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S2.I3.i1.p1.1.1">Large volumes of training data are required</span>. This data is usually not available for games at the time of development. As the game has not yet been released, the only data available typically comes from developers and testers playing it, which is insufficient for large-scale training.</p>
</div>
</li>
<li class="ltx_item" id="S2.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I3.i2.p1">
<p class="ltx_p" id="S2.I3.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S2.I3.i2.p1.1.1">Human-Like Control Input</span>. In video game development, AI systems typically process inputs differently from human players, which poses a fundamental challenge in creating believable behaviors. Humans use controllers such as: keyboard, mouse, game-pads (including analog joysticks), steering wheels, etc. Using a controller involves atomic actions, e.g., pressing a key or applying a force in one or more of the controller axes. The observable in-game behaviors emerge from sequences of these inputs, adding complexity to the input space. In contrast, AI in games is usually programmed to perform high-level behaviors like ”move to point X”, ”attack enemy Y”, or ”flee”, which operate on a more abstract level than direct input actions.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S2.p29">
<p class="ltx_p" id="S2.p29.1"><span class="ltx_text ltx_font_bold" id="S2.p29.1.1">Simulating Social Norms.</span> In the literature related to human-like AI agents, the simulation of social norms is frequently highlighted as an important factor for enhancing believability <cite class="ltx_cite ltx_citemacro_cite">Johansson (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib21" title="">2013</a>); Weiss and Tscheligi (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib57" title="">2012</a>); Warpefelt et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib55" title="">2013</a>)</cite>. In <cite class="ltx_cite ltx_citemacro_cite">Johansson (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib21" title="">2013</a>)</cite>, the term “socially believable” is used to describe agents that effectively cooperate and coordinate within a group. The authors in <cite class="ltx_cite ltx_citemacro_cite">Weiss and Tscheligi (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib57" title="">2012</a>)</cite> enumerate several social cues essential for believable agents, including: reflexivity, grouping, attachment, reciprocity, and the ability to attribute mental (intentional) states to oneself and to others.</p>
</div>
<div class="ltx_para" id="S2.p30">
<p class="ltx_p" id="S2.p30.1">In <cite class="ltx_cite ltx_citemacro_cite">Warpefelt et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib55" title="">2013</a>)</cite>, the concept of a <em class="ltx_emph ltx_font_italic" id="S2.p30.1.1">Game Agent Matrix</em> is introduced. This matrix includes columns labeled <em class="ltx_emph ltx_font_italic" id="S2.p30.1.2">single agent</em>, <em class="ltx_emph ltx_font_italic" id="S2.p30.1.3">multiple agents</em>, <em class="ltx_emph ltx_font_italic" id="S2.p30.1.4">social structural</em>, <em class="ltx_emph ltx_font_italic" id="S2.p30.1.5">social goals</em>, and <em class="ltx_emph ltx_font_italic" id="S2.p30.1.6">cultural historical</em>, and rows labeled <em class="ltx_emph ltx_font_italic" id="S2.p30.1.7">act</em>, <em class="ltx_emph ltx_font_italic" id="S2.p30.1.8">react</em>, and <em class="ltx_emph ltx_font_italic" id="S2.p30.1.9">interact</em>. The matrix cells incorporate concepts such as <em class="ltx_emph ltx_font_italic" id="S2.p30.1.10">awareness</em>. The study evaluated many games, finding that numerous concepts, particularly those related to social structural and social goals, were underrepresented. The authors emphasized:</p>
<blockquote class="ltx_quote" id="S2.p30.2">
<p class="ltx_p" id="S2.p30.2.1">“<span class="ltx_text ltx_font_italic" id="S2.p30.2.1.1">NPCs need to exhibit behavior consistent with the environment,
the situation and their character in order to seem believable.</span>”</p>
</blockquote>
</div>
<div class="ltx_para" id="S2.p31">
<p class="ltx_p" id="S2.p31.1">Incorporating social norms into video games presents substantial challenges. A notable example is <em class="ltx_emph ltx_font_italic" id="S2.p31.1.1">The Elder Scrolls IV: Oblivion</em>, developed by <em class="ltx_emph ltx_font_italic" id="S2.p31.1.2">Bethesda Software</em>. In this game, despite the social norm against stealing, players can exploit a loophole by placing a basket over a shopkeeper’s head, preventing them from noticing thefts. This is an interesting attempt at introducing realistic perception mechanics, yet it lacks a robust implementation of social norms.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p32">
<p class="ltx_p" id="S2.p32.1"><span class="ltx_text ltx_font_bold" id="S2.p32.1.1">Specific Human-Like Activities in the Game.</span> Let us conclude this section with the observation that games (or virtual environments in general) are highly diverse and open-ended. They may include any aspect of real-world activities, such as conversing in natural language or driving. All such in-game activities can be assessed for their human-likeness <cite class="ltx_cite ltx_citemacro_cite">Hecker et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib17" title="">2020</a>)</cite>. On one hand, this diversity makes the task of creating general solutions for testing AI believability very challenging. An AI-based <em class="ltx_emph ltx_font_italic" id="S2.p32.1.2">Turing Test</em> judge should either be customized for a specific activity or capable of evaluating every task humans perform. On the other hand, these specific in-game activities could make it easier for human judges to distinguish between humans and bots. Even if bots are competent and believable in core gameplay, they might fail at some specific tasks, such as engaging in natural conversation or driving on streets.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Experiment Environment</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The rest of this article is dedicated to a study concerning the problem of believable bots – their distinction from human players and evaluation of their human-likeness ratio in a team-based tactical commandos-style game. The game chosen for this study is <em class="ltx_emph ltx_font_italic" id="S3.p1.1.1">Tactical Troops: Anthracite Shift</em> <cite class="ltx_cite ltx_citemacro_cite">Świechowski et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib50" title="">2021</a>)</cite> (depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S3.F1" title="Figure 1 ‣ 3. Experiment Environment ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_tag">1</span></a>), which is available on the <em class="ltx_emph ltx_font_italic" id="S3.p1.1.2">Steam</em> platform<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://store.steampowered.com/</span></span></span>.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">In <em class="ltx_emph ltx_font_italic" id="S3.p2.1.1">Tactical Troops: Anthracite Shift</em>, each game is played on a 2D map viewed from above. Two players alternate turns, each commanding up to four units. Units are eliminated when they lose all their health points (HP). Unlike many turn-based games, movement is continuous rather than grid-based. The maximum distance a unit can move is determined by its action points (AP), which are also used for performing actions. For example, the larger circle in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S3.F1" title="Figure 1 ‣ 3. Experiment Environment ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the maximum movement range in a single turn, whereas the smaller (inner) circle indicates the range within which a unit can move and still fire its current weapon.</p>
</div>
<figure class="ltx_figure" id="S3.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="240" id="S3.F1.g1" src="extracted/6480023/Figures/tt-movement.png" width="334"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Movement range in Tactical Troops: Anthracite Shift.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S3.F1.1">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S3.F1.2">The image shows a top-down view of a Tactical Troops video game map. In the top-left corner, there are portraits representing the player’s available units, each displaying three statistics as progress bars: current armor, health, and action points. In the top-right corner, a timer indicates the remaining time for the player’s turn. The map itself has two distinct terrain types: the left side consists of dirt ground, while the right side features a large asphalt parking lot with several vehicles.
Three units belonging to the player stand on the parking lot, with one of them currently selected. Around the selected unit, two circular indicators are visible. The smaller circle represents the area where the unit can move while still being able to fire its currently selected weapon, while the larger circle shows the unit’s maximum movement range.
Scattered across the map are various interactive and environmental elements. There are two small areas marked as control points, labeled with the numbers “1” and “2”. Additionally, two pairs of teleporters are present, allowing for rapid movement across different parts of the map. Exploding barrels can also be seen in the bottom-right portion of the map.</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">Units can perform actions in any sequence. Considering the main focus of this article, which is the assessment of human-likeness, it is essential to discuss the potential actions each unit can undertake:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">Movement</span>: Effective movement is crucial as the map’s dynamic environments feature buildings for cover, strategic hiding spots, explosive elements, and teleporters that allow for rapid relocation between a designated pair of positions.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Shooting</span>: Each unit is equipped with two weapons from a selection of over 30 types. The shooting action includes choosing a weapon, selecting a shooting mode (single or burst), and positioning accurately (units shoot in the direction they face).</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">Reloading</span> weapons.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">Using gadgets</span>: Units carry up to three gadgets, which can be throwable (e.g., grenades, mines) or togglable (e.g., cloaks, shields, and armors). Using throwable gadgets effectively requires careful consideration of positioning and the force applied.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(5)</span>
<div class="ltx_para" id="S3.I1.i5.p1">
<p class="ltx_p" id="S3.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i5.p1.1.1">Overwatch</span>: This stance transforms a unit into a stationary defense that automatically fires at the first enemy unit entering its range during the opponent’s turn.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">The game features two alternative victory conditions:</p>
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">Elimination</span>: Defeat all enemy units.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.1">Domination</span> or <span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.2">Devastation</span>: In Domination, a player wins by controlling the majority of designated areas (control points) on the map for an entire turn. Usually, a map contains three control points, and controlling at least two is necessary for victory. Devastation involves the destruction of specific stationary objects on the map. While the Elimination condition is always applicable, Domination and Devastation modes are exclusive to specific maps. Introducing these modes aims to discourage defensive play (“camping”) and promote more dynamic interactions.</p>
</div>
</li>
</ol>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Method Behind AI Agents</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">For a comprehensive explanation of the AI player’s methodology in <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.1">Tactical Troops: Anthracite Shift</em>, please refer to <cite class="ltx_cite ltx_citemacro_cite">Świechowski et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib50" title="">2021</a>)</cite>. This method involves a hybrid approach combining Utility AI <cite class="ltx_cite ltx_citemacro_cite">Rabin (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib40" title="">2013</a>)</cite> and Monte Carlo Tree Search (MCTS) <cite class="ltx_cite ltx_citemacro_cite">Świechowski et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib49" title="">2023</a>)</cite>, which are integrated through a blackboard architecture. The Utility AI component handles the strategic layer at a high level. It evaluates and assigns one of six possible orders to each controlled unit, where some orders may include parameters like assaulting or defending a specific point of interest. The utility value of each order is determined by a real-valued numerical score, derived from 10 different considerations (factors). Orders are assigned to units on a greedy basis, meaning that the first unit to receive an order is the one with the globally maximum among each unit’s highest scored orders. Assigning an order triggers a recalculation of scores for all other units.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">The MCTS algorithm acts as the tactical layer, employing a simplified model of the game. The execution quality of a strategic order is used as a heuristic evaluation function in MCTS, which allows for early termination of simulations. To manage the complexity and avoid combinatorial explosion, the sequence in which units are simulated by MCTS is heuristically determined at each turn. MCTS is allocated a budget of approximately <math alttext="30,000" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.2"><semantics id="S3.SS1.p2.1.m1.2a"><mrow id="S3.SS1.p2.1.m1.2.3.2" xref="S3.SS1.p2.1.m1.2.3.1.cmml"><mn id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">30</mn><mo id="S3.SS1.p2.1.m1.2.3.2.1" xref="S3.SS1.p2.1.m1.2.3.1.cmml">,</mo><mn id="S3.SS1.p2.1.m1.2.2" xref="S3.SS1.p2.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.2b"><list id="S3.SS1.p2.1.m1.2.3.1.cmml" xref="S3.SS1.p2.1.m1.2.3.2"><cn id="S3.SS1.p2.1.m1.1.1.cmml" type="integer" xref="S3.SS1.p2.1.m1.1.1">30</cn><cn id="S3.SS1.p2.1.m1.2.2.cmml" type="integer" xref="S3.SS1.p2.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.2c">30,000</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.2d">30 , 000</annotation></semantics></math> iterations per turn.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Method Behind Human-Likeness Evaluation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.2">In an initial study <cite class="ltx_cite ltx_citemacro_cite">Świechowski et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib50" title="">2021</a>)</cite>, an XGBoost model utilizing 20 summary features per match was trained to differentiate human players from bots. It achieved an accuracy of <math alttext="0.68" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">0.68</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn id="S4.p1.1.m1.1.1.cmml" type="float" xref="S4.p1.1.m1.1.1">0.68</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">0.68</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">0.68</annotation></semantics></math> and an F1-score of <math alttext="0.58" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">0.58</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn id="S4.p1.2.m2.1.1.cmml" type="float" xref="S4.p1.2.m2.1.1">0.58</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">0.58</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">0.58</annotation></semantics></math>. This model was developed using 800 matches and evaluated on an independent set of 200 matches.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">In this study, we present a more sophisticated approach using a hybrid deep neural network that combines convolutional (CNN) and recurrent (RNN) subnetworks. The purpose of the CNN component is to extract features from 2D images, while the RNN component is dedicated to processing summarized data and detecting dependencies within it. The full architecture of the solution is presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S4.F2" title="Figure 2 ‣ 4. Method Behind Human-Likeness Evaluation ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="748" id="S4.F2.g1" src="extracted/6480023/Figures/model.png" width="388"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Neural Network architecture for the problem.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S4.F2.1">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F2.2">The picture represents a diagram of a neural network machine learning model.
The diagram consists of boxes and arrows that illustrate the data flow.
It will be described from the top (input layer) to the bottom (output layer).</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F2.3">The input layer contains two boxes:
(A) Spatial data with dimensions [250, 256, 256, 6], where the last index denotes six different maps.
(B) Flattened scalar features of size [250, 20] for the last 250 states.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F2.4">The input is connected to a TimeDistributed layer (also referred to as the temporal loop), which repeats the following pattern:
SpatialInput -¿ Conv2D -¿ MaxPooling2D -¿ BatchNormalization -¿ Conv2D -¿ MaxPooling2D -¿ BatchNormalization -¿ Flatten -¿ Concatenate (with the Flattened Scalar Features input) -¿ Dense Layer -¿ Dropout.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F2.5">The output from the TimeDistributed layer is subsequently connected to the following components in sequence:
LSTM -¿ Dense Layer -¿ Dense Layer -¿ Output.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F2.6">The output represents the probability that the first player encoded in the scalar features in the input is human.</p>
</div>
</div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">We will now give an overview of the input.</p>
</div>
<div class="ltx_para" id="S4.p4">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.I1.i1.p1.1.1">Input_1</em>: graphical (pixel) representation of the map. It involves 6 different layers (submaps): obstacles (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S4.F3" title="Figure 3 ‣ 1st item ‣ 4. Method Behind Human-Likeness Evaluation ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_tag">3</span></a>), rooftops, teleports (that influence movement capabilities), control points, friendly units with health (the health values are normalized and represented as a color saturation), enemy units with health values. The last two maps are generated dynamically, based on the current state of the game (in the current time).</p>
</div>
<figure class="ltx_figure" id="S4.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="230" id="S4.F3.g1" src="extracted/6480023/Figures/obstacle_map.png" width="220"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>A map of obstacles. One of the six input layers to the spatial component of the neural network. The map of obstacles is crucial because the shapes and positions of obstacles affect lines of sight and lines of fire for the units. Obstacles play a key role in unit placement such as finding hiding spots and avoiding exposure or finding good places to hunt other units. Therefore, they are essential from the perspective of making intelligent positioning decisions.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S4.F3.1">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F3.2">A top-down view of the entire level, rendered in a special way to represent a map of obstacles - an idea similar to a mask. The original pixel colors are replaced with either very dark (near-black) or very light (near-white) shades. Light-colored pixels indicate obstacles, representing areas that cannot be moved into or shot through. In this specific map, three relatively large obstacles (train wagons) are positioned in the middle. On the right, two large rock formations serve as additional barriers. Throughout the level, there are also numerous smaller obstacles, such as trees and walls. The background contrasts with these obstacles with dark shades.</p>
</div>
</div>
</figure>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.I1.i2.p1.1.1">Input_2</em>: vector representation of 10 x 2 (for both players) numerical features that compute certain values until the current time <math alttext="t" class="ltx_Math" display="inline" id="S4.I1.i2.p1.1.m1.1"><semantics id="S4.I1.i2.p1.1.m1.1a"><mi id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.1b"><ci id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i2.p1.1.m1.1d">italic_t</annotation></semantics></math>. These values are: turn number, damage dealt and received, friendly-fire damage, friendly-fire to total damage ratio, # of used grenades, damage dealt using grenades to total damage, # of used gadgets, # of units’ status changes.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.I1.i3.p1.1.1">Input_3 and Input_4</em>: recurrent neural layers for the spatial and numerical representations, respectively. To properly capture the dynamics of game-play, the input data is passed to the network repeatedly as a sequence of the last 250 states of the game. If a particular game is shorter, then the missing inputs are replaced by zeroes.</p>
</div>
</li>
</ul>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Results</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">To evaluate the efficacy of the model, we used 5-fold cross validation on the
set of available game logs. The results are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S4.T1" title="Table 1 ‣ 4.1. Results ‣ 4. Method Behind Human-Likeness Evaluation ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.5">Let the possible classes be <math alttext="\left\{Human,Bot\right\}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.2"><semantics id="S4.SS1.p2.1.m1.2a"><mrow id="S4.SS1.p2.1.m1.2.2.2" xref="S4.SS1.p2.1.m1.2.2.3.cmml"><mo id="S4.SS1.p2.1.m1.2.2.2.3" xref="S4.SS1.p2.1.m1.2.2.3.cmml">{</mo><mrow id="S4.SS1.p2.1.m1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.1.1.2.cmml">H</mi><mo id="S4.SS1.p2.1.m1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p2.1.m1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.3.cmml">u</mi><mo id="S4.SS1.p2.1.m1.1.1.1.1.1a" xref="S4.SS1.p2.1.m1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p2.1.m1.1.1.1.1.4" xref="S4.SS1.p2.1.m1.1.1.1.1.4.cmml">m</mi><mo id="S4.SS1.p2.1.m1.1.1.1.1.1b" xref="S4.SS1.p2.1.m1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p2.1.m1.1.1.1.1.5" xref="S4.SS1.p2.1.m1.1.1.1.1.5.cmml">a</mi><mo id="S4.SS1.p2.1.m1.1.1.1.1.1c" xref="S4.SS1.p2.1.m1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p2.1.m1.1.1.1.1.6" xref="S4.SS1.p2.1.m1.1.1.1.1.6.cmml">n</mi></mrow><mo id="S4.SS1.p2.1.m1.2.2.2.4" xref="S4.SS1.p2.1.m1.2.2.3.cmml">,</mo><mrow id="S4.SS1.p2.1.m1.2.2.2.2" xref="S4.SS1.p2.1.m1.2.2.2.2.cmml"><mi id="S4.SS1.p2.1.m1.2.2.2.2.2" xref="S4.SS1.p2.1.m1.2.2.2.2.2.cmml">B</mi><mo id="S4.SS1.p2.1.m1.2.2.2.2.1" xref="S4.SS1.p2.1.m1.2.2.2.2.1.cmml">⁢</mo><mi id="S4.SS1.p2.1.m1.2.2.2.2.3" xref="S4.SS1.p2.1.m1.2.2.2.2.3.cmml">o</mi><mo id="S4.SS1.p2.1.m1.2.2.2.2.1a" xref="S4.SS1.p2.1.m1.2.2.2.2.1.cmml">⁢</mo><mi id="S4.SS1.p2.1.m1.2.2.2.2.4" xref="S4.SS1.p2.1.m1.2.2.2.2.4.cmml">t</mi></mrow><mo id="S4.SS1.p2.1.m1.2.2.2.5" xref="S4.SS1.p2.1.m1.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.2b"><set id="S4.SS1.p2.1.m1.2.2.3.cmml" xref="S4.SS1.p2.1.m1.2.2.2"><apply id="S4.SS1.p2.1.m1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1"><times id="S4.SS1.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1"></times><ci id="S4.SS1.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.2">𝐻</ci><ci id="S4.SS1.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3">𝑢</ci><ci id="S4.SS1.p2.1.m1.1.1.1.1.4.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.4">𝑚</ci><ci id="S4.SS1.p2.1.m1.1.1.1.1.5.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.5">𝑎</ci><ci id="S4.SS1.p2.1.m1.1.1.1.1.6.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.6">𝑛</ci></apply><apply id="S4.SS1.p2.1.m1.2.2.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2"><times id="S4.SS1.p2.1.m1.2.2.2.2.1.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2.1"></times><ci id="S4.SS1.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2.2">𝐵</ci><ci id="S4.SS1.p2.1.m1.2.2.2.2.3.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2.3">𝑜</ci><ci id="S4.SS1.p2.1.m1.2.2.2.2.4.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2.4">𝑡</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.2c">\left\{Human,Bot\right\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.2d">{ italic_H italic_u italic_m italic_a italic_n , italic_B italic_o italic_t }</annotation></semantics></math>. Let <math alttext="TP_{Human}" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">T</mi><mo id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">⁢</mo><msub id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml"><mi id="S4.SS1.p2.2.m2.1.1.3.2" xref="S4.SS1.p2.2.m2.1.1.3.2.cmml">P</mi><mrow id="S4.SS1.p2.2.m2.1.1.3.3" xref="S4.SS1.p2.2.m2.1.1.3.3.cmml"><mi id="S4.SS1.p2.2.m2.1.1.3.3.2" xref="S4.SS1.p2.2.m2.1.1.3.3.2.cmml">H</mi><mo id="S4.SS1.p2.2.m2.1.1.3.3.1" xref="S4.SS1.p2.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p2.2.m2.1.1.3.3.3" xref="S4.SS1.p2.2.m2.1.1.3.3.3.cmml">u</mi><mo id="S4.SS1.p2.2.m2.1.1.3.3.1a" xref="S4.SS1.p2.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p2.2.m2.1.1.3.3.4" xref="S4.SS1.p2.2.m2.1.1.3.3.4.cmml">m</mi><mo id="S4.SS1.p2.2.m2.1.1.3.3.1b" xref="S4.SS1.p2.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p2.2.m2.1.1.3.3.5" xref="S4.SS1.p2.2.m2.1.1.3.3.5.cmml">a</mi><mo id="S4.SS1.p2.2.m2.1.1.3.3.1c" xref="S4.SS1.p2.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p2.2.m2.1.1.3.3.6" xref="S4.SS1.p2.2.m2.1.1.3.3.6.cmml">n</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><times id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1"></times><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">𝑇</ci><apply id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.1.1.3.1.cmml" xref="S4.SS1.p2.2.m2.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.2.m2.1.1.3.2.cmml" xref="S4.SS1.p2.2.m2.1.1.3.2">𝑃</ci><apply id="S4.SS1.p2.2.m2.1.1.3.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3.3"><times id="S4.SS1.p2.2.m2.1.1.3.3.1.cmml" xref="S4.SS1.p2.2.m2.1.1.3.3.1"></times><ci id="S4.SS1.p2.2.m2.1.1.3.3.2.cmml" xref="S4.SS1.p2.2.m2.1.1.3.3.2">𝐻</ci><ci id="S4.SS1.p2.2.m2.1.1.3.3.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3.3.3">𝑢</ci><ci id="S4.SS1.p2.2.m2.1.1.3.3.4.cmml" xref="S4.SS1.p2.2.m2.1.1.3.3.4">𝑚</ci><ci id="S4.SS1.p2.2.m2.1.1.3.3.5.cmml" xref="S4.SS1.p2.2.m2.1.1.3.3.5">𝑎</ci><ci id="S4.SS1.p2.2.m2.1.1.3.3.6.cmml" xref="S4.SS1.p2.2.m2.1.1.3.3.6">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">TP_{Human}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">italic_T italic_P start_POSTSUBSCRIPT italic_H italic_u italic_m italic_a italic_n end_POSTSUBSCRIPT</annotation></semantics></math> denote the number of true positives calculated for the human class. Analogously, <math alttext="TN_{X}" class="ltx_Math" display="inline" id="S4.SS1.p2.3.m3.1"><semantics id="S4.SS1.p2.3.m3.1a"><mrow id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">T</mi><mo id="S4.SS1.p2.3.m3.1.1.1" xref="S4.SS1.p2.3.m3.1.1.1.cmml">⁢</mo><msub id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml"><mi id="S4.SS1.p2.3.m3.1.1.3.2" xref="S4.SS1.p2.3.m3.1.1.3.2.cmml">N</mi><mi id="S4.SS1.p2.3.m3.1.1.3.3" xref="S4.SS1.p2.3.m3.1.1.3.3.cmml">X</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><times id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1.1"></times><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">𝑇</ci><apply id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.3.1.cmml" xref="S4.SS1.p2.3.m3.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.3.m3.1.1.3.2.cmml" xref="S4.SS1.p2.3.m3.1.1.3.2">𝑁</ci><ci id="S4.SS1.p2.3.m3.1.1.3.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3.3">𝑋</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">TN_{X}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.3.m3.1d">italic_T italic_N start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="TN_{X}" class="ltx_Math" display="inline" id="S4.SS1.p2.4.m4.1"><semantics id="S4.SS1.p2.4.m4.1a"><mrow id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml"><mi id="S4.SS1.p2.4.m4.1.1.2" xref="S4.SS1.p2.4.m4.1.1.2.cmml">T</mi><mo id="S4.SS1.p2.4.m4.1.1.1" xref="S4.SS1.p2.4.m4.1.1.1.cmml">⁢</mo><msub id="S4.SS1.p2.4.m4.1.1.3" xref="S4.SS1.p2.4.m4.1.1.3.cmml"><mi id="S4.SS1.p2.4.m4.1.1.3.2" xref="S4.SS1.p2.4.m4.1.1.3.2.cmml">N</mi><mi id="S4.SS1.p2.4.m4.1.1.3.3" xref="S4.SS1.p2.4.m4.1.1.3.3.cmml">X</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1"><times id="S4.SS1.p2.4.m4.1.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1.1"></times><ci id="S4.SS1.p2.4.m4.1.1.2.cmml" xref="S4.SS1.p2.4.m4.1.1.2">𝑇</ci><apply id="S4.SS1.p2.4.m4.1.1.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.4.m4.1.1.3.1.cmml" xref="S4.SS1.p2.4.m4.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.4.m4.1.1.3.2.cmml" xref="S4.SS1.p2.4.m4.1.1.3.2">𝑁</ci><ci id="S4.SS1.p2.4.m4.1.1.3.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3.3">𝑋</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">TN_{X}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.4.m4.1d">italic_T italic_N start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="TN_{X}" class="ltx_Math" display="inline" id="S4.SS1.p2.5.m5.1"><semantics id="S4.SS1.p2.5.m5.1a"><mrow id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml"><mi id="S4.SS1.p2.5.m5.1.1.2" xref="S4.SS1.p2.5.m5.1.1.2.cmml">T</mi><mo id="S4.SS1.p2.5.m5.1.1.1" xref="S4.SS1.p2.5.m5.1.1.1.cmml">⁢</mo><msub id="S4.SS1.p2.5.m5.1.1.3" xref="S4.SS1.p2.5.m5.1.1.3.cmml"><mi id="S4.SS1.p2.5.m5.1.1.3.2" xref="S4.SS1.p2.5.m5.1.1.3.2.cmml">N</mi><mi id="S4.SS1.p2.5.m5.1.1.3.3" xref="S4.SS1.p2.5.m5.1.1.3.3.cmml">X</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><apply id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1"><times id="S4.SS1.p2.5.m5.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1.1"></times><ci id="S4.SS1.p2.5.m5.1.1.2.cmml" xref="S4.SS1.p2.5.m5.1.1.2">𝑇</ci><apply id="S4.SS1.p2.5.m5.1.1.3.cmml" xref="S4.SS1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.5.m5.1.1.3.1.cmml" xref="S4.SS1.p2.5.m5.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.5.m5.1.1.3.2.cmml" xref="S4.SS1.p2.5.m5.1.1.3.2">𝑁</ci><ci id="S4.SS1.p2.5.m5.1.1.3.3.cmml" xref="S4.SS1.p2.5.m5.1.1.3.3">𝑋</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">TN_{X}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.5.m5.1d">italic_T italic_N start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT</annotation></semantics></math> denote true negatives, false positives, and false negatives.
In addition to Macro-F1 score defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Macro|F1=\frac{F1_{Human}+F1_{Bot}}{2}" class="ltx_Math" display="block" id="S4.E1.m1.1"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml"><mrow id="S4.E1.m1.1.1.2" xref="S4.E1.m1.1.1.2.cmml"><mrow id="S4.E1.m1.1.1.2.2" xref="S4.E1.m1.1.1.2.2.cmml"><mi id="S4.E1.m1.1.1.2.2.2" xref="S4.E1.m1.1.1.2.2.2.cmml">M</mi><mo id="S4.E1.m1.1.1.2.2.1" xref="S4.E1.m1.1.1.2.2.1.cmml">⁢</mo><mi id="S4.E1.m1.1.1.2.2.3" xref="S4.E1.m1.1.1.2.2.3.cmml">a</mi><mo id="S4.E1.m1.1.1.2.2.1a" xref="S4.E1.m1.1.1.2.2.1.cmml">⁢</mo><mi id="S4.E1.m1.1.1.2.2.4" xref="S4.E1.m1.1.1.2.2.4.cmml">c</mi><mo id="S4.E1.m1.1.1.2.2.1b" xref="S4.E1.m1.1.1.2.2.1.cmml">⁢</mo><mi id="S4.E1.m1.1.1.2.2.5" xref="S4.E1.m1.1.1.2.2.5.cmml">r</mi><mo id="S4.E1.m1.1.1.2.2.1c" xref="S4.E1.m1.1.1.2.2.1.cmml">⁢</mo><mi id="S4.E1.m1.1.1.2.2.6" xref="S4.E1.m1.1.1.2.2.6.cmml">o</mi></mrow><mo fence="false" id="S4.E1.m1.1.1.2.1" xref="S4.E1.m1.1.1.2.1.cmml">|</mo><mrow id="S4.E1.m1.1.1.2.3" xref="S4.E1.m1.1.1.2.3.cmml"><mi id="S4.E1.m1.1.1.2.3.2" xref="S4.E1.m1.1.1.2.3.2.cmml">F</mi><mo id="S4.E1.m1.1.1.2.3.1" xref="S4.E1.m1.1.1.2.3.1.cmml">⁢</mo><mn id="S4.E1.m1.1.1.2.3.3" xref="S4.E1.m1.1.1.2.3.3.cmml">1</mn></mrow></mrow><mo id="S4.E1.m1.1.1.1" xref="S4.E1.m1.1.1.1.cmml">=</mo><mfrac id="S4.E1.m1.1.1.3" xref="S4.E1.m1.1.1.3.cmml"><mrow id="S4.E1.m1.1.1.3.2" xref="S4.E1.m1.1.1.3.2.cmml"><mrow id="S4.E1.m1.1.1.3.2.2" xref="S4.E1.m1.1.1.3.2.2.cmml"><mi id="S4.E1.m1.1.1.3.2.2.2" xref="S4.E1.m1.1.1.3.2.2.2.cmml">F</mi><mo id="S4.E1.m1.1.1.3.2.2.1" xref="S4.E1.m1.1.1.3.2.2.1.cmml">⁢</mo><msub id="S4.E1.m1.1.1.3.2.2.3" xref="S4.E1.m1.1.1.3.2.2.3.cmml"><mn id="S4.E1.m1.1.1.3.2.2.3.2" xref="S4.E1.m1.1.1.3.2.2.3.2.cmml">1</mn><mrow id="S4.E1.m1.1.1.3.2.2.3.3" xref="S4.E1.m1.1.1.3.2.2.3.3.cmml"><mi id="S4.E1.m1.1.1.3.2.2.3.3.2" xref="S4.E1.m1.1.1.3.2.2.3.3.2.cmml">H</mi><mo id="S4.E1.m1.1.1.3.2.2.3.3.1" xref="S4.E1.m1.1.1.3.2.2.3.3.1.cmml">⁢</mo><mi id="S4.E1.m1.1.1.3.2.2.3.3.3" xref="S4.E1.m1.1.1.3.2.2.3.3.3.cmml">u</mi><mo id="S4.E1.m1.1.1.3.2.2.3.3.1a" xref="S4.E1.m1.1.1.3.2.2.3.3.1.cmml">⁢</mo><mi id="S4.E1.m1.1.1.3.2.2.3.3.4" xref="S4.E1.m1.1.1.3.2.2.3.3.4.cmml">m</mi><mo id="S4.E1.m1.1.1.3.2.2.3.3.1b" xref="S4.E1.m1.1.1.3.2.2.3.3.1.cmml">⁢</mo><mi id="S4.E1.m1.1.1.3.2.2.3.3.5" xref="S4.E1.m1.1.1.3.2.2.3.3.5.cmml">a</mi><mo id="S4.E1.m1.1.1.3.2.2.3.3.1c" xref="S4.E1.m1.1.1.3.2.2.3.3.1.cmml">⁢</mo><mi id="S4.E1.m1.1.1.3.2.2.3.3.6" xref="S4.E1.m1.1.1.3.2.2.3.3.6.cmml">n</mi></mrow></msub></mrow><mo id="S4.E1.m1.1.1.3.2.1" xref="S4.E1.m1.1.1.3.2.1.cmml">+</mo><mrow id="S4.E1.m1.1.1.3.2.3" xref="S4.E1.m1.1.1.3.2.3.cmml"><mi id="S4.E1.m1.1.1.3.2.3.2" xref="S4.E1.m1.1.1.3.2.3.2.cmml">F</mi><mo id="S4.E1.m1.1.1.3.2.3.1" xref="S4.E1.m1.1.1.3.2.3.1.cmml">⁢</mo><msub id="S4.E1.m1.1.1.3.2.3.3" xref="S4.E1.m1.1.1.3.2.3.3.cmml"><mn id="S4.E1.m1.1.1.3.2.3.3.2" xref="S4.E1.m1.1.1.3.2.3.3.2.cmml">1</mn><mrow id="S4.E1.m1.1.1.3.2.3.3.3" xref="S4.E1.m1.1.1.3.2.3.3.3.cmml"><mi id="S4.E1.m1.1.1.3.2.3.3.3.2" xref="S4.E1.m1.1.1.3.2.3.3.3.2.cmml">B</mi><mo id="S4.E1.m1.1.1.3.2.3.3.3.1" xref="S4.E1.m1.1.1.3.2.3.3.3.1.cmml">⁢</mo><mi id="S4.E1.m1.1.1.3.2.3.3.3.3" xref="S4.E1.m1.1.1.3.2.3.3.3.3.cmml">o</mi><mo id="S4.E1.m1.1.1.3.2.3.3.3.1a" xref="S4.E1.m1.1.1.3.2.3.3.3.1.cmml">⁢</mo><mi id="S4.E1.m1.1.1.3.2.3.3.3.4" xref="S4.E1.m1.1.1.3.2.3.3.3.4.cmml">t</mi></mrow></msub></mrow></mrow><mn id="S4.E1.m1.1.1.3.3" xref="S4.E1.m1.1.1.3.3.cmml">2</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1"><eq id="S4.E1.m1.1.1.1.cmml" xref="S4.E1.m1.1.1.1"></eq><apply id="S4.E1.m1.1.1.2.cmml" xref="S4.E1.m1.1.1.2"><csymbol cd="latexml" id="S4.E1.m1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.2.1">conditional</csymbol><apply id="S4.E1.m1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.2.2"><times id="S4.E1.m1.1.1.2.2.1.cmml" xref="S4.E1.m1.1.1.2.2.1"></times><ci id="S4.E1.m1.1.1.2.2.2.cmml" xref="S4.E1.m1.1.1.2.2.2">𝑀</ci><ci id="S4.E1.m1.1.1.2.2.3.cmml" xref="S4.E1.m1.1.1.2.2.3">𝑎</ci><ci id="S4.E1.m1.1.1.2.2.4.cmml" xref="S4.E1.m1.1.1.2.2.4">𝑐</ci><ci id="S4.E1.m1.1.1.2.2.5.cmml" xref="S4.E1.m1.1.1.2.2.5">𝑟</ci><ci id="S4.E1.m1.1.1.2.2.6.cmml" xref="S4.E1.m1.1.1.2.2.6">𝑜</ci></apply><apply id="S4.E1.m1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.2.3"><times id="S4.E1.m1.1.1.2.3.1.cmml" xref="S4.E1.m1.1.1.2.3.1"></times><ci id="S4.E1.m1.1.1.2.3.2.cmml" xref="S4.E1.m1.1.1.2.3.2">𝐹</ci><cn id="S4.E1.m1.1.1.2.3.3.cmml" type="integer" xref="S4.E1.m1.1.1.2.3.3">1</cn></apply></apply><apply id="S4.E1.m1.1.1.3.cmml" xref="S4.E1.m1.1.1.3"><divide id="S4.E1.m1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.3"></divide><apply id="S4.E1.m1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.3.2"><plus id="S4.E1.m1.1.1.3.2.1.cmml" xref="S4.E1.m1.1.1.3.2.1"></plus><apply id="S4.E1.m1.1.1.3.2.2.cmml" xref="S4.E1.m1.1.1.3.2.2"><times id="S4.E1.m1.1.1.3.2.2.1.cmml" xref="S4.E1.m1.1.1.3.2.2.1"></times><ci id="S4.E1.m1.1.1.3.2.2.2.cmml" xref="S4.E1.m1.1.1.3.2.2.2">𝐹</ci><apply id="S4.E1.m1.1.1.3.2.2.3.cmml" xref="S4.E1.m1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.3.2.2.3.1.cmml" xref="S4.E1.m1.1.1.3.2.2.3">subscript</csymbol><cn id="S4.E1.m1.1.1.3.2.2.3.2.cmml" type="integer" xref="S4.E1.m1.1.1.3.2.2.3.2">1</cn><apply id="S4.E1.m1.1.1.3.2.2.3.3.cmml" xref="S4.E1.m1.1.1.3.2.2.3.3"><times id="S4.E1.m1.1.1.3.2.2.3.3.1.cmml" xref="S4.E1.m1.1.1.3.2.2.3.3.1"></times><ci id="S4.E1.m1.1.1.3.2.2.3.3.2.cmml" xref="S4.E1.m1.1.1.3.2.2.3.3.2">𝐻</ci><ci id="S4.E1.m1.1.1.3.2.2.3.3.3.cmml" xref="S4.E1.m1.1.1.3.2.2.3.3.3">𝑢</ci><ci id="S4.E1.m1.1.1.3.2.2.3.3.4.cmml" xref="S4.E1.m1.1.1.3.2.2.3.3.4">𝑚</ci><ci id="S4.E1.m1.1.1.3.2.2.3.3.5.cmml" xref="S4.E1.m1.1.1.3.2.2.3.3.5">𝑎</ci><ci id="S4.E1.m1.1.1.3.2.2.3.3.6.cmml" xref="S4.E1.m1.1.1.3.2.2.3.3.6">𝑛</ci></apply></apply></apply><apply id="S4.E1.m1.1.1.3.2.3.cmml" xref="S4.E1.m1.1.1.3.2.3"><times id="S4.E1.m1.1.1.3.2.3.1.cmml" xref="S4.E1.m1.1.1.3.2.3.1"></times><ci id="S4.E1.m1.1.1.3.2.3.2.cmml" xref="S4.E1.m1.1.1.3.2.3.2">𝐹</ci><apply id="S4.E1.m1.1.1.3.2.3.3.cmml" xref="S4.E1.m1.1.1.3.2.3.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.3.2.3.3.1.cmml" xref="S4.E1.m1.1.1.3.2.3.3">subscript</csymbol><cn id="S4.E1.m1.1.1.3.2.3.3.2.cmml" type="integer" xref="S4.E1.m1.1.1.3.2.3.3.2">1</cn><apply id="S4.E1.m1.1.1.3.2.3.3.3.cmml" xref="S4.E1.m1.1.1.3.2.3.3.3"><times id="S4.E1.m1.1.1.3.2.3.3.3.1.cmml" xref="S4.E1.m1.1.1.3.2.3.3.3.1"></times><ci id="S4.E1.m1.1.1.3.2.3.3.3.2.cmml" xref="S4.E1.m1.1.1.3.2.3.3.3.2">𝐵</ci><ci id="S4.E1.m1.1.1.3.2.3.3.3.3.cmml" xref="S4.E1.m1.1.1.3.2.3.3.3.3">𝑜</ci><ci id="S4.E1.m1.1.1.3.2.3.3.3.4.cmml" xref="S4.E1.m1.1.1.3.2.3.3.3.4">𝑡</ci></apply></apply></apply></apply><cn id="S4.E1.m1.1.1.3.3.cmml" type="integer" xref="S4.E1.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">Macro|F1=\frac{F1_{Human}+F1_{Bot}}{2}</annotation><annotation encoding="application/x-llamapun" id="S4.E1.m1.1d">italic_M italic_a italic_c italic_r italic_o | italic_F 1 = divide start_ARG italic_F 1 start_POSTSUBSCRIPT italic_H italic_u italic_m italic_a italic_n end_POSTSUBSCRIPT + italic_F 1 start_POSTSUBSCRIPT italic_B italic_o italic_t end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p2.6">where:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="F1_{X}=\frac{2*TP_{X}}{2*TP_{X}+FP_{X}+FN_{X}}" class="ltx_Math" display="block" id="S4.E2.m1.1"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"><mrow id="S4.E2.m1.1.1.2" xref="S4.E2.m1.1.1.2.cmml"><mi id="S4.E2.m1.1.1.2.2" xref="S4.E2.m1.1.1.2.2.cmml">F</mi><mo id="S4.E2.m1.1.1.2.1" xref="S4.E2.m1.1.1.2.1.cmml">⁢</mo><msub id="S4.E2.m1.1.1.2.3" xref="S4.E2.m1.1.1.2.3.cmml"><mn id="S4.E2.m1.1.1.2.3.2" xref="S4.E2.m1.1.1.2.3.2.cmml">1</mn><mi id="S4.E2.m1.1.1.2.3.3" xref="S4.E2.m1.1.1.2.3.3.cmml">X</mi></msub></mrow><mo id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.cmml">=</mo><mfrac id="S4.E2.m1.1.1.3" xref="S4.E2.m1.1.1.3.cmml"><mrow id="S4.E2.m1.1.1.3.2" xref="S4.E2.m1.1.1.3.2.cmml"><mrow id="S4.E2.m1.1.1.3.2.2" xref="S4.E2.m1.1.1.3.2.2.cmml"><mn id="S4.E2.m1.1.1.3.2.2.2" xref="S4.E2.m1.1.1.3.2.2.2.cmml">2</mn><mo id="S4.E2.m1.1.1.3.2.2.1" lspace="0.222em" rspace="0.222em" xref="S4.E2.m1.1.1.3.2.2.1.cmml">∗</mo><mi id="S4.E2.m1.1.1.3.2.2.3" xref="S4.E2.m1.1.1.3.2.2.3.cmml">T</mi></mrow><mo id="S4.E2.m1.1.1.3.2.1" xref="S4.E2.m1.1.1.3.2.1.cmml">⁢</mo><msub id="S4.E2.m1.1.1.3.2.3" xref="S4.E2.m1.1.1.3.2.3.cmml"><mi id="S4.E2.m1.1.1.3.2.3.2" xref="S4.E2.m1.1.1.3.2.3.2.cmml">P</mi><mi id="S4.E2.m1.1.1.3.2.3.3" xref="S4.E2.m1.1.1.3.2.3.3.cmml">X</mi></msub></mrow><mrow id="S4.E2.m1.1.1.3.3" xref="S4.E2.m1.1.1.3.3.cmml"><mrow id="S4.E2.m1.1.1.3.3.2" xref="S4.E2.m1.1.1.3.3.2.cmml"><mrow id="S4.E2.m1.1.1.3.3.2.2" xref="S4.E2.m1.1.1.3.3.2.2.cmml"><mn id="S4.E2.m1.1.1.3.3.2.2.2" xref="S4.E2.m1.1.1.3.3.2.2.2.cmml">2</mn><mo id="S4.E2.m1.1.1.3.3.2.2.1" lspace="0.222em" rspace="0.222em" xref="S4.E2.m1.1.1.3.3.2.2.1.cmml">∗</mo><mi id="S4.E2.m1.1.1.3.3.2.2.3" xref="S4.E2.m1.1.1.3.3.2.2.3.cmml">T</mi></mrow><mo id="S4.E2.m1.1.1.3.3.2.1" xref="S4.E2.m1.1.1.3.3.2.1.cmml">⁢</mo><msub id="S4.E2.m1.1.1.3.3.2.3" xref="S4.E2.m1.1.1.3.3.2.3.cmml"><mi id="S4.E2.m1.1.1.3.3.2.3.2" xref="S4.E2.m1.1.1.3.3.2.3.2.cmml">P</mi><mi id="S4.E2.m1.1.1.3.3.2.3.3" xref="S4.E2.m1.1.1.3.3.2.3.3.cmml">X</mi></msub></mrow><mo id="S4.E2.m1.1.1.3.3.1" xref="S4.E2.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E2.m1.1.1.3.3.3" xref="S4.E2.m1.1.1.3.3.3.cmml"><mi id="S4.E2.m1.1.1.3.3.3.2" xref="S4.E2.m1.1.1.3.3.3.2.cmml">F</mi><mo id="S4.E2.m1.1.1.3.3.3.1" xref="S4.E2.m1.1.1.3.3.3.1.cmml">⁢</mo><msub id="S4.E2.m1.1.1.3.3.3.3" xref="S4.E2.m1.1.1.3.3.3.3.cmml"><mi id="S4.E2.m1.1.1.3.3.3.3.2" xref="S4.E2.m1.1.1.3.3.3.3.2.cmml">P</mi><mi id="S4.E2.m1.1.1.3.3.3.3.3" xref="S4.E2.m1.1.1.3.3.3.3.3.cmml">X</mi></msub></mrow><mo id="S4.E2.m1.1.1.3.3.1a" xref="S4.E2.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E2.m1.1.1.3.3.4" xref="S4.E2.m1.1.1.3.3.4.cmml"><mi id="S4.E2.m1.1.1.3.3.4.2" xref="S4.E2.m1.1.1.3.3.4.2.cmml">F</mi><mo id="S4.E2.m1.1.1.3.3.4.1" xref="S4.E2.m1.1.1.3.3.4.1.cmml">⁢</mo><msub id="S4.E2.m1.1.1.3.3.4.3" xref="S4.E2.m1.1.1.3.3.4.3.cmml"><mi id="S4.E2.m1.1.1.3.3.4.3.2" xref="S4.E2.m1.1.1.3.3.4.3.2.cmml">N</mi><mi id="S4.E2.m1.1.1.3.3.4.3.3" xref="S4.E2.m1.1.1.3.3.4.3.3.cmml">X</mi></msub></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1"><eq id="S4.E2.m1.1.1.1.cmml" xref="S4.E2.m1.1.1.1"></eq><apply id="S4.E2.m1.1.1.2.cmml" xref="S4.E2.m1.1.1.2"><times id="S4.E2.m1.1.1.2.1.cmml" xref="S4.E2.m1.1.1.2.1"></times><ci id="S4.E2.m1.1.1.2.2.cmml" xref="S4.E2.m1.1.1.2.2">𝐹</ci><apply id="S4.E2.m1.1.1.2.3.cmml" xref="S4.E2.m1.1.1.2.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.2.3.1.cmml" xref="S4.E2.m1.1.1.2.3">subscript</csymbol><cn id="S4.E2.m1.1.1.2.3.2.cmml" type="integer" xref="S4.E2.m1.1.1.2.3.2">1</cn><ci id="S4.E2.m1.1.1.2.3.3.cmml" xref="S4.E2.m1.1.1.2.3.3">𝑋</ci></apply></apply><apply id="S4.E2.m1.1.1.3.cmml" xref="S4.E2.m1.1.1.3"><divide id="S4.E2.m1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.3"></divide><apply id="S4.E2.m1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.3.2"><times id="S4.E2.m1.1.1.3.2.1.cmml" xref="S4.E2.m1.1.1.3.2.1"></times><apply id="S4.E2.m1.1.1.3.2.2.cmml" xref="S4.E2.m1.1.1.3.2.2"><times id="S4.E2.m1.1.1.3.2.2.1.cmml" xref="S4.E2.m1.1.1.3.2.2.1"></times><cn id="S4.E2.m1.1.1.3.2.2.2.cmml" type="integer" xref="S4.E2.m1.1.1.3.2.2.2">2</cn><ci id="S4.E2.m1.1.1.3.2.2.3.cmml" xref="S4.E2.m1.1.1.3.2.2.3">𝑇</ci></apply><apply id="S4.E2.m1.1.1.3.2.3.cmml" xref="S4.E2.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.3.2.3.1.cmml" xref="S4.E2.m1.1.1.3.2.3">subscript</csymbol><ci id="S4.E2.m1.1.1.3.2.3.2.cmml" xref="S4.E2.m1.1.1.3.2.3.2">𝑃</ci><ci id="S4.E2.m1.1.1.3.2.3.3.cmml" xref="S4.E2.m1.1.1.3.2.3.3">𝑋</ci></apply></apply><apply id="S4.E2.m1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.3.3"><plus id="S4.E2.m1.1.1.3.3.1.cmml" xref="S4.E2.m1.1.1.3.3.1"></plus><apply id="S4.E2.m1.1.1.3.3.2.cmml" xref="S4.E2.m1.1.1.3.3.2"><times id="S4.E2.m1.1.1.3.3.2.1.cmml" xref="S4.E2.m1.1.1.3.3.2.1"></times><apply id="S4.E2.m1.1.1.3.3.2.2.cmml" xref="S4.E2.m1.1.1.3.3.2.2"><times id="S4.E2.m1.1.1.3.3.2.2.1.cmml" xref="S4.E2.m1.1.1.3.3.2.2.1"></times><cn id="S4.E2.m1.1.1.3.3.2.2.2.cmml" type="integer" xref="S4.E2.m1.1.1.3.3.2.2.2">2</cn><ci id="S4.E2.m1.1.1.3.3.2.2.3.cmml" xref="S4.E2.m1.1.1.3.3.2.2.3">𝑇</ci></apply><apply id="S4.E2.m1.1.1.3.3.2.3.cmml" xref="S4.E2.m1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.3.3.2.3.1.cmml" xref="S4.E2.m1.1.1.3.3.2.3">subscript</csymbol><ci id="S4.E2.m1.1.1.3.3.2.3.2.cmml" xref="S4.E2.m1.1.1.3.3.2.3.2">𝑃</ci><ci id="S4.E2.m1.1.1.3.3.2.3.3.cmml" xref="S4.E2.m1.1.1.3.3.2.3.3">𝑋</ci></apply></apply><apply id="S4.E2.m1.1.1.3.3.3.cmml" xref="S4.E2.m1.1.1.3.3.3"><times id="S4.E2.m1.1.1.3.3.3.1.cmml" xref="S4.E2.m1.1.1.3.3.3.1"></times><ci id="S4.E2.m1.1.1.3.3.3.2.cmml" xref="S4.E2.m1.1.1.3.3.3.2">𝐹</ci><apply id="S4.E2.m1.1.1.3.3.3.3.cmml" xref="S4.E2.m1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.3.3.3.3.1.cmml" xref="S4.E2.m1.1.1.3.3.3.3">subscript</csymbol><ci id="S4.E2.m1.1.1.3.3.3.3.2.cmml" xref="S4.E2.m1.1.1.3.3.3.3.2">𝑃</ci><ci id="S4.E2.m1.1.1.3.3.3.3.3.cmml" xref="S4.E2.m1.1.1.3.3.3.3.3">𝑋</ci></apply></apply><apply id="S4.E2.m1.1.1.3.3.4.cmml" xref="S4.E2.m1.1.1.3.3.4"><times id="S4.E2.m1.1.1.3.3.4.1.cmml" xref="S4.E2.m1.1.1.3.3.4.1"></times><ci id="S4.E2.m1.1.1.3.3.4.2.cmml" xref="S4.E2.m1.1.1.3.3.4.2">𝐹</ci><apply id="S4.E2.m1.1.1.3.3.4.3.cmml" xref="S4.E2.m1.1.1.3.3.4.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.3.3.4.3.1.cmml" xref="S4.E2.m1.1.1.3.3.4.3">subscript</csymbol><ci id="S4.E2.m1.1.1.3.3.4.3.2.cmml" xref="S4.E2.m1.1.1.3.3.4.3.2">𝑁</ci><ci id="S4.E2.m1.1.1.3.3.4.3.3.cmml" xref="S4.E2.m1.1.1.3.3.4.3.3">𝑋</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">F1_{X}=\frac{2*TP_{X}}{2*TP_{X}+FP_{X}+FN_{X}}</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.1d">italic_F 1 start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT = divide start_ARG 2 ∗ italic_T italic_P start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT end_ARG start_ARG 2 ∗ italic_T italic_P start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT + italic_F italic_P start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT + italic_F italic_N start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p2.7">we also calculated precision for the human class:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Precision(Human)=\frac{TP_{Human}}{TP_{Human}+FP_{Human}}" class="ltx_Math" display="block" id="S4.E3.m1.1"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1" xref="S4.E3.m1.1.1.1.cmml"><mi id="S4.E3.m1.1.1.1.3" xref="S4.E3.m1.1.1.1.3.cmml">P</mi><mo id="S4.E3.m1.1.1.1.2" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.4" xref="S4.E3.m1.1.1.1.4.cmml">r</mi><mo id="S4.E3.m1.1.1.1.2a" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.5" xref="S4.E3.m1.1.1.1.5.cmml">e</mi><mo id="S4.E3.m1.1.1.1.2b" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.6" xref="S4.E3.m1.1.1.1.6.cmml">c</mi><mo id="S4.E3.m1.1.1.1.2c" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.7" xref="S4.E3.m1.1.1.1.7.cmml">i</mi><mo id="S4.E3.m1.1.1.1.2d" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.8" xref="S4.E3.m1.1.1.1.8.cmml">s</mi><mo id="S4.E3.m1.1.1.1.2e" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.9" xref="S4.E3.m1.1.1.1.9.cmml">i</mi><mo id="S4.E3.m1.1.1.1.2f" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.10" xref="S4.E3.m1.1.1.1.10.cmml">o</mi><mo id="S4.E3.m1.1.1.1.2g" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.11" xref="S4.E3.m1.1.1.1.11.cmml">n</mi><mo id="S4.E3.m1.1.1.1.2h" xref="S4.E3.m1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E3.m1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.cmml"><mo id="S4.E3.m1.1.1.1.1.1.2" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.cmml"><mi id="S4.E3.m1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.2.cmml">H</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.3.cmml">u</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1a" xref="S4.E3.m1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.4" xref="S4.E3.m1.1.1.1.1.1.1.4.cmml">m</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1b" xref="S4.E3.m1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.5" xref="S4.E3.m1.1.1.1.1.1.1.5.cmml">a</mi><mo id="S4.E3.m1.1.1.1.1.1.1.1c" xref="S4.E3.m1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.1.1.1.1.6" xref="S4.E3.m1.1.1.1.1.1.1.6.cmml">n</mi></mrow><mo id="S4.E3.m1.1.1.1.1.1.3" stretchy="false" xref="S4.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E3.m1.1.1.2" xref="S4.E3.m1.1.1.2.cmml">=</mo><mfrac id="S4.E3.m1.1.1.3" xref="S4.E3.m1.1.1.3.cmml"><mrow id="S4.E3.m1.1.1.3.2" xref="S4.E3.m1.1.1.3.2.cmml"><mi id="S4.E3.m1.1.1.3.2.2" xref="S4.E3.m1.1.1.3.2.2.cmml">T</mi><mo id="S4.E3.m1.1.1.3.2.1" xref="S4.E3.m1.1.1.3.2.1.cmml">⁢</mo><msub id="S4.E3.m1.1.1.3.2.3" xref="S4.E3.m1.1.1.3.2.3.cmml"><mi id="S4.E3.m1.1.1.3.2.3.2" xref="S4.E3.m1.1.1.3.2.3.2.cmml">P</mi><mrow id="S4.E3.m1.1.1.3.2.3.3" xref="S4.E3.m1.1.1.3.2.3.3.cmml"><mi id="S4.E3.m1.1.1.3.2.3.3.2" xref="S4.E3.m1.1.1.3.2.3.3.2.cmml">H</mi><mo id="S4.E3.m1.1.1.3.2.3.3.1" xref="S4.E3.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.2.3.3.3" xref="S4.E3.m1.1.1.3.2.3.3.3.cmml">u</mi><mo id="S4.E3.m1.1.1.3.2.3.3.1a" xref="S4.E3.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.2.3.3.4" xref="S4.E3.m1.1.1.3.2.3.3.4.cmml">m</mi><mo id="S4.E3.m1.1.1.3.2.3.3.1b" xref="S4.E3.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.2.3.3.5" xref="S4.E3.m1.1.1.3.2.3.3.5.cmml">a</mi><mo id="S4.E3.m1.1.1.3.2.3.3.1c" xref="S4.E3.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.2.3.3.6" xref="S4.E3.m1.1.1.3.2.3.3.6.cmml">n</mi></mrow></msub></mrow><mrow id="S4.E3.m1.1.1.3.3" xref="S4.E3.m1.1.1.3.3.cmml"><mrow id="S4.E3.m1.1.1.3.3.2" xref="S4.E3.m1.1.1.3.3.2.cmml"><mi id="S4.E3.m1.1.1.3.3.2.2" xref="S4.E3.m1.1.1.3.3.2.2.cmml">T</mi><mo id="S4.E3.m1.1.1.3.3.2.1" xref="S4.E3.m1.1.1.3.3.2.1.cmml">⁢</mo><msub id="S4.E3.m1.1.1.3.3.2.3" xref="S4.E3.m1.1.1.3.3.2.3.cmml"><mi id="S4.E3.m1.1.1.3.3.2.3.2" xref="S4.E3.m1.1.1.3.3.2.3.2.cmml">P</mi><mrow id="S4.E3.m1.1.1.3.3.2.3.3" xref="S4.E3.m1.1.1.3.3.2.3.3.cmml"><mi id="S4.E3.m1.1.1.3.3.2.3.3.2" xref="S4.E3.m1.1.1.3.3.2.3.3.2.cmml">H</mi><mo id="S4.E3.m1.1.1.3.3.2.3.3.1" xref="S4.E3.m1.1.1.3.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.3.2.3.3.3" xref="S4.E3.m1.1.1.3.3.2.3.3.3.cmml">u</mi><mo id="S4.E3.m1.1.1.3.3.2.3.3.1a" xref="S4.E3.m1.1.1.3.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.3.2.3.3.4" xref="S4.E3.m1.1.1.3.3.2.3.3.4.cmml">m</mi><mo id="S4.E3.m1.1.1.3.3.2.3.3.1b" xref="S4.E3.m1.1.1.3.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.3.2.3.3.5" xref="S4.E3.m1.1.1.3.3.2.3.3.5.cmml">a</mi><mo id="S4.E3.m1.1.1.3.3.2.3.3.1c" xref="S4.E3.m1.1.1.3.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.3.2.3.3.6" xref="S4.E3.m1.1.1.3.3.2.3.3.6.cmml">n</mi></mrow></msub></mrow><mo id="S4.E3.m1.1.1.3.3.1" xref="S4.E3.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E3.m1.1.1.3.3.3" xref="S4.E3.m1.1.1.3.3.3.cmml"><mi id="S4.E3.m1.1.1.3.3.3.2" xref="S4.E3.m1.1.1.3.3.3.2.cmml">F</mi><mo id="S4.E3.m1.1.1.3.3.3.1" xref="S4.E3.m1.1.1.3.3.3.1.cmml">⁢</mo><msub id="S4.E3.m1.1.1.3.3.3.3" xref="S4.E3.m1.1.1.3.3.3.3.cmml"><mi id="S4.E3.m1.1.1.3.3.3.3.2" xref="S4.E3.m1.1.1.3.3.3.3.2.cmml">P</mi><mrow id="S4.E3.m1.1.1.3.3.3.3.3" xref="S4.E3.m1.1.1.3.3.3.3.3.cmml"><mi id="S4.E3.m1.1.1.3.3.3.3.3.2" xref="S4.E3.m1.1.1.3.3.3.3.3.2.cmml">H</mi><mo id="S4.E3.m1.1.1.3.3.3.3.3.1" xref="S4.E3.m1.1.1.3.3.3.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.3.3.3.3.3" xref="S4.E3.m1.1.1.3.3.3.3.3.3.cmml">u</mi><mo id="S4.E3.m1.1.1.3.3.3.3.3.1a" xref="S4.E3.m1.1.1.3.3.3.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.3.3.3.3.4" xref="S4.E3.m1.1.1.3.3.3.3.3.4.cmml">m</mi><mo id="S4.E3.m1.1.1.3.3.3.3.3.1b" xref="S4.E3.m1.1.1.3.3.3.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.3.3.3.3.5" xref="S4.E3.m1.1.1.3.3.3.3.3.5.cmml">a</mi><mo id="S4.E3.m1.1.1.3.3.3.3.3.1c" xref="S4.E3.m1.1.1.3.3.3.3.3.1.cmml">⁢</mo><mi id="S4.E3.m1.1.1.3.3.3.3.3.6" xref="S4.E3.m1.1.1.3.3.3.3.3.6.cmml">n</mi></mrow></msub></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1"><eq id="S4.E3.m1.1.1.2.cmml" xref="S4.E3.m1.1.1.2"></eq><apply id="S4.E3.m1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"><times id="S4.E3.m1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.2"></times><ci id="S4.E3.m1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.3">𝑃</ci><ci id="S4.E3.m1.1.1.1.4.cmml" xref="S4.E3.m1.1.1.1.4">𝑟</ci><ci id="S4.E3.m1.1.1.1.5.cmml" xref="S4.E3.m1.1.1.1.5">𝑒</ci><ci id="S4.E3.m1.1.1.1.6.cmml" xref="S4.E3.m1.1.1.1.6">𝑐</ci><ci id="S4.E3.m1.1.1.1.7.cmml" xref="S4.E3.m1.1.1.1.7">𝑖</ci><ci id="S4.E3.m1.1.1.1.8.cmml" xref="S4.E3.m1.1.1.1.8">𝑠</ci><ci id="S4.E3.m1.1.1.1.9.cmml" xref="S4.E3.m1.1.1.1.9">𝑖</ci><ci id="S4.E3.m1.1.1.1.10.cmml" xref="S4.E3.m1.1.1.1.10">𝑜</ci><ci id="S4.E3.m1.1.1.1.11.cmml" xref="S4.E3.m1.1.1.1.11">𝑛</ci><apply id="S4.E3.m1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1"><times id="S4.E3.m1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1"></times><ci id="S4.E3.m1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.2">𝐻</ci><ci id="S4.E3.m1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.3">𝑢</ci><ci id="S4.E3.m1.1.1.1.1.1.1.4.cmml" xref="S4.E3.m1.1.1.1.1.1.1.4">𝑚</ci><ci id="S4.E3.m1.1.1.1.1.1.1.5.cmml" xref="S4.E3.m1.1.1.1.1.1.1.5">𝑎</ci><ci id="S4.E3.m1.1.1.1.1.1.1.6.cmml" xref="S4.E3.m1.1.1.1.1.1.1.6">𝑛</ci></apply></apply><apply id="S4.E3.m1.1.1.3.cmml" xref="S4.E3.m1.1.1.3"><divide id="S4.E3.m1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.3"></divide><apply id="S4.E3.m1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.3.2"><times id="S4.E3.m1.1.1.3.2.1.cmml" xref="S4.E3.m1.1.1.3.2.1"></times><ci id="S4.E3.m1.1.1.3.2.2.cmml" xref="S4.E3.m1.1.1.3.2.2">𝑇</ci><apply id="S4.E3.m1.1.1.3.2.3.cmml" xref="S4.E3.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.2.3.1.cmml" xref="S4.E3.m1.1.1.3.2.3">subscript</csymbol><ci id="S4.E3.m1.1.1.3.2.3.2.cmml" xref="S4.E3.m1.1.1.3.2.3.2">𝑃</ci><apply id="S4.E3.m1.1.1.3.2.3.3.cmml" xref="S4.E3.m1.1.1.3.2.3.3"><times id="S4.E3.m1.1.1.3.2.3.3.1.cmml" xref="S4.E3.m1.1.1.3.2.3.3.1"></times><ci id="S4.E3.m1.1.1.3.2.3.3.2.cmml" xref="S4.E3.m1.1.1.3.2.3.3.2">𝐻</ci><ci id="S4.E3.m1.1.1.3.2.3.3.3.cmml" xref="S4.E3.m1.1.1.3.2.3.3.3">𝑢</ci><ci id="S4.E3.m1.1.1.3.2.3.3.4.cmml" xref="S4.E3.m1.1.1.3.2.3.3.4">𝑚</ci><ci id="S4.E3.m1.1.1.3.2.3.3.5.cmml" xref="S4.E3.m1.1.1.3.2.3.3.5">𝑎</ci><ci id="S4.E3.m1.1.1.3.2.3.3.6.cmml" xref="S4.E3.m1.1.1.3.2.3.3.6">𝑛</ci></apply></apply></apply><apply id="S4.E3.m1.1.1.3.3.cmml" xref="S4.E3.m1.1.1.3.3"><plus id="S4.E3.m1.1.1.3.3.1.cmml" xref="S4.E3.m1.1.1.3.3.1"></plus><apply id="S4.E3.m1.1.1.3.3.2.cmml" xref="S4.E3.m1.1.1.3.3.2"><times id="S4.E3.m1.1.1.3.3.2.1.cmml" xref="S4.E3.m1.1.1.3.3.2.1"></times><ci id="S4.E3.m1.1.1.3.3.2.2.cmml" xref="S4.E3.m1.1.1.3.3.2.2">𝑇</ci><apply id="S4.E3.m1.1.1.3.3.2.3.cmml" xref="S4.E3.m1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.3.2.3.1.cmml" xref="S4.E3.m1.1.1.3.3.2.3">subscript</csymbol><ci id="S4.E3.m1.1.1.3.3.2.3.2.cmml" xref="S4.E3.m1.1.1.3.3.2.3.2">𝑃</ci><apply id="S4.E3.m1.1.1.3.3.2.3.3.cmml" xref="S4.E3.m1.1.1.3.3.2.3.3"><times id="S4.E3.m1.1.1.3.3.2.3.3.1.cmml" xref="S4.E3.m1.1.1.3.3.2.3.3.1"></times><ci id="S4.E3.m1.1.1.3.3.2.3.3.2.cmml" xref="S4.E3.m1.1.1.3.3.2.3.3.2">𝐻</ci><ci id="S4.E3.m1.1.1.3.3.2.3.3.3.cmml" xref="S4.E3.m1.1.1.3.3.2.3.3.3">𝑢</ci><ci id="S4.E3.m1.1.1.3.3.2.3.3.4.cmml" xref="S4.E3.m1.1.1.3.3.2.3.3.4">𝑚</ci><ci id="S4.E3.m1.1.1.3.3.2.3.3.5.cmml" xref="S4.E3.m1.1.1.3.3.2.3.3.5">𝑎</ci><ci id="S4.E3.m1.1.1.3.3.2.3.3.6.cmml" xref="S4.E3.m1.1.1.3.3.2.3.3.6">𝑛</ci></apply></apply></apply><apply id="S4.E3.m1.1.1.3.3.3.cmml" xref="S4.E3.m1.1.1.3.3.3"><times id="S4.E3.m1.1.1.3.3.3.1.cmml" xref="S4.E3.m1.1.1.3.3.3.1"></times><ci id="S4.E3.m1.1.1.3.3.3.2.cmml" xref="S4.E3.m1.1.1.3.3.3.2">𝐹</ci><apply id="S4.E3.m1.1.1.3.3.3.3.cmml" xref="S4.E3.m1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.3.3.3.1.cmml" xref="S4.E3.m1.1.1.3.3.3.3">subscript</csymbol><ci id="S4.E3.m1.1.1.3.3.3.3.2.cmml" xref="S4.E3.m1.1.1.3.3.3.3.2">𝑃</ci><apply id="S4.E3.m1.1.1.3.3.3.3.3.cmml" xref="S4.E3.m1.1.1.3.3.3.3.3"><times id="S4.E3.m1.1.1.3.3.3.3.3.1.cmml" xref="S4.E3.m1.1.1.3.3.3.3.3.1"></times><ci id="S4.E3.m1.1.1.3.3.3.3.3.2.cmml" xref="S4.E3.m1.1.1.3.3.3.3.3.2">𝐻</ci><ci id="S4.E3.m1.1.1.3.3.3.3.3.3.cmml" xref="S4.E3.m1.1.1.3.3.3.3.3.3">𝑢</ci><ci id="S4.E3.m1.1.1.3.3.3.3.3.4.cmml" xref="S4.E3.m1.1.1.3.3.3.3.3.4">𝑚</ci><ci id="S4.E3.m1.1.1.3.3.3.3.3.5.cmml" xref="S4.E3.m1.1.1.3.3.3.3.3.5">𝑎</ci><ci id="S4.E3.m1.1.1.3.3.3.3.3.6.cmml" xref="S4.E3.m1.1.1.3.3.3.3.3.6">𝑛</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">Precision(Human)=\frac{TP_{Human}}{TP_{Human}+FP_{Human}}</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.1d">italic_P italic_r italic_e italic_c italic_i italic_s italic_i italic_o italic_n ( italic_H italic_u italic_m italic_a italic_n ) = divide start_ARG italic_T italic_P start_POSTSUBSCRIPT italic_H italic_u italic_m italic_a italic_n end_POSTSUBSCRIPT end_ARG start_ARG italic_T italic_P start_POSTSUBSCRIPT italic_H italic_u italic_m italic_a italic_n end_POSTSUBSCRIPT + italic_F italic_P start_POSTSUBSCRIPT italic_H italic_u italic_m italic_a italic_n end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p2.8">and recall for the human class:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Recall(Human)=\frac{TP_{Human}}{TP_{Human}+FN_{Human}}" class="ltx_Math" display="block" id="S4.E4.m1.1"><semantics id="S4.E4.m1.1a"><mrow id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml"><mrow id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.3" xref="S4.E4.m1.1.1.1.3.cmml">R</mi><mo id="S4.E4.m1.1.1.1.2" xref="S4.E4.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.4" xref="S4.E4.m1.1.1.1.4.cmml">e</mi><mo id="S4.E4.m1.1.1.1.2a" xref="S4.E4.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.5" xref="S4.E4.m1.1.1.1.5.cmml">c</mi><mo id="S4.E4.m1.1.1.1.2b" xref="S4.E4.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.6" xref="S4.E4.m1.1.1.1.6.cmml">a</mi><mo id="S4.E4.m1.1.1.1.2c" xref="S4.E4.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.7" xref="S4.E4.m1.1.1.1.7.cmml">l</mi><mo id="S4.E4.m1.1.1.1.2d" xref="S4.E4.m1.1.1.1.2.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.8" xref="S4.E4.m1.1.1.1.8.cmml">l</mi><mo id="S4.E4.m1.1.1.1.2e" xref="S4.E4.m1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E4.m1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.cmml"><mo id="S4.E4.m1.1.1.1.1.1.2" stretchy="false" xref="S4.E4.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.2.cmml">H</mi><mo id="S4.E4.m1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.3.cmml">u</mi><mo id="S4.E4.m1.1.1.1.1.1.1.1a" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.1.1.1.4" xref="S4.E4.m1.1.1.1.1.1.1.4.cmml">m</mi><mo id="S4.E4.m1.1.1.1.1.1.1.1b" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.1.1.1.5" xref="S4.E4.m1.1.1.1.1.1.1.5.cmml">a</mi><mo id="S4.E4.m1.1.1.1.1.1.1.1c" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.1.1.1.6" xref="S4.E4.m1.1.1.1.1.1.1.6.cmml">n</mi></mrow><mo id="S4.E4.m1.1.1.1.1.1.3" stretchy="false" xref="S4.E4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E4.m1.1.1.2" xref="S4.E4.m1.1.1.2.cmml">=</mo><mfrac id="S4.E4.m1.1.1.3" xref="S4.E4.m1.1.1.3.cmml"><mrow id="S4.E4.m1.1.1.3.2" xref="S4.E4.m1.1.1.3.2.cmml"><mi id="S4.E4.m1.1.1.3.2.2" xref="S4.E4.m1.1.1.3.2.2.cmml">T</mi><mo id="S4.E4.m1.1.1.3.2.1" xref="S4.E4.m1.1.1.3.2.1.cmml">⁢</mo><msub id="S4.E4.m1.1.1.3.2.3" xref="S4.E4.m1.1.1.3.2.3.cmml"><mi id="S4.E4.m1.1.1.3.2.3.2" xref="S4.E4.m1.1.1.3.2.3.2.cmml">P</mi><mrow id="S4.E4.m1.1.1.3.2.3.3" xref="S4.E4.m1.1.1.3.2.3.3.cmml"><mi id="S4.E4.m1.1.1.3.2.3.3.2" xref="S4.E4.m1.1.1.3.2.3.3.2.cmml">H</mi><mo id="S4.E4.m1.1.1.3.2.3.3.1" xref="S4.E4.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.2.3.3.3" xref="S4.E4.m1.1.1.3.2.3.3.3.cmml">u</mi><mo id="S4.E4.m1.1.1.3.2.3.3.1a" xref="S4.E4.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.2.3.3.4" xref="S4.E4.m1.1.1.3.2.3.3.4.cmml">m</mi><mo id="S4.E4.m1.1.1.3.2.3.3.1b" xref="S4.E4.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.2.3.3.5" xref="S4.E4.m1.1.1.3.2.3.3.5.cmml">a</mi><mo id="S4.E4.m1.1.1.3.2.3.3.1c" xref="S4.E4.m1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.2.3.3.6" xref="S4.E4.m1.1.1.3.2.3.3.6.cmml">n</mi></mrow></msub></mrow><mrow id="S4.E4.m1.1.1.3.3" xref="S4.E4.m1.1.1.3.3.cmml"><mrow id="S4.E4.m1.1.1.3.3.2" xref="S4.E4.m1.1.1.3.3.2.cmml"><mi id="S4.E4.m1.1.1.3.3.2.2" xref="S4.E4.m1.1.1.3.3.2.2.cmml">T</mi><mo id="S4.E4.m1.1.1.3.3.2.1" xref="S4.E4.m1.1.1.3.3.2.1.cmml">⁢</mo><msub id="S4.E4.m1.1.1.3.3.2.3" xref="S4.E4.m1.1.1.3.3.2.3.cmml"><mi id="S4.E4.m1.1.1.3.3.2.3.2" xref="S4.E4.m1.1.1.3.3.2.3.2.cmml">P</mi><mrow id="S4.E4.m1.1.1.3.3.2.3.3" xref="S4.E4.m1.1.1.3.3.2.3.3.cmml"><mi id="S4.E4.m1.1.1.3.3.2.3.3.2" xref="S4.E4.m1.1.1.3.3.2.3.3.2.cmml">H</mi><mo id="S4.E4.m1.1.1.3.3.2.3.3.1" xref="S4.E4.m1.1.1.3.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.3.2.3.3.3" xref="S4.E4.m1.1.1.3.3.2.3.3.3.cmml">u</mi><mo id="S4.E4.m1.1.1.3.3.2.3.3.1a" xref="S4.E4.m1.1.1.3.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.3.2.3.3.4" xref="S4.E4.m1.1.1.3.3.2.3.3.4.cmml">m</mi><mo id="S4.E4.m1.1.1.3.3.2.3.3.1b" xref="S4.E4.m1.1.1.3.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.3.2.3.3.5" xref="S4.E4.m1.1.1.3.3.2.3.3.5.cmml">a</mi><mo id="S4.E4.m1.1.1.3.3.2.3.3.1c" xref="S4.E4.m1.1.1.3.3.2.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.3.2.3.3.6" xref="S4.E4.m1.1.1.3.3.2.3.3.6.cmml">n</mi></mrow></msub></mrow><mo id="S4.E4.m1.1.1.3.3.1" xref="S4.E4.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E4.m1.1.1.3.3.3" xref="S4.E4.m1.1.1.3.3.3.cmml"><mi id="S4.E4.m1.1.1.3.3.3.2" xref="S4.E4.m1.1.1.3.3.3.2.cmml">F</mi><mo id="S4.E4.m1.1.1.3.3.3.1" xref="S4.E4.m1.1.1.3.3.3.1.cmml">⁢</mo><msub id="S4.E4.m1.1.1.3.3.3.3" xref="S4.E4.m1.1.1.3.3.3.3.cmml"><mi id="S4.E4.m1.1.1.3.3.3.3.2" xref="S4.E4.m1.1.1.3.3.3.3.2.cmml">N</mi><mrow id="S4.E4.m1.1.1.3.3.3.3.3" xref="S4.E4.m1.1.1.3.3.3.3.3.cmml"><mi id="S4.E4.m1.1.1.3.3.3.3.3.2" xref="S4.E4.m1.1.1.3.3.3.3.3.2.cmml">H</mi><mo id="S4.E4.m1.1.1.3.3.3.3.3.1" xref="S4.E4.m1.1.1.3.3.3.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.3.3.3.3.3" xref="S4.E4.m1.1.1.3.3.3.3.3.3.cmml">u</mi><mo id="S4.E4.m1.1.1.3.3.3.3.3.1a" xref="S4.E4.m1.1.1.3.3.3.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.3.3.3.3.4" xref="S4.E4.m1.1.1.3.3.3.3.3.4.cmml">m</mi><mo id="S4.E4.m1.1.1.3.3.3.3.3.1b" xref="S4.E4.m1.1.1.3.3.3.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.3.3.3.3.5" xref="S4.E4.m1.1.1.3.3.3.3.3.5.cmml">a</mi><mo id="S4.E4.m1.1.1.3.3.3.3.3.1c" xref="S4.E4.m1.1.1.3.3.3.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.3.3.3.3.3.6" xref="S4.E4.m1.1.1.3.3.3.3.3.6.cmml">n</mi></mrow></msub></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.1b"><apply id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1"><eq id="S4.E4.m1.1.1.2.cmml" xref="S4.E4.m1.1.1.2"></eq><apply id="S4.E4.m1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"><times id="S4.E4.m1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.2"></times><ci id="S4.E4.m1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.3">𝑅</ci><ci id="S4.E4.m1.1.1.1.4.cmml" xref="S4.E4.m1.1.1.1.4">𝑒</ci><ci id="S4.E4.m1.1.1.1.5.cmml" xref="S4.E4.m1.1.1.1.5">𝑐</ci><ci id="S4.E4.m1.1.1.1.6.cmml" xref="S4.E4.m1.1.1.1.6">𝑎</ci><ci id="S4.E4.m1.1.1.1.7.cmml" xref="S4.E4.m1.1.1.1.7">𝑙</ci><ci id="S4.E4.m1.1.1.1.8.cmml" xref="S4.E4.m1.1.1.1.8">𝑙</ci><apply id="S4.E4.m1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1"><times id="S4.E4.m1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1"></times><ci id="S4.E4.m1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.2">𝐻</ci><ci id="S4.E4.m1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.3">𝑢</ci><ci id="S4.E4.m1.1.1.1.1.1.1.4.cmml" xref="S4.E4.m1.1.1.1.1.1.1.4">𝑚</ci><ci id="S4.E4.m1.1.1.1.1.1.1.5.cmml" xref="S4.E4.m1.1.1.1.1.1.1.5">𝑎</ci><ci id="S4.E4.m1.1.1.1.1.1.1.6.cmml" xref="S4.E4.m1.1.1.1.1.1.1.6">𝑛</ci></apply></apply><apply id="S4.E4.m1.1.1.3.cmml" xref="S4.E4.m1.1.1.3"><divide id="S4.E4.m1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.3"></divide><apply id="S4.E4.m1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.3.2"><times id="S4.E4.m1.1.1.3.2.1.cmml" xref="S4.E4.m1.1.1.3.2.1"></times><ci id="S4.E4.m1.1.1.3.2.2.cmml" xref="S4.E4.m1.1.1.3.2.2">𝑇</ci><apply id="S4.E4.m1.1.1.3.2.3.cmml" xref="S4.E4.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.3.2.3.1.cmml" xref="S4.E4.m1.1.1.3.2.3">subscript</csymbol><ci id="S4.E4.m1.1.1.3.2.3.2.cmml" xref="S4.E4.m1.1.1.3.2.3.2">𝑃</ci><apply id="S4.E4.m1.1.1.3.2.3.3.cmml" xref="S4.E4.m1.1.1.3.2.3.3"><times id="S4.E4.m1.1.1.3.2.3.3.1.cmml" xref="S4.E4.m1.1.1.3.2.3.3.1"></times><ci id="S4.E4.m1.1.1.3.2.3.3.2.cmml" xref="S4.E4.m1.1.1.3.2.3.3.2">𝐻</ci><ci id="S4.E4.m1.1.1.3.2.3.3.3.cmml" xref="S4.E4.m1.1.1.3.2.3.3.3">𝑢</ci><ci id="S4.E4.m1.1.1.3.2.3.3.4.cmml" xref="S4.E4.m1.1.1.3.2.3.3.4">𝑚</ci><ci id="S4.E4.m1.1.1.3.2.3.3.5.cmml" xref="S4.E4.m1.1.1.3.2.3.3.5">𝑎</ci><ci id="S4.E4.m1.1.1.3.2.3.3.6.cmml" xref="S4.E4.m1.1.1.3.2.3.3.6">𝑛</ci></apply></apply></apply><apply id="S4.E4.m1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.3.3"><plus id="S4.E4.m1.1.1.3.3.1.cmml" xref="S4.E4.m1.1.1.3.3.1"></plus><apply id="S4.E4.m1.1.1.3.3.2.cmml" xref="S4.E4.m1.1.1.3.3.2"><times id="S4.E4.m1.1.1.3.3.2.1.cmml" xref="S4.E4.m1.1.1.3.3.2.1"></times><ci id="S4.E4.m1.1.1.3.3.2.2.cmml" xref="S4.E4.m1.1.1.3.3.2.2">𝑇</ci><apply id="S4.E4.m1.1.1.3.3.2.3.cmml" xref="S4.E4.m1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.3.3.2.3.1.cmml" xref="S4.E4.m1.1.1.3.3.2.3">subscript</csymbol><ci id="S4.E4.m1.1.1.3.3.2.3.2.cmml" xref="S4.E4.m1.1.1.3.3.2.3.2">𝑃</ci><apply id="S4.E4.m1.1.1.3.3.2.3.3.cmml" xref="S4.E4.m1.1.1.3.3.2.3.3"><times id="S4.E4.m1.1.1.3.3.2.3.3.1.cmml" xref="S4.E4.m1.1.1.3.3.2.3.3.1"></times><ci id="S4.E4.m1.1.1.3.3.2.3.3.2.cmml" xref="S4.E4.m1.1.1.3.3.2.3.3.2">𝐻</ci><ci id="S4.E4.m1.1.1.3.3.2.3.3.3.cmml" xref="S4.E4.m1.1.1.3.3.2.3.3.3">𝑢</ci><ci id="S4.E4.m1.1.1.3.3.2.3.3.4.cmml" xref="S4.E4.m1.1.1.3.3.2.3.3.4">𝑚</ci><ci id="S4.E4.m1.1.1.3.3.2.3.3.5.cmml" xref="S4.E4.m1.1.1.3.3.2.3.3.5">𝑎</ci><ci id="S4.E4.m1.1.1.3.3.2.3.3.6.cmml" xref="S4.E4.m1.1.1.3.3.2.3.3.6">𝑛</ci></apply></apply></apply><apply id="S4.E4.m1.1.1.3.3.3.cmml" xref="S4.E4.m1.1.1.3.3.3"><times id="S4.E4.m1.1.1.3.3.3.1.cmml" xref="S4.E4.m1.1.1.3.3.3.1"></times><ci id="S4.E4.m1.1.1.3.3.3.2.cmml" xref="S4.E4.m1.1.1.3.3.3.2">𝐹</ci><apply id="S4.E4.m1.1.1.3.3.3.3.cmml" xref="S4.E4.m1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.3.3.3.3.1.cmml" xref="S4.E4.m1.1.1.3.3.3.3">subscript</csymbol><ci id="S4.E4.m1.1.1.3.3.3.3.2.cmml" xref="S4.E4.m1.1.1.3.3.3.3.2">𝑁</ci><apply id="S4.E4.m1.1.1.3.3.3.3.3.cmml" xref="S4.E4.m1.1.1.3.3.3.3.3"><times id="S4.E4.m1.1.1.3.3.3.3.3.1.cmml" xref="S4.E4.m1.1.1.3.3.3.3.3.1"></times><ci id="S4.E4.m1.1.1.3.3.3.3.3.2.cmml" xref="S4.E4.m1.1.1.3.3.3.3.3.2">𝐻</ci><ci id="S4.E4.m1.1.1.3.3.3.3.3.3.cmml" xref="S4.E4.m1.1.1.3.3.3.3.3.3">𝑢</ci><ci id="S4.E4.m1.1.1.3.3.3.3.3.4.cmml" xref="S4.E4.m1.1.1.3.3.3.3.3.4">𝑚</ci><ci id="S4.E4.m1.1.1.3.3.3.3.3.5.cmml" xref="S4.E4.m1.1.1.3.3.3.3.3.5">𝑎</ci><ci id="S4.E4.m1.1.1.3.3.3.3.3.6.cmml" xref="S4.E4.m1.1.1.3.3.3.3.3.6">𝑛</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.1c">Recall(Human)=\frac{TP_{Human}}{TP_{Human}+FN_{Human}}</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m1.1d">italic_R italic_e italic_c italic_a italic_l italic_l ( italic_H italic_u italic_m italic_a italic_n ) = divide start_ARG italic_T italic_P start_POSTSUBSCRIPT italic_H italic_u italic_m italic_a italic_n end_POSTSUBSCRIPT end_ARG start_ARG italic_T italic_P start_POSTSUBSCRIPT italic_H italic_u italic_m italic_a italic_n end_POSTSUBSCRIPT + italic_F italic_N start_POSTSUBSCRIPT italic_H italic_u italic_m italic_a italic_n end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p2.9">The training data for the game were imbalanced due to the limited availability of human players. It comprised a total of 93,195 logs from 89,667 AI vs. AI matches, 2,190 AI vs. Human matches, and 1,338 Human vs. Human matches. Due to this imbalance, per-class metrics for the human class are included, as this is a minority class and it is more susceptible to higher errors.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>Results achieved using 5-fold cross validation.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.9">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.9.10.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.9.10.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.9.10.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_t" id="S4.T1.9.10.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.9.10.1.2.1">F1 Score</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.9.10.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.9.10.1.3.1">Precision (H)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.9.10.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.9.10.1.4.1">Recall (H)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt" id="S4.T1.3.3.4">Full (RNN+CNN)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_tt" id="S4.T1.1.1.1"><math alttext="0.92" class="ltx_Math" display="inline" id="S4.T1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.m1.1a"><mn id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml">0.92</mn><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><cn id="S4.T1.1.1.1.m1.1.1.cmml" type="float" xref="S4.T1.1.1.1.m1.1.1">0.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">0.92</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.m1.1d">0.92</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.2.2.2"><math alttext="0.87" class="ltx_Math" display="inline" id="S4.T1.2.2.2.m1.1"><semantics id="S4.T1.2.2.2.m1.1a"><mn id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml">0.87</mn><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><cn id="S4.T1.2.2.2.m1.1.1.cmml" type="float" xref="S4.T1.2.2.2.m1.1.1">0.87</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">0.87</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.m1.1d">0.87</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.3.3.3"><math alttext="0.81" class="ltx_Math" display="inline" id="S4.T1.3.3.3.m1.1"><semantics id="S4.T1.3.3.3.m1.1a"><mn id="S4.T1.3.3.3.m1.1.1" xref="S4.T1.3.3.3.m1.1.1.cmml">0.81</mn><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><cn id="S4.T1.3.3.3.m1.1.1.cmml" type="float" xref="S4.T1.3.3.3.m1.1.1">0.81</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">0.81</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.m1.1d">0.81</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T1.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.6.6.4">RNN only</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T1.4.4.1"><math alttext="0.88" class="ltx_Math" display="inline" id="S4.T1.4.4.1.m1.1"><semantics id="S4.T1.4.4.1.m1.1a"><mn id="S4.T1.4.4.1.m1.1.1" xref="S4.T1.4.4.1.m1.1.1.cmml">0.88</mn><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.1.m1.1b"><cn id="S4.T1.4.4.1.m1.1.1.cmml" type="float" xref="S4.T1.4.4.1.m1.1.1">0.88</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.1.m1.1c">0.88</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.4.1.m1.1d">0.88</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.5.2"><math alttext="0.75" class="ltx_Math" display="inline" id="S4.T1.5.5.2.m1.1"><semantics id="S4.T1.5.5.2.m1.1a"><mn id="S4.T1.5.5.2.m1.1.1" xref="S4.T1.5.5.2.m1.1.1.cmml">0.75</mn><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.2.m1.1b"><cn id="S4.T1.5.5.2.m1.1.1.cmml" type="float" xref="S4.T1.5.5.2.m1.1.1">0.75</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.2.m1.1c">0.75</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.5.2.m1.1d">0.75</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.6.6.3"><math alttext="0.79" class="ltx_Math" display="inline" id="S4.T1.6.6.3.m1.1"><semantics id="S4.T1.6.6.3.m1.1a"><mn id="S4.T1.6.6.3.m1.1.1" xref="S4.T1.6.6.3.m1.1.1.cmml">0.79</mn><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.3.m1.1b"><cn id="S4.T1.6.6.3.m1.1.1.cmml" type="float" xref="S4.T1.6.6.3.m1.1.1">0.79</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.3.m1.1c">0.79</annotation><annotation encoding="application/x-llamapun" id="S4.T1.6.6.3.m1.1d">0.79</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T1.9.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="S4.T1.9.9.4">CNN only</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_rr" id="S4.T1.7.7.1"><math alttext="0.59" class="ltx_Math" display="inline" id="S4.T1.7.7.1.m1.1"><semantics id="S4.T1.7.7.1.m1.1a"><mn id="S4.T1.7.7.1.m1.1.1" xref="S4.T1.7.7.1.m1.1.1.cmml">0.59</mn><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.1.m1.1b"><cn id="S4.T1.7.7.1.m1.1.1.cmml" type="float" xref="S4.T1.7.7.1.m1.1.1">0.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.1.m1.1c">0.59</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.7.1.m1.1d">0.59</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.8.8.2"><math alttext="0.61" class="ltx_Math" display="inline" id="S4.T1.8.8.2.m1.1"><semantics id="S4.T1.8.8.2.m1.1a"><mn id="S4.T1.8.8.2.m1.1.1" xref="S4.T1.8.8.2.m1.1.1.cmml">0.61</mn><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.2.m1.1b"><cn id="S4.T1.8.8.2.m1.1.1.cmml" type="float" xref="S4.T1.8.8.2.m1.1.1">0.61</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.2.m1.1c">0.61</annotation><annotation encoding="application/x-llamapun" id="S4.T1.8.8.2.m1.1d">0.61</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.9.9.3"><math alttext="0.57" class="ltx_Math" display="inline" id="S4.T1.9.9.3.m1.1"><semantics id="S4.T1.9.9.3.m1.1a"><mn id="S4.T1.9.9.3.m1.1.1" xref="S4.T1.9.9.3.m1.1.1.cmml">0.57</mn><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.3.m1.1b"><cn id="S4.T1.9.9.3.m1.1.1.cmml" type="float" xref="S4.T1.9.9.3.m1.1.1">0.57</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.3.m1.1c">0.57</annotation><annotation encoding="application/x-llamapun" id="S4.T1.9.9.3.m1.1d">0.57</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.3">The proposed method, that combines CNN and RNN architectures, achieved an F1-Score equal to <math alttext="0.92" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><mn id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">0.92</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><cn id="S4.SS1.p3.1.m1.1.1.cmml" type="float" xref="S4.SS1.p3.1.m1.1.1">0.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">0.92</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.1d">0.92</annotation></semantics></math>.
This result clearly indicates that the deep learning model significantly outperformed the initial XGBoost model, which was based on only 20 input features, by improving the F1-Score from <math alttext="0.58" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><mn id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">0.58</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><cn id="S4.SS1.p3.2.m2.1.1.cmml" type="float" xref="S4.SS1.p3.2.m2.1.1">0.58</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">0.58</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">0.58</annotation></semantics></math> to <math alttext="0.92" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><mn id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">0.92</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><cn id="S4.SS1.p3.3.m3.1.1.cmml" type="float" xref="S4.SS1.p3.3.m3.1.1">0.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">0.92</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.3.m3.1d">0.92</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">In Table <a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S4.T1" title="Table 1 ‣ 4.1. Results ‣ 4. Method Behind Human-Likeness Evaluation ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_tag">1</span></a>, there is also a comparison of the full approach with models based on a single component only: either the RNN network transforming aggregated scalar features from the game states or the CNN network with six types of 2D maps as input per game state. We can observe that although a considerable amount of information can be inferred from the maps (e.g., the damage dealt thanks to unit health heatmaps or the presence of units at a particular game state), the CNN model performs significantly worse for the task, achieving an F1-score of only <math alttext="0.59" class="ltx_Math" display="inline" id="S4.SS1.p4.1.m1.1"><semantics id="S4.SS1.p4.1.m1.1a"><mn id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">0.59</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><cn id="S4.SS1.p4.1.m1.1.1.cmml" type="float" xref="S4.SS1.p4.1.m1.1.1">0.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">0.59</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.1.m1.1d">0.59</annotation></semantics></math>. The RNN network alone is slightly inferior to the full approach in terms of F1-score but exhibits significantly lower precision. Combining the RNN and CNN components drastically enhances precision and slightly improves the F1-score as well.</p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1">Our method achieves better results in differentiating human players from bots compared to most results reported in the literature for different games. For instance, in Pac-Man <cite class="ltx_cite ltx_citemacro_cite">Miranda et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib35" title="">2017</a>)</cite>, the differentiation had a success rate of <math alttext="74\%" class="ltx_Math" display="inline" id="S4.SS1.p5.1.m1.1"><semantics id="S4.SS1.p5.1.m1.1a"><mrow id="S4.SS1.p5.1.m1.1.1" xref="S4.SS1.p5.1.m1.1.1.cmml"><mn id="S4.SS1.p5.1.m1.1.1.2" xref="S4.SS1.p5.1.m1.1.1.2.cmml">74</mn><mo id="S4.SS1.p5.1.m1.1.1.1" xref="S4.SS1.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.1.m1.1b"><apply id="S4.SS1.p5.1.m1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p5.1.m1.1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1.1">percent</csymbol><cn id="S4.SS1.p5.1.m1.1.1.2.cmml" type="integer" xref="S4.SS1.p5.1.m1.1.1.2">74</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.1.m1.1c">74\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.1.m1.1d">74 %</annotation></semantics></math>. However, it is inappropriate to compare human-like assessment models for agents across different games. As discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#S2" title="2. Discussion of the Challenges ‣ The Many Challenges of Human-Like Agents in Virtual Game Environments"><span class="ltx_text ltx_ref_tag">2</span></a>, not only do different environments allow for different expressions of believability, but also the perception of it depends on how the AI was created. For example, both extremely weak and extremely strong AI agents would likely be considered not human-like. The conclusions stemming from these observations will be discussed in the next section.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusions</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Games have transcended mere entertainment. They also serve as experimental platforms for various algorithms and AI techniques. Developing models to distinguish accurately between humans and AI bots presents unique opportunities in several domains including fake information detection, identity verification (e.g., in educational, healthcare, financial transactions, creative industries, job recruitment, and online dating), scam prevention, and other illegal or immoral activities, along with measuring AI progress. The inspirations trace back to the <em class="ltx_emph ltx_font_italic" id="S5.p1.1.1">Imitation Game</em>, potentially paving the way for next-generation <em class="ltx_emph ltx_font_italic" id="S5.p1.1.2">CAPTCHAS</em>.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">In the first part of the paper, we explored various aspects involved in the creation and evaluation of believable AI agents. These include the diversity of human players, the complexity of the action spaces, the challenges of scalability, avoiding superhuman capabilities, introducing idle and non-relevant actions, considering biological constraints, incorporating emotional elements, handling uncertainty, adaptability, allowing bots to make and recover from mistakes, training human-like AI, simulating social norms, and challenges related to specific human-like activities within the game.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">In the subsequent part, we addressed the challenge of constructing a model for assessing AI in terms of human-likeness within the game <em class="ltx_emph ltx_font_italic" id="S5.p3.1.1">Tactical Troops: Anthracite Shift</em>. By integrating deep convolutional and recurrent neural networks, we achieved an F1-Score of <math alttext="0.92" class="ltx_Math" display="inline" id="S5.p3.1.m1.1"><semantics id="S5.p3.1.m1.1a"><mn id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">0.92</mn><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><cn id="S5.p3.1.m1.1.1.cmml" type="float" xref="S5.p3.1.m1.1.1">0.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">0.92</annotation><annotation encoding="application/x-llamapun" id="S5.p3.1.m1.1d">0.92</annotation></semantics></math>, marking a substantial enhancement from a prior approach that utilized XGBoost and a simpler training configuration. The proposed architecture is relatively general (combining visual spatial data with numeric data), so it can serve as an inspiration for ML models for similar tasks.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">We propose an open hypothesis that <span class="ltx_text ltx_font_bold" id="S5.p4.1.1">the complexity involved in creating human-like agents in a particular environment correlates inversely with the ease of developing methods to distinguish between humans and bots in that environment</span>. We invite researchers to engage with this hypothesis to validate or refute it.</p>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">We contend that a human-likeness assessment model can serve as an automated quality assurance tool in the development of AI players. This model and the agents can be iteratively refined. The process would start with creating weak bots, which the model would not classify as human-like, and progressively aim to deceive the model through enhancements. Once the model erroneously classifies these improved bots as humans (false positive), it would be judicious to retrain the model.</p>
</div>
<div class="ltx_para" id="S5.p6">
<p class="ltx_p" id="S5.p6.1">The presence of human-like NPCs in games offers multiple benefits. Primarily, they enhance the gaming experience by balancing realism and playing strength <cite class="ltx_cite ltx_citemacro_cite">Soni and Hingston (<a class="ltx_ref" href="https://arxiv.org/html/2505.20011v1#bib.bib47" title="">2008</a>)</cite>. Additionally, they can reduce the “cold start” effect in massively multiplayer online games until a critical mass of human players is achieved. Furthermore, they facilitate more precise testing by simulating human player behaviors. Human-likeness assessment models also have broader applications, such as bot detection in environments where bot usage by players is considered unfair and is strictly prohibited.</p>
</div>
<div class="ltx_para" id="S5.p7">
<p class="ltx_p" id="S5.p7.1">Driven by these various motivations, we will soon organize an open machine learning competition hosted at <em class="ltx_emph ltx_font_italic" id="S5.p7.1.1">knowledgepit.ai</em> platform. Based on data from <em class="ltx_emph ltx_font_italic" id="S5.p7.1.2">Tactical Troops: Anthracite Shift</em> provided by us, the task will be to create a model that differentiates human players from bots. The method presented in this article will serve as a baseline.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arinbjarnar and Kudenko (2012)</span>
<span class="ltx_bibblock">
Maria Arinbjarnar and Daniel Kudenko. 2012.

</span>
<span class="ltx_bibblock">Actor Bots.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Believable Bots: Can Computers Play Like People?</em>, Philip Hingston (Ed.). Springer-Verlag, Berlin, 69–97.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-642-32323-2_3" title="">https://doi.org/10.1007/978-3-642-32323-2_3</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arzate Cruz and Ramirez Uresti (2018)</span>
<span class="ltx_bibblock">
Christian Arzate Cruz and Jorge Adolfo Ramirez Uresti. 2018.

</span>
<span class="ltx_bibblock">HRLB2̂: A Reinforcement Learning Based Framework for Believable Bots.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Applied Sciences</em> 8, 12 (2018), 2453.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bailey et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Christine Bailey, Jiaming You, Gavan Acton, Adam Rankin, and Michael Katchabaw. 2012.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Believability Through Psychosocial Behaviour: Creating Bots That Are More Engaging and Entertaining</em>.

</span>
<span class="ltx_bibblock">Springer Berlin Heidelberg, Berlin, Heidelberg, 29–68.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-642-32323-2_2" title="">https://doi.org/10.1007/978-3-642-32323-2_2</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bogdanovych et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Anton Bogdanovych, Tomas Trescak, and Simeon Simoff. 2015.

</span>
<span class="ltx_bibblock">Formalising Believability and Building Believable Virtual Agents. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">Artificial Life and Computational Intelligence: First Australasian Conference, ACALCI 2015, February 5-7, 2015. Proceedings 1</em>. Springer, Newcastle, NSW, Australia, 142–156.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bogdanovych et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Anton Bogdanovych, Tomas Trescak, and Simeon Simoff. 2016.

</span>
<span class="ltx_bibblock">What Makes Virtual Agents Believable?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Connection Science</em> 28, 1 (2016), 83–108.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bryant and Miikkulainen (2006)</span>
<span class="ltx_bibblock">
Bobby D. Bryant and Risto Miikkulainen. 2006.

</span>
<span class="ltx_bibblock">Evolving Stochastic Controller Networks for Intelligent Game Agents. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">2006 IEEE International Conference on Evolutionary Computation</em>. 1007–1014.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/CEC.2006.1688419" title="">https://doi.org/10.1109/CEC.2006.1688419</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Campbell et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2002)</span>
<span class="ltx_bibblock">
Murray Campbell, A Joseph Hoane Jr, and Feng-hsiung Hsu. 2002.

</span>
<span class="ltx_bibblock">Deep Blue.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">Artificial Intelligence</em> 134, 1-2 (2002), 57–83.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/S0004-3702(01)00129-1" title="">https://doi.org/10.1016/S0004-3702(01)00129-1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cavazza (2000)</span>
<span class="ltx_bibblock">
Marc Cavazza. 2000.

</span>
<span class="ltx_bibblock">Al in Computer Games: Survey and Perspectives.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Virtual Reality</em> 5 (2000), 223–235.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cowling et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2012a)</span>
<span class="ltx_bibblock">
Peter I Cowling, Edward J Powley, and Daniel Whitehouse. 2012a.

</span>
<span class="ltx_bibblock">Information Set Monte Carlo Tree Search.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">IEEE Transactions on Computational Intelligence and AI in Games</em> 4, 2 (2012), 120–143.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cowling et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2012b)</span>
<span class="ltx_bibblock">
Peter I Cowling, Colin D Ward, and Edward J Powley. 2012b.

</span>
<span class="ltx_bibblock">Ensemble Determinization in Monte Carlo Tree Search for the Imperfect Information Card Game Magic: The Gathering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">IEEE Transactions on Computational Intelligence and AI in Games</em> 4, 4 (2012), 241–257.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ehrmann et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (1968)</span>
<span class="ltx_bibblock">
Jacques Ehrmann, Cathy Lewis, and Phil Lewis. 1968.

</span>
<span class="ltx_bibblock">Homo Ludens Revisited.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Yale French Studies</em> 41 (1968), 31–57.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elsayed and King (2017)</span>
<span class="ltx_bibblock">
Salma Elsayed and David J King. 2017.

</span>
<span class="ltx_bibblock">Affect and Believability in Game Characters: A Review of the Use of Affective Computing in Games. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">GAME-ON’2017, 18th annual Conference on Simulation and AI in Computer Games</em>. EUROSIS, 90–97.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gamez et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
David Gamez, Zafeirios Fountas, and Andreas K Fidjeland. 2012.

</span>
<span class="ltx_bibblock">A Neurally Controlled Computer Game Avatar with Humanlike Behavior.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">IEEE Transactions on Computational Intelligence and AI in Games</em> 5, 1 (2012), 1–14.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gelly et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Sylvain Gelly, Levente Kocsis, Marc Schoenauer, Michèle Sebag, David Silver, Csaba Szepesvári, and Olivier Teytaud. 2012.

</span>
<span class="ltx_bibblock">The Grand Challenge of Computer Go: Monte Carlo Tree Search and Extensions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">Communications ACM</em> 55, 3 (March 2012), 106–113.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2093548.2093574" title="">https://doi.org/10.1145/2093548.2093574</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Georgeff et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (1999)</span>
<span class="ltx_bibblock">
Michael Georgeff, Barney Pell, Martha Pollack, Milind Tambe, and Michael Wooldridge. 1999.

</span>
<span class="ltx_bibblock">The Belief-Desire-Intention Model of Agency. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Intelligent Agents V: Agents Theories, Architectures, and Languages: 5th International Workshop, ATAL’98 Paris, France, July 4–7, 1998 Proceedings 5</em>. Springer, 1–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hecker et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Simon Hecker, Dengxin Dai, Alexander Liniger, Martin Hahner, and Luc Van Gool. 2020.

</span>
<span class="ltx_bibblock">Learning Accurate and Human-Like Driving Using Semantic Maps and Attention. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>. IEEE, 2346–2353.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hessel et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Matteo Hessel, Joseph Modayil, Hado Van Hasselt, Tom Schaul, Georg Ostrovski, Will Dabney, Dan Horgan, Bilal Piot, Mohammad Azar, and David Silver. 2018.

</span>
<span class="ltx_bibblock">Rainbow: Combining Improvements in Deep Reinforcement Learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Proceedings of the AAAI conference on artificial intelligence</em>, Vol. 32. 3215–3222.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hingston (2009)</span>
<span class="ltx_bibblock">
Philip Hingston. 2009.

</span>
<span class="ltx_bibblock">A Turing Test for Computer Game Bots.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">IEEE Transactions on Computational Intelligence and AI in Games</em> 1, 3 (2009), 169–186.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izard (2013)</span>
<span class="ltx_bibblock">
Carroll E Izard. 2013.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Human Emotions</em>.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johansson (2013)</span>
<span class="ltx_bibblock">
Magnus Johansson. 2013.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Do non player characters dream of electric sheep?: A thesis about players, npcs, immersion and believability</em>.

</span>
<span class="ltx_bibblock">Ph.D. Dissertation. Department of Computer and Systems Sciences, Stockholm University.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpov et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Igor V Karpov, Jacob Schrum, and Risto Miikkulainen. 2012.

</span>
<span class="ltx_bibblock">Believable Bot Navigation via Playback of Human Traces.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Believable Bots: Can Computers Play Like People?</em> Springer, 151–170.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-642-32323-2_6" title="">https://doi.org/10.1007/978-3-642-32323-2_6</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khalifa et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Ahmed Khalifa, Aaron Isaksen, Julian Togelius, and Andy Nealen. 2016.

</span>
<span class="ltx_bibblock">Modifying MCTS for Human-Like General Video Game Playing. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</em> (New York, New York, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib23.4.2">(IJCAI’16)</em>. AAAI Press, 2514–2520.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kurke (1999)</span>
<span class="ltx_bibblock">
Leslie Kurke. 1999.

</span>
<span class="ltx_bibblock">Ancient Greek Board Games and How to Play Them.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Classical philology</em> 94, 3 (1999), 247–267.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laird (2002)</span>
<span class="ltx_bibblock">
John Laird. 2002.

</span>
<span class="ltx_bibblock">Research in Human-Level AI using Computer Games.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Commun. ACM</em> 45 (01 2002), 32–35.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/502269.502290" title="">https://doi.org/10.1145/502269.502290</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laird and VanLent (2001)</span>
<span class="ltx_bibblock">
John Laird and Michael VanLent. 2001.

</span>
<span class="ltx_bibblock">Human-Level AI’s Killer Application: Interactive Computer Games.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">AI Magazine</em> 22, 2 (Jun. 2001), 15–26.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1609/aimag.v22i2.1558" title="">https://doi.org/10.1609/aimag.v22i2.1558</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee and Heeter (2012)</span>
<span class="ltx_bibblock">
Michael Sangyeob Lee and Carrie Heeter. 2012.

</span>
<span class="ltx_bibblock">What do you mean by believable characters?: The effect of character rating and hostility on the perception of character believability.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Journal of Gaming &amp; Virtual Worlds</em> 4, 1 (2012), 81–97.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1386/jgvw.4.1.81_1" title="">https://doi.org/10.1386/jgvw.4.1.81_1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lidén (2003)</span>
<span class="ltx_bibblock">
Lars Lidén. 2003.

</span>
<span class="ltx_bibblock">Artificial Stupidity: The Art of Intentional Mistakes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">AI Game Programming Wisdom</em> 2, 5 (2003), 41–48.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Livingstone (2006)</span>
<span class="ltx_bibblock">
Daniel Livingstone. 2006.

</span>
<span class="ltx_bibblock">Turing’s Test and Believable AI in Games.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Computers in Entertainment (CIE)</em> 4, 1 (2006), 6–19.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1111293.1111303" title="">https://doi.org/10.1145/1111293.1111303</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mańdziuk and Szałaj (2012)</span>
<span class="ltx_bibblock">
Jacek Mańdziuk and Przemysław Szałaj. 2012.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Creating a Personality System for RTS Bots</em>.

</span>
<span class="ltx_bibblock">Springer Berlin Heidelberg, Berlin, Heidelberg, 231–264.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-642-32323-2_10" title="">https://doi.org/10.1007/978-3-642-32323-2_10</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marques et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Nuno Marques, Francisco Melo, Samuel Mascarenhas, Joao Dias, Rui Prada, and Ana Paiva. 2013.

</span>
<span class="ltx_bibblock">Towards Agents with Human-Like Decisions Under Uncertainty. In <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Proceedings of the Annual Meeting of the Cognitive Science Society</em>, Vol. 35. 2978–2983.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCarthy (1990)</span>
<span class="ltx_bibblock">
John McCarthy. 1990.

</span>
<span class="ltx_bibblock">Chess as the Drosophila of AI.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Computers, Chess, and Cognition</em>, T. Anthony Marsland and Jonathan Schaeffer (Eds.). Springer, 227–237.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Milani et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Stephanie Milani, Arthur Juliani, Ida Momennejad, Raluca Georgescu, Jaroslaw Rzepecki, Alison Shaw, Gavin Costello, Fei Fang, Sam Devlin, and Katja Hofmann. 2023.

</span>
<span class="ltx_bibblock">Navigates Like Me: Understanding How People Evaluate Human-Like AI in Video Games. In <em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</em>. 1–18.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Millington (2019)</span>
<span class="ltx_bibblock">
Ian Millington. 2019.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">AI for Games</em>.

</span>
<span class="ltx_bibblock">CRC Press.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miranda et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Maximiliano Miranda, Antonio A. Sánchez-Ruiz-Granados, and Federico Peinado. 2017.

</span>
<span class="ltx_bibblock">Pac-Man or Pac-Bot? Exploring Subjective Perception of Players’ Humanity in Ms. Pac-Man. In <em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">Conference of the Spanish Association for Videogames Sciences</em>. 1–12.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:45425351" title="">https://api.semanticscholar.org/CorpusID:45425351</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moor (1976)</span>
<span class="ltx_bibblock">
James H Moor. 1976.

</span>
<span class="ltx_bibblock">An Analysis of the Turing Test.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Philosophical Studies: An International Journal for Philosophy in the Analytic Tradition</em> 30, 4 (1976), 249–257.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Morita and Hosobe (2023)</span>
<span class="ltx_bibblock">
Takahiro Morita and Hiroshi Hosobe. 2023.

</span>
<span class="ltx_bibblock">Video Game Agents with Human-like Behavior using the Deep Q-Network and Biological Constraints. In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of ICAART 2023</em>, Ana Paula Rocha, Luc Steels, and Jaap van den Herik (Eds.), Vol. 3. 525–531.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5220/0011697500003393" title="">https://doi.org/10.5220/0011697500003393</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nejati et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2006)</span>
<span class="ltx_bibblock">
Negin Nejati, Pat Langley, and Tolga Konik. 2006.

</span>
<span class="ltx_bibblock">Learning Hierarchical Task Networks by Observation. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">Proceedings of the 23rd international conference on Machine learning</em>, William W. Cohen and Andrew W. Moore (Eds.). 665–672.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI et al<span class="ltx_text" id="bib.bib39.4.4.1">.</span> (2019)</span>
<span class="ltx_bibblock">
OpenAI, Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław D<span class="ltx_ERROR undefined" id="bib.bib39.5.1">\k</span>ebiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris Hesse, et al<span class="ltx_text" id="bib.bib39.6.2">.</span> 2019.

</span>
<span class="ltx_bibblock">Dota 2 with Large Scale Deep Reinforcement Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1912.06680

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/1912.06680" title="">https://arxiv.org/abs/1912.06680</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rabin (2013)</span>
<span class="ltx_bibblock">
Steven Rabin. 2013.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Game AI Pro: Collected Wisdom of Game AI Professionals</em>.

</span>
<span class="ltx_bibblock">CRC Press.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">ISBN=978-1466565968.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rankin et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2010)</span>
<span class="ltx_bibblock">
Adam Rankin, Gavan Acton, and Michael Katchabaw. 2010.

</span>
<span class="ltx_bibblock">A Scalable Approach to Believable Non Player Characters in Modern Video Games. In <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">Proceedings of 11-th International Conference on Intelligent Games and Simulation</em>, Alladin Ayesh (Ed.), Vol. 2010. 8.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Samuel (1959)</span>
<span class="ltx_bibblock">
Arthur L Samuel. 1959.

</span>
<span class="ltx_bibblock">Some Studies in Machine Learning Using the Game of Checkers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">IBM Journal of Research and Development</em> 3, 3 (1959), 210–229.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1147/rd.33.0210" title="">https://doi.org/10.1147/rd.33.0210</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schaeffer et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2007)</span>
<span class="ltx_bibblock">
Jonathan Schaeffer, Neil Burch, Yngvi Bjornsson, Akihiro Kishimoto, Martin Muller, Robert Lake, Paul Lu, and Steve Sutphen. 2007.

</span>
<span class="ltx_bibblock">Checkers is Solved.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">science</em> 317, 5844 (2007), 1518–1522.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1126/science.1144079" title="">https://doi.org/10.1126/science.1144079</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schrum et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Jacob Schrum, Igor V. Karpov, and Risto Miikkulainen. 2012.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">Human-Like Combat Behaviour via Multiobjective Neuroevolution</em>.

</span>
<span class="ltx_bibblock">Springer Berlin Heidelberg, Berlin, Heidelberg, 119–150.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-642-32323-2_5" title="">https://doi.org/10.1007/978-3-642-32323-2_5</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silver et al<span class="ltx_text" id="bib.bib45.3.3.1">.</span> (2016)</span>
<span class="ltx_bibblock">
David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al<span class="ltx_text" id="bib.bib45.4.1">.</span> 2016.

</span>
<span class="ltx_bibblock">Mastering the Game of Go with Deep Neural Networks and Tree Search.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.5.1">Nature</em> 529, 7587 (2016), 484–489.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1038/nature16961" title="">https://doi.org/10.1038/nature16961</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silver et al<span class="ltx_text" id="bib.bib46.3.3.1">.</span> (2017)</span>
<span class="ltx_bibblock">
David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al<span class="ltx_text" id="bib.bib46.4.1">.</span> 2017.

</span>
<span class="ltx_bibblock">Mastering the game of Go without human knowledge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.5.1">Nature</em> 550, 7676 (2017), 354–359.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1038/nature24270" title="">https://doi.org/10.1038/nature24270</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soni and Hingston (2008)</span>
<span class="ltx_bibblock">
Bhuman Soni and Philip Hingston. 2008.

</span>
<span class="ltx_bibblock">Bots Trained to Play Like a Human are More Fun. In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)</em>. IEEE, 363–369.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/IJCNN.2008.4633818" title="">https://doi.org/10.1109/IJCNN.2008.4633818</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Świechowski (2020)</span>
<span class="ltx_bibblock">
Maciej Świechowski. 2020.

</span>
<span class="ltx_bibblock">Game AI Competitions: Motivation for the Imitation Game-Playing Competition. In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">2020 Federated Conference on Computer Science and Information Systems (FedCSIS)</em>, Maria Ganzha, Leszek Maciaszek, and Marcin Paprzycki (Eds.), Vol. 21. IEEE, 155–160.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Świechowski et al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Maciej Świechowski, Konrad Godlewski, Bartosz Sawicki, and Jacek Mańdziuk. 2023.

</span>
<span class="ltx_bibblock">Monte Carlo Tree Search: A Review of Recent Modifications and Applications.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">Artificial Intelligence Review</em> 56 (2023), 2497–2562.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s10462-022-10228-y" title="">https://doi.org/10.1007/s10462-022-10228-y</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Świechowski et al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Maciej Świechowski, Daniel Lewiński, and Rafał Tyl. 2021.

</span>
<span class="ltx_bibblock">Combining Utility AI and MCTS Towards Creating Intelligent Agents in Video Games, with the Use Case of Tactical Troops: Anthracite Shift. In <em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">2021 IEEE Symposium Series on Computational Intelligence (SSCI)</em>. 1–8.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/SSCI50451.2021.9660170" title="">https://doi.org/10.1109/SSCI50451.2021.9660170</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tencé et al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2010)</span>
<span class="ltx_bibblock">
Fabien Tencé, Cédric Buche, Pierre De Loor, and Olivier Marc. 2010.

</span>
<span class="ltx_bibblock">The Challenge of Believability in Video Games: Definitions, Agents Models and Imitation Learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">Proceedings of GAMEON-ASIA’2010</em>, Wenji Mao and Lode Vermeersch (Eds.). 38–45.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Togelius et al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Julian Togelius, Georgios N Yannakakis, Sergey Karakovskiy, and Noor Shaker. 2012.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.3.1">Assessing Believability</em>.

</span>
<span class="ltx_bibblock">Springer Publishing Company, 215–230.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vinyals et al<span class="ltx_text" id="bib.bib53.3.3.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al<span class="ltx_text" id="bib.bib53.4.1">.</span> 2019.

</span>
<span class="ltx_bibblock">Grandmaster level in StarCraft II using multi-agent reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.5.1">Nature</em> 575, 7782 (2019), 350–354.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1038/s41586-019-1724-z" title="">https://doi.org/10.1038/s41586-019-1724-z</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2009)</span>
<span class="ltx_bibblock">
Di Wang, Budhitama Subagdja, Ah-Hwee Tan, and Gee-Wah Ng. 2009.

</span>
<span class="ltx_bibblock">Creating Human-like Autonomous Players in Real-time First Person Shooter Computer Games. In <em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">Proceedings of Twenty-First IAAI Conference</em>, Karen Haigh and Nestor Rychtyckyj (Eds.). 173–178.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Warpefelt et al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Henrik Warpefelt, Magnus Johansson, and Harko Verhagen. 2013.

</span>
<span class="ltx_bibblock">Analyzing the Believability of Game Character Behavior Using the Game Agent Matrix. In <em class="ltx_emph ltx_font_italic" id="bib.bib55.3.1">Proceedings of DiGRA 2013 Conference</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Warwick and Shah (2016)</span>
<span class="ltx_bibblock">
Kevin Warwick and Huma Shah. 2016.

</span>
<span class="ltx_bibblock">Can Machines Think? A Report on Turing Test Experiments at the Royal Society.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Journal of experimental &amp; Theoretical artificial Intelligence</em> 28, 6 (2016), 989–1007.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weiss and Tscheligi (2012)</span>
<span class="ltx_bibblock">
Astrid Weiss and Manfred Tscheligi. 2012.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Rethinking the Human–Agent Relationship: Which Social Cues Do Interactive Agents Really Need to Have?</em>
</span>
<span class="ltx_bibblock">Springer Berlin Heidelberg, Berlin, Heidelberg, 1–28.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-642-32323-2_1" title="">https://doi.org/10.1007/978-3-642-32323-2_1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib58.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Minerva Wu, Je Seok Lee, and Constance Steinkuehler. 2021.

</span>
<span class="ltx_bibblock">Understanding Tilt in Esports: A study on Young League of Legends Players. In <em class="ltx_emph ltx_font_italic" id="bib.bib58.3.1">Proceedings of the 2021 CHI conference on human factors in computing systems</em>, Yoshifumi Kitamura (Ed.). ACM New York, 1–9.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3411764.3445143" title="">https://doi.org/10.1145/3411764.3445143</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zadeh (2008)</span>
<span class="ltx_bibblock">
Lotfi A Zadeh. 2008.

</span>
<span class="ltx_bibblock">Toward human level machine intelligence-is it achievable? the need for a paradigm shift.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">IEEE Computational Intelligence Magazine</em> 3, 3 (2008), 11–22.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zuchowska et al<span class="ltx_text" id="bib.bib60.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Laura Zuchowska, Krzysztof Kutt, and Grzegorz J Nalepa. 2021.

</span>
<span class="ltx_bibblock">Bartle Taxonomy-based Game for Affective and Personality Computing Research. In <em class="ltx_emph ltx_font_italic" id="bib.bib60.3.1">Twelfth International Workshop Modelling and Reasoning in Context @ IJCAI</em>, Jörg Cassens, Rebekah Wegener, and Anders Kofod-Petersen (Eds.). 51–55.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon May 26 13:47:27 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
