<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning</title>
<!--Generated on Mon May 26 17:18:45 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2505.20241v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S1" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S2" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S3" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Problem Setting and Preliminaries</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S3.SS0.SSS0.Px1" title="In 3 Problem Setting and Preliminaries ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Notations.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S3.SS0.SSS0.Px2" title="In 3 Problem Setting and Preliminaries ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">PRM training with Monte Carlo signals.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S3.SS0.SSS0.Px3" title="In 3 Problem Setting and Preliminaries ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">PRM-based inference with aggregation function.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S3.SS0.SSS0.Px4" title="In 3 Problem Setting and Preliminaries ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Bi-level optimization.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S4" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>The Proposed Domain-reweighting Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S4.SS0.SSS0.Px1" title="In 4 The Proposed Domain-reweighting Method ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Overview.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S4.SS0.SSS0.Px2" title="In 4 The Proposed Domain-reweighting Method ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Datasets.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S4.SS0.SSS0.Px3" title="In 4 The Proposed Domain-reweighting Method ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Lower-level optimization: domain-reweighted training of PRM.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S4.SS0.SSS0.Px4" title="In 4 The Proposed Domain-reweighting Method ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Upper-level optimization: learning domain reweighting parameters.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimental Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS1" title="In 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Datasets and benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS2" title="In 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Experimental settings</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS2.SSS0.Px1" title="In 5.2 Experimental settings ‣ 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Multistage reasoning.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS2.SSS0.Px2" title="In 5.2 Experimental settings ‣ 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Base models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS2.SSS0.Px3" title="In 5.2 Experimental settings ‣ 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Training hyperparameters.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS2.SSS0.Px4" title="In 5.2 Experimental settings ‣ 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Baselines.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS3" title="In 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Benchmark evaluation of DreamPRM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS4" title="In 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Scaling and generalization analysis of DreamPRM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS5" title="In 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Ablation study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS6" title="In 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.6 </span>Analysis of learned domain weights</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S6" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A1" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A1.SS0.SSS0.Px1" title="In Appendix A Related Works ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Multimodal Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A1.SS0.SSS0.Px2" title="In Appendix A Related Works ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Process Reward Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A1.SS0.SSS0.Px3" title="In Appendix A Related Works ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title">Domain Reweighting</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A2" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Optimization algorithm</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A3" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Dataset Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A4" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Structural Thinking Prompt</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A5" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Additional Experimental Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A6" title="In DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Limitations &amp; Future Work.</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Qi Cao  Ruiyi Wang  Ruiyi Zhang  Sai Ashish Somayajula  Pengtao Xie
<br class="ltx_break"/>University of California, San Diego 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{q9cao,ruiyi,ruz048,ssomayaj,p1xie}@ucsd.edu</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Reasoning has substantially improved the performance of large language models (LLMs) on complicated tasks. Central to the current reasoning studies, Process Reward Models (PRMs) offer a fine-grained evaluation of intermediate reasoning steps and guide the reasoning process. However, extending PRMs to multimodal large language models (MLLMs) introduces challenges. Since multimodal reasoning covers a wider range of tasks compared to text-only scenarios, the resulting distribution shift from the training to testing sets is more severe, leading to greater generalization difficulty. Training a reliable multimodal PRM, therefore, demands large and diverse datasets to ensure sufficient coverage. However, current multimodal reasoning datasets suffer from a marked quality imbalance, which degrades PRM performance and highlights the need for an effective data selection strategy. To address the issues, we introduce DreamPRM, a domain-reweighted training framework for multimodal PRMs which employs bi-level optimization. In the lower-level optimization, DreamPRM performs fine-tuning on multiple datasets with domain weights, allowing the PRM to prioritize high-quality reasoning signals and alleviating the impact of dataset quality imbalance. In the upper-level optimization, the PRM is evaluated on a separate meta-learning dataset; this feedback updates the domain weights through an aggregation loss function, thereby improving the generalization capability of trained PRM. Extensive experiments on multiple multimodal reasoning benchmarks covering both mathematical and general reasoning show that test-time scaling with DreamPRM consistently improves the performance of state-of-the-art MLLMs. Further comparisons reveal that DreamPRM’s domain-reweighting strategy surpasses other data selection methods and yields higher accuracy gains than existing test-time scaling approaches.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Reasoning <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib49" title=""><span class="ltx_text" style="font-size:80%;">49</span></a>]</cite> has significantly enhanced the logical and critical thinking capabilities of large language models (LLMs) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib1" title=""><span class="ltx_text" style="font-size:80%;">1</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib7" title=""><span class="ltx_text" style="font-size:80%;">7</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib52" title=""><span class="ltx_text" style="font-size:80%;">52</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib43" title=""><span class="ltx_text" style="font-size:80%;">43</span></a>]</cite>. Post-training  <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib39" title=""><span class="ltx_text" style="font-size:80%;">39</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib9" title=""><span class="ltx_text" style="font-size:80%;">9</span></a>]</cite> and test-time scaling strategies <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib38" title=""><span class="ltx_text" style="font-size:80%;">38</span></a>]</cite> enable sophisticated reasoning behaviors in LLMs and extend the length of Chain-of-Thoughts (CoTs) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib62" title=""><span class="ltx_text" style="font-size:80%;">62</span></a>]</cite>, thereby achieving strong results on challenging benchmarks <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib71" title=""><span class="ltx_text" style="font-size:80%;">71</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib41" title=""><span class="ltx_text" style="font-size:80%;">41</span></a>]</cite>. A key component of these advances is the Process Reward Models (PRMs) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib26" title=""><span class="ltx_text" style="font-size:80%;">26</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib24" title=""><span class="ltx_text" style="font-size:80%;">24</span></a>]</cite>, which provide fine-grained, step-wise supervision of the reasoning process and reliable selection of high-quality reasoning trajectories. These developments are proven highly effective for improving the performance of LLMs in complex tasks <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib35" title=""><span class="ltx_text" style="font-size:80%;">35</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib53" title=""><span class="ltx_text" style="font-size:80%;">53</span></a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Given the success with LLMs, a natural extension is to apply PRMs to multimodal large language models (MLLMs) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib63" title=""><span class="ltx_text" style="font-size:80%;">63</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib25" title=""><span class="ltx_text" style="font-size:80%;">25</span></a>]</cite> to enhance their reasoning abilities. Early studies of multimodal PRMs demonstrate promise results, yet substantial challenges persist. Distinct from text-only inputs of LLMs, MLLMs must combine diverse visual and language signals: a high-dimensional, continuous image space coupled with discrete language tokens. This fusion dramatically broadens the input manifold and leads to more severe <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">distribution shifts</em> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib50" title=""><span class="ltx_text" style="font-size:80%;">50</span></a>]</cite> from training to testing distributions. Consequently, directly utilizing PRM training strategies from the text domain <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib60" title=""><span class="ltx_text" style="font-size:80%;">60</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib34" title=""><span class="ltx_text" style="font-size:80%;">34</span></a>]</cite> underperforms, mainly due to the decreased generalizability <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib10" title=""><span class="ltx_text" style="font-size:80%;">10</span></a>]</cite> caused by the insufficient coverage of the multimodal input space.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">A straightforward solution to this problem is to combine multiple datasets that emphasize different multimodal reasoning skills, thereby enlarging the sampling space. However, <em class="ltx_emph ltx_font_italic" id="S1.p3.1.1">quality imbalance</em> among existing multimodal reasoning datasets is more severe than in text-only settings: many contain noisy inputs such as unnecessary modalities <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib69" title=""><span class="ltx_text" style="font-size:80%;">69</span></a>]</cite> or questions of negligible difficulty <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib30" title=""><span class="ltx_text" style="font-size:80%;">30</span></a>]</cite>, as illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">1</span></a>. Since these easy datasets contribute little to effective sampling, paying much attention to them can substantially degrade PRM performance. Therefore, an effective data selection strategy that filters out unreliable datasets and instances is crucial to training a high-quality multimodal PRM.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To overcome these challenges, we propose DreamPRM, a domain-reweighted training framework for multimodal PRMs. Inspired by domain-reweighting techniques <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib47" title=""><span class="ltx_text" style="font-size:80%;">47</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib11" title=""><span class="ltx_text" style="font-size:80%;">11</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib51" title=""><span class="ltx_text" style="font-size:80%;">51</span></a>]</cite>, DreamPRM dynamically learns appropriate weights for each multimodal reasoning dataset, allowing them to contribute unequally during training. Datasets that contain many noisy samples tend to receive lower domain weights, reducing their influence on PRM parameter updates. Conversely, high-quality datasets are assigned higher weights and thus play a more important role in optimization. This domain-reweighting strategy alleviates the issue of dataset quality imbalances. DreamPRM adopts a bi-level optimization (BLO) framework <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib13" title=""><span class="ltx_text" style="font-size:80%;">13</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib28" title=""><span class="ltx_text" style="font-size:80%;">28</span></a>]</cite> to jointly learn the domain weights and PRM parameters. At the lower level, the PRM parameters are optimized with Monte Carlo signals on multiple training domains under different domain weights. At the upper level, the optimized PRM is evaluated on a separate meta domain to compute a novel aggregation function loss, which is used to optimized the domain weights. Extensive experiments on a wide range of multimodal reasoning benchmarks verify the effectiveness of DreamPRM.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="423" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.9.2.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text ltx_font_bold" id="S1.F1.2.1" style="font-size:90%;">DreamPRM improves multimodal reasoning by mitigating the dataset quality imbalance problem.<span class="ltx_text ltx_font_medium" id="S1.F1.2.1.2"> </span>Left<span class="ltx_text ltx_font_medium" id="S1.F1.2.1.1">: On five benchmarks, DreamPRM outperforms base model (InternVL-2.5-8B-MPO <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib58" title=""><span class="ltx_text" style="font-size:80%;">58</span></a>]</cite>) by an average of <math alttext="+4.0\%" class="ltx_Math" display="inline" id="S1.F1.2.1.1.m1.1"><semantics id="S1.F1.2.1.1.m1.1b"><mrow id="S1.F1.2.1.1.m1.1.1" xref="S1.F1.2.1.1.m1.1.1.cmml"><mo id="S1.F1.2.1.1.m1.1.1b" xref="S1.F1.2.1.1.m1.1.1.cmml">+</mo><mrow id="S1.F1.2.1.1.m1.1.1.2" xref="S1.F1.2.1.1.m1.1.1.2.cmml"><mn id="S1.F1.2.1.1.m1.1.1.2.2" xref="S1.F1.2.1.1.m1.1.1.2.2.cmml">4.0</mn><mo id="S1.F1.2.1.1.m1.1.1.2.1" xref="S1.F1.2.1.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.2.1.1.m1.1c"><apply id="S1.F1.2.1.1.m1.1.1.cmml" xref="S1.F1.2.1.1.m1.1.1"><plus id="S1.F1.2.1.1.m1.1.1.1.cmml" xref="S1.F1.2.1.1.m1.1.1"></plus><apply id="S1.F1.2.1.1.m1.1.1.2.cmml" xref="S1.F1.2.1.1.m1.1.1.2"><csymbol cd="latexml" id="S1.F1.2.1.1.m1.1.1.2.1.cmml" xref="S1.F1.2.1.1.m1.1.1.2.1">percent</csymbol><cn id="S1.F1.2.1.1.m1.1.1.2.2.cmml" type="float" xref="S1.F1.2.1.1.m1.1.1.2.2">4.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.2.1.1.m1.1d">+4.0\%</annotation><annotation encoding="application/x-llamapun" id="S1.F1.2.1.1.m1.1e">+ 4.0 %</annotation></semantics></math>. DreamPRM also consistently surpasses Vanilla PRM trained without data selection. </span>Right<span class="ltx_text ltx_font_medium" id="S1.F1.2.1.3">: Easy <span class="ltx_text ltx_font_smallcaps" id="S1.F1.2.1.3.1">AI2D</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib21" title=""><span class="ltx_text" style="font-size:80%;">21</span></a>]</cite> questions (weight 0.55) vs. hard <span class="ltx_text ltx_font_smallcaps" id="S1.F1.2.1.3.2">M3CoT</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib5" title=""><span class="ltx_text" style="font-size:80%;">5</span></a>]</cite> questions (weight 1.49) shows how DreamPRM prioritizes data that demand deeper reasoning - samples requiring knowledge from both textual and visual modalities for step-by-step logical deduction.</span></span></figcaption>
</figure>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our contributions are summarized as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose DreamPRM, a <em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.1">domain-reweighted</em> multimodal process reward model training framework that dynamically adjusts the importance of different training domains. We formulate the training process of DreamPRM as a <em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.2">bi-level optimization</em> (BLO) problem, where the lower level optimizes the PRM via domain-reweighted fine-tuning, and the upper level optimizes domain weights with an aggregation function loss. Our method helps address dataset quality imbalance issue in multimodal reasoning, and improves the generalization ability of PRM.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We conduct extensive experiments using DreamPRM on a wide range of multimodal reasoning benchmarks. Results indicate that DreamPRM consistently surpasses PRM baselines with other data selection strategies, confirming the effectiveness of its bi-level optimization based domain-reweighting strategy. Carefully designed evaluations further demonstrate that DreamPRM possesses both scaling capability and generalization ability to stronger models.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Recent advances in <span class="ltx_text ltx_font_bold" id="S2.p1.1.1">multimodal reasoning</span> reveal that directly applying CoT prompting to MLLMs often triggers hallucinations. This motivates post-training and inference-time scaling remedies, such as mixed-preference optimization <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib58" title=""><span class="ltx_text" style="font-size:80%;">58</span></a>]</cite>, structured-thinking fine-tuning <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib65" title=""><span class="ltx_text" style="font-size:80%;">65</span></a>]</cite>, self-feedback length-normalized decoding <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib68" title=""><span class="ltx_text" style="font-size:80%;">68</span></a>]</cite>, and Monte Carlo Tree Search (MCTS)-guided retrieval-augmented search <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib10" title=""><span class="ltx_text" style="font-size:80%;">10</span></a>]</cite>. Complementary work on <span class="ltx_text ltx_font_bold" id="S2.p1.1.2">process reward models</span> replaces costly human-step supervision with Monte Carlo or MCTS-based automatic labeling to score intermediate reasoning steps <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib26" title=""><span class="ltx_text" style="font-size:80%;">26</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib55" title=""><span class="ltx_text" style="font-size:80%;">55</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib34" title=""><span class="ltx_text" style="font-size:80%;">34</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib60" title=""><span class="ltx_text" style="font-size:80%;">60</span></a>]</cite>. Meanwhile, <span class="ltx_text ltx_font_bold" id="S2.p1.1.3">domain-reweighting</span> techniques such as group distributionally robust optimization <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib64" title=""><span class="ltx_text" style="font-size:80%;">64</span></a>]</cite>, first-order bi-level optimization <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib12" title=""><span class="ltx_text" style="font-size:80%;">12</span></a>]</cite>, and data-mixing scaling laws <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib67" title=""><span class="ltx_text" style="font-size:80%;">67</span></a>]</cite>, aim to adaptively balance heterogeneous corpora to boost generalization. Our method is related to all three lines of work as a domain-reweighted multimodal PRM. Owing to space constraints, the complete review is provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A1" title="Appendix A Related Works ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Problem Setting and Preliminaries</h2>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Notations.</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.10">Let <math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS0.SSS0.Px1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.1.m1.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.1.m1.1d">caligraphic_I</annotation></semantics></math>, <math alttext="\mathcal{T}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS0.SSS0.Px1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">𝒯</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.2.m2.1b"><ci id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1">𝒯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.2.m2.1c">\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.2.m2.1d">caligraphic_T</annotation></semantics></math>, and <math alttext="\mathcal{Y}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS0.SSS0.Px1.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml">𝒴</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.3.m3.1b"><ci id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1">𝒴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.3.m3.1c">\mathcal{Y}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.3.m3.1d">caligraphic_Y</annotation></semantics></math> denote the multimodal input space (images), textual instruction space, and response space, respectively. A multimodal large language model (MLLM) is formalized as a parametric mapping <math alttext="M_{\theta}:\mathcal{T}\times\mathcal{I}\to\Delta(\mathcal{Y})" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.4.m4.1"><semantics id="S3.SS0.SSS0.Px1.p1.4.m4.1a"><mrow id="S3.SS0.SSS0.Px1.p1.4.m4.1.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.cmml"><msub id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.cmml"><mi id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.2.cmml">M</mi><mi id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.3.cmml">θ</mi></msub><mo id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.1" lspace="0.278em" rspace="0.278em" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.1.cmml">:</mo><mrow id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.cmml"><mrow id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.2.cmml">𝒯</mi><mo id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.1" lspace="0.222em" rspace="0.222em" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.1.cmml">×</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.3.cmml">ℐ</mi></mrow><mo id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.1" stretchy="false" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.1.cmml">→</mo><mrow id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.2" mathvariant="normal" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.2.cmml">Δ</mi><mo id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.1.cmml">⁢</mo><mrow id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.3.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.cmml"><mo id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.3.2.1" stretchy="false" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.cmml">𝒴</mi><mo id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.3.2.2" stretchy="false" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2"><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.1">:</ci><apply id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.2">𝑀</ci><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.2.3">𝜃</ci></apply><apply id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3"><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.1">→</ci><apply id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2"><times id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.1"></times><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.2">𝒯</ci><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.2.3">ℐ</ci></apply><apply id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3"><times id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.1"></times><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.2.3.3.2">Δ</ci><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1">𝒴</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.4.m4.1c">M_{\theta}:\mathcal{T}\times\mathcal{I}\to\Delta(\mathcal{Y})</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.4.m4.1d">italic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT : caligraphic_T × caligraphic_I → roman_Δ ( caligraphic_Y )</annotation></semantics></math>, where <math alttext="\hat{y}\sim M_{\theta}(\cdot|x)" class="ltx_math_unparsed" display="inline" id="S3.SS0.SSS0.Px1.p1.5.m5.1"><semantics id="S3.SS0.SSS0.Px1.p1.5.m5.1a"><mrow id="S3.SS0.SSS0.Px1.p1.5.m5.1b"><mover accent="true" id="S3.SS0.SSS0.Px1.p1.5.m5.1.1"><mi id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2">y</mi><mo id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.1">^</mo></mover><mo id="S3.SS0.SSS0.Px1.p1.5.m5.1.2">∼</mo><msub id="S3.SS0.SSS0.Px1.p1.5.m5.1.3"><mi id="S3.SS0.SSS0.Px1.p1.5.m5.1.3.2">M</mi><mi id="S3.SS0.SSS0.Px1.p1.5.m5.1.3.3">θ</mi></msub><mrow id="S3.SS0.SSS0.Px1.p1.5.m5.1.4"><mo id="S3.SS0.SSS0.Px1.p1.5.m5.1.4.1" stretchy="false">(</mo><mo id="S3.SS0.SSS0.Px1.p1.5.m5.1.4.2" lspace="0em" rspace="0em">⋅</mo><mo fence="false" id="S3.SS0.SSS0.Px1.p1.5.m5.1.4.3" rspace="0.167em" stretchy="false">|</mo><mi id="S3.SS0.SSS0.Px1.p1.5.m5.1.4.4">x</mi><mo id="S3.SS0.SSS0.Px1.p1.5.m5.1.4.5" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.5.m5.1c">\hat{y}\sim M_{\theta}(\cdot|x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.5.m5.1d">over^ start_ARG italic_y end_ARG ∼ italic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( ⋅ | italic_x )</annotation></semantics></math> represents the stochastic generation of responses conditioned on input pair <math alttext="x=(t,I)" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.6.m6.2"><semantics id="S3.SS0.SSS0.Px1.p1.6.m6.2a"><mrow id="S3.SS0.SSS0.Px1.p1.6.m6.2.3" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.6.m6.2.3.2" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3.2.cmml">x</mi><mo id="S3.SS0.SSS0.Px1.p1.6.m6.2.3.1" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3.1.cmml">=</mo><mrow id="S3.SS0.SSS0.Px1.p1.6.m6.2.3.3.2" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3.3.1.cmml"><mo id="S3.SS0.SSS0.Px1.p1.6.m6.2.3.3.2.1" stretchy="false" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3.3.1.cmml">(</mo><mi id="S3.SS0.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.cmml">t</mi><mo id="S3.SS0.SSS0.Px1.p1.6.m6.2.3.3.2.2" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3.3.1.cmml">,</mo><mi id="S3.SS0.SSS0.Px1.p1.6.m6.2.2" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.2.cmml">I</mi><mo id="S3.SS0.SSS0.Px1.p1.6.m6.2.3.3.2.3" stretchy="false" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.6.m6.2b"><apply id="S3.SS0.SSS0.Px1.p1.6.m6.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3"><eq id="S3.SS0.SSS0.Px1.p1.6.m6.2.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3.1"></eq><ci id="S3.SS0.SSS0.Px1.p1.6.m6.2.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3.2">𝑥</ci><interval closure="open" id="S3.SS0.SSS0.Px1.p1.6.m6.2.3.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.3.3.2"><ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1">𝑡</ci><ci id="S3.SS0.SSS0.Px1.p1.6.m6.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.2.2">𝐼</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.6.m6.2c">x=(t,I)</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.6.m6.2d">italic_x = ( italic_t , italic_I )</annotation></semantics></math> including visual input <math alttext="I\in\mathcal{I}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.7.m7.1"><semantics id="S3.SS0.SSS0.Px1.p1.7.m7.1a"><mrow id="S3.SS0.SSS0.Px1.p1.7.m7.1.1" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.cmml">I</mi><mo id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.1" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3.cmml">ℐ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.7.m7.1b"><apply id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1"><in id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.1"></in><ci id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2">𝐼</ci><ci id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3">ℐ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.7.m7.1c">I\in\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.7.m7.1d">italic_I ∈ caligraphic_I</annotation></semantics></math> and textual instruction <math alttext="t\in\mathcal{T}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.8.m8.1"><semantics id="S3.SS0.SSS0.Px1.p1.8.m8.1a"><mrow id="S3.SS0.SSS0.Px1.p1.8.m8.1.1" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.2" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.2.cmml">t</mi><mo id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.1" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.3" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.3.cmml">𝒯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.8.m8.1b"><apply id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1"><in id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.1"></in><ci id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.2">𝑡</ci><ci id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.3">𝒯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.8.m8.1c">t\in\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.8.m8.1d">italic_t ∈ caligraphic_T</annotation></semantics></math>, with <math alttext="\Delta(\mathcal{Y})" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.9.m9.1"><semantics id="S3.SS0.SSS0.Px1.p1.9.m9.1a"><mrow id="S3.SS0.SSS0.Px1.p1.9.m9.1.2" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.2.cmml"><mi id="S3.SS0.SSS0.Px1.p1.9.m9.1.2.2" mathvariant="normal" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.2.2.cmml">Δ</mi><mo id="S3.SS0.SSS0.Px1.p1.9.m9.1.2.1" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.2.1.cmml">⁢</mo><mrow id="S3.SS0.SSS0.Px1.p1.9.m9.1.2.3.2" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.2.cmml"><mo id="S3.SS0.SSS0.Px1.p1.9.m9.1.2.3.2.1" stretchy="false" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.9.m9.1.1" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.cmml">𝒴</mi><mo id="S3.SS0.SSS0.Px1.p1.9.m9.1.2.3.2.2" stretchy="false" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.9.m9.1b"><apply id="S3.SS0.SSS0.Px1.p1.9.m9.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.2"><times id="S3.SS0.SSS0.Px1.p1.9.m9.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.2.1"></times><ci id="S3.SS0.SSS0.Px1.p1.9.m9.1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.2.2">Δ</ci><ci id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1">𝒴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.9.m9.1c">\Delta(\mathcal{Y})</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.9.m9.1d">roman_Δ ( caligraphic_Y )</annotation></semantics></math> denoting the probability simplex over the response space. We use <math alttext="y\in\mathcal{Y}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.10.m10.1"><semantics id="S3.SS0.SSS0.Px1.p1.10.m10.1a"><mrow id="S3.SS0.SSS0.Px1.p1.10.m10.1.1" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2.cmml">y</mi><mo id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3.cmml">𝒴</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.10.m10.1b"><apply id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1"><in id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1"></in><ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2">𝑦</ci><ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3">𝒴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.10.m10.1c">y\in\mathcal{Y}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.10.m10.1d">italic_y ∈ caligraphic_Y</annotation></semantics></math> to denote the ground truth label from a dataset.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p2.9">The process reward model (PRM) constitutes a sequence classification function <math alttext="\mathcal{V}_{\phi}:\mathcal{T}\times\mathcal{I}\times\mathcal{Y}\to[0,1]" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p2.1.m1.2"><semantics id="S3.SS0.SSS0.Px1.p2.1.m1.2a"><mrow id="S3.SS0.SSS0.Px1.p2.1.m1.2.3" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.cmml"><msub id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.2" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.2.cmml">𝒱</mi><mi id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.3" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.3.cmml">ϕ</mi></msub><mo id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.1" lspace="0.278em" rspace="0.278em" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.1.cmml">:</mo><mrow id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.cmml"><mrow id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.2" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.2.cmml">𝒯</mi><mo id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.1" lspace="0.222em" rspace="0.222em" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.1.cmml">×</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.3" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.3.cmml">ℐ</mi><mo id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.1.cmml">×</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.4" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.4.cmml">𝒴</mi></mrow><mo id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.1" stretchy="false" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.1.cmml">→</mo><mrow id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.3.2" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.3.1.cmml"><mo id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.3.2.1" stretchy="false" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.3.1.cmml">[</mo><mn id="S3.SS0.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p2.1.m1.1.1.cmml">0</mn><mo id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.3.2.2" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.3.1.cmml">,</mo><mn id="S3.SS0.SSS0.Px1.p2.1.m1.2.2" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.2.cmml">1</mn><mo id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.3.2.3" stretchy="false" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.3.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.1.m1.2b"><apply id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3"><ci id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.1.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.1">:</ci><apply id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.1.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.2.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.2">𝒱</ci><ci id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.3.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.2.3">italic-ϕ</ci></apply><apply id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3"><ci id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.1.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.1">→</ci><apply id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2"><times id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.1.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.1"></times><ci id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.2.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.2">𝒯</ci><ci id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.3.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.3">ℐ</ci><ci id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.4.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.2.4">𝒴</ci></apply><interval closure="closed" id="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.3.1.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.3.3.3.2"><cn id="S3.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" type="integer" xref="S3.SS0.SSS0.Px1.p2.1.m1.1.1">0</cn><cn id="S3.SS0.SSS0.Px1.p2.1.m1.2.2.cmml" type="integer" xref="S3.SS0.SSS0.Px1.p2.1.m1.2.2">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.1.m1.2c">\mathcal{V}_{\phi}:\mathcal{T}\times\mathcal{I}\times\mathcal{Y}\to[0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p2.1.m1.2d">caligraphic_V start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT : caligraphic_T × caligraphic_I × caligraphic_Y → [ 0 , 1 ]</annotation></semantics></math>, parameterized by <math alttext="\phi" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p2.2.m2.1"><semantics id="S3.SS0.SSS0.Px1.p2.2.m2.1a"><mi id="S3.SS0.SSS0.Px1.p2.2.m2.1.1" xref="S3.SS0.SSS0.Px1.p2.2.m2.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.2.m2.1b"><ci id="S3.SS0.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.2.m2.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.2.m2.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p2.2.m2.1d">italic_ϕ</annotation></semantics></math>, which quantifies the epistemic value of partial reasoning state <math alttext="\hat{y}_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p2.3.m3.1"><semantics id="S3.SS0.SSS0.Px1.p2.3.m3.1a"><msub id="S3.SS0.SSS0.Px1.p2.3.m3.1.1" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1.cmml"><mover accent="true" id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2.cmml"><mi id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2.2" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2.2.cmml">y</mi><mo id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2.1" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.3" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.3.m3.1b"><apply id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1">subscript</csymbol><apply id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2"><ci id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2.1">^</ci><ci id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1.2.2">𝑦</ci></apply><ci id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.3.m3.1c">\hat{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p2.3.m3.1d">over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> through scalar reward <math alttext="p_{i}=\mathcal{V}_{\phi}(x,\hat{y}_{i})" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p2.4.m4.2"><semantics id="S3.SS0.SSS0.Px1.p2.4.m4.2a"><mrow id="S3.SS0.SSS0.Px1.p2.4.m4.2.2" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.cmml"><msub id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.cmml"><mi id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.2" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.2.cmml">p</mi><mi id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.3" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.3.cmml">i</mi></msub><mo id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.2" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.2.cmml">=</mo><mrow id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.cmml"><msub id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.2" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.2.cmml">𝒱</mi><mi id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.3" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.3.cmml">ϕ</mi></msub><mo id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.2" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.2.cmml">⁢</mo><mrow id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.2.cmml"><mo id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.2" stretchy="false" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.2.cmml">(</mo><mi id="S3.SS0.SSS0.Px1.p2.4.m4.1.1" xref="S3.SS0.SSS0.Px1.p2.4.m4.1.1.cmml">x</mi><mo id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.3" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.2.cmml">,</mo><msub id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.cmml"><mover accent="true" id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2.cmml"><mi id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2.2" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2.2.cmml">y</mi><mo id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2.1" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.3" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.4" stretchy="false" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.4.m4.2b"><apply id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2"><eq id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.2.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.2"></eq><apply id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.1.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.2.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.2">𝑝</ci><ci id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.3.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.3.3">𝑖</ci></apply><apply id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1"><times id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.2.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.2"></times><apply id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.1.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.2.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.2">𝒱</ci><ci id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.3.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.3.3">italic-ϕ</ci></apply><interval closure="open" id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1"><ci id="S3.SS0.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.1.1">𝑥</ci><apply id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1">subscript</csymbol><apply id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2"><ci id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2.1">^</ci><ci id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.2.2">𝑦</ci></apply><ci id="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p2.4.m4.2.2.1.1.1.1.3">𝑖</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.4.m4.2c">p_{i}=\mathcal{V}_{\phi}(x,\hat{y}_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p2.4.m4.2d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = caligraphic_V start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT ( italic_x , over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, modeling incremental utility toward solving instruction <math alttext="t" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p2.5.m5.1"><semantics id="S3.SS0.SSS0.Px1.p2.5.m5.1a"><mi id="S3.SS0.SSS0.Px1.p2.5.m5.1.1" xref="S3.SS0.SSS0.Px1.p2.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.5.m5.1b"><ci id="S3.SS0.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.5.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p2.5.m5.1d">italic_t</annotation></semantics></math> under visual grounding <math alttext="I" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p2.6.m6.1"><semantics id="S3.SS0.SSS0.Px1.p2.6.m6.1a"><mi id="S3.SS0.SSS0.Px1.p2.6.m6.1.1" xref="S3.SS0.SSS0.Px1.p2.6.m6.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.6.m6.1b"><ci id="S3.SS0.SSS0.Px1.p2.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.6.m6.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.6.m6.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p2.6.m6.1d">italic_I</annotation></semantics></math>. Specifically, <math alttext="\hat{y}_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p2.7.m7.1"><semantics id="S3.SS0.SSS0.Px1.p2.7.m7.1a"><msub id="S3.SS0.SSS0.Px1.p2.7.m7.1.1" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1.cmml"><mover accent="true" id="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2.cmml"><mi id="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2.2" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2.2.cmml">y</mi><mo id="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2.1" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS0.SSS0.Px1.p2.7.m7.1.1.3" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.7.m7.1b"><apply id="S3.SS0.SSS0.Px1.p2.7.m7.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p2.7.m7.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1">subscript</csymbol><apply id="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2"><ci id="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2.1">^</ci><ci id="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1.2.2">𝑦</ci></apply><ci id="S3.SS0.SSS0.Px1.p2.7.m7.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p2.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.7.m7.1c">\hat{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p2.7.m7.1d">over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the first <math alttext="i" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p2.8.m8.1"><semantics id="S3.SS0.SSS0.Px1.p2.8.m8.1a"><mi id="S3.SS0.SSS0.Px1.p2.8.m8.1.1" xref="S3.SS0.SSS0.Px1.p2.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.8.m8.1b"><ci id="S3.SS0.SSS0.Px1.p2.8.m8.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.8.m8.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.8.m8.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p2.8.m8.1d">italic_i</annotation></semantics></math> steps of a complete reasoning trajectory <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p2.9.m9.1"><semantics id="S3.SS0.SSS0.Px1.p2.9.m9.1a"><mover accent="true" id="S3.SS0.SSS0.Px1.p2.9.m9.1.1" xref="S3.SS0.SSS0.Px1.p2.9.m9.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p2.9.m9.1.1.2" xref="S3.SS0.SSS0.Px1.p2.9.m9.1.1.2.cmml">y</mi><mo id="S3.SS0.SSS0.Px1.p2.9.m9.1.1.1" xref="S3.SS0.SSS0.Px1.p2.9.m9.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.9.m9.1b"><apply id="S3.SS0.SSS0.Px1.p2.9.m9.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.9.m9.1.1"><ci id="S3.SS0.SSS0.Px1.p2.9.m9.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.9.m9.1.1.1">^</ci><ci id="S3.SS0.SSS0.Px1.p2.9.m9.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p2.9.m9.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.9.m9.1c">\hat{y}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p2.9.m9.1d">over^ start_ARG italic_y end_ARG</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">PRM training with Monte Carlo signals.</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.7">Due to the lack of ground truth epistemic value for each partial reasoning state <math alttext="\hat{y}_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS0.SSS0.Px2.p1.1.m1.1a"><msub id="S3.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mover accent="true" id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml"><mi id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.2" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.2.cmml">y</mi><mo id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.1" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><apply id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2"><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.1">^</ci><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.2">𝑦</ci></apply><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.1.m1.1c">\hat{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.1.m1.1d">over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, training of PRM requires automatic generation of approximated supervision signals. An effective approach to obtain these signals is to use the Monte Carlo method <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib60" title=""><span class="ltx_text" style="font-size:80%;">60</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib56" title=""><span class="ltx_text" style="font-size:80%;">56</span></a>]</cite>. We first feed the input question-image pair <math alttext="x=(t,I)" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.2.m2.2"><semantics id="S3.SS0.SSS0.Px2.p1.2.m2.2a"><mrow id="S3.SS0.SSS0.Px2.p1.2.m2.2.3" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3.cmml"><mi id="S3.SS0.SSS0.Px2.p1.2.m2.2.3.2" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3.2.cmml">x</mi><mo id="S3.SS0.SSS0.Px2.p1.2.m2.2.3.1" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3.1.cmml">=</mo><mrow id="S3.SS0.SSS0.Px2.p1.2.m2.2.3.3.2" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3.3.1.cmml"><mo id="S3.SS0.SSS0.Px2.p1.2.m2.2.3.3.2.1" stretchy="false" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3.3.1.cmml">(</mo><mi id="S3.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">t</mi><mo id="S3.SS0.SSS0.Px2.p1.2.m2.2.3.3.2.2" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3.3.1.cmml">,</mo><mi id="S3.SS0.SSS0.Px2.p1.2.m2.2.2" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.2.cmml">I</mi><mo id="S3.SS0.SSS0.Px2.p1.2.m2.2.3.3.2.3" stretchy="false" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.2.m2.2b"><apply id="S3.SS0.SSS0.Px2.p1.2.m2.2.3.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3"><eq id="S3.SS0.SSS0.Px2.p1.2.m2.2.3.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3.1"></eq><ci id="S3.SS0.SSS0.Px2.p1.2.m2.2.3.2.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3.2">𝑥</ci><interval closure="open" id="S3.SS0.SSS0.Px2.p1.2.m2.2.3.3.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.3.3.2"><ci id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1">𝑡</ci><ci id="S3.SS0.SSS0.Px2.p1.2.m2.2.2.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.2">𝐼</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.2.m2.2c">x=(t,I)</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.2.m2.2d">italic_x = ( italic_t , italic_I )</annotation></semantics></math> and the prefix solution <math alttext="\hat{y}_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="S3.SS0.SSS0.Px2.p1.3.m3.1a"><msub id="S3.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.cmml"><mover accent="true" id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml"><mi id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.2" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.2.cmml">y</mi><mo id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.1" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><apply id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2"><ci id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.1">^</ci><ci id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.2">𝑦</ci></apply><ci id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.3.m3.1c">\hat{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.3.m3.1d">over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> into the MLLM, and let it complete the remaining steps until reaching the final answer. We randomly sample multiple completions, compare their final answers to the gold answer <math alttext="y" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.4.m4.1"><semantics id="S3.SS0.SSS0.Px2.p1.4.m4.1a"><mi id="S3.SS0.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px2.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.4.m4.1b"><ci id="S3.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.4.m4.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.4.m4.1d">italic_y</annotation></semantics></math>, and thereby obtain multiple correctness labels. PRM is trained as a sequence classification task to predict these correctness labels. The ratio of correct completions at the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.5.m5.1"><semantics id="S3.SS0.SSS0.Px2.p1.5.m5.1a"><mi id="S3.SS0.SSS0.Px2.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.5.m5.1b"><ci id="S3.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.5.m5.1d">italic_i</annotation></semantics></math>-th step estimates the “correctness level” up to step <math alttext="i" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.6.m6.1"><semantics id="S3.SS0.SSS0.Px2.p1.6.m6.1a"><mi id="S3.SS0.SSS0.Px2.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px2.p1.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.6.m6.1b"><ci id="S3.SS0.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.6.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.6.m6.1d">italic_i</annotation></semantics></math>, which is used as the approximated supervision signals <math alttext="p_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.7.m7.1"><semantics id="S3.SS0.SSS0.Px2.p1.7.m7.1a"><msub id="S3.SS0.SSS0.Px2.p1.7.m7.1.1" xref="S3.SS0.SSS0.Px2.p1.7.m7.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p1.7.m7.1.1.2" xref="S3.SS0.SSS0.Px2.p1.7.m7.1.1.2.cmml">p</mi><mi id="S3.SS0.SSS0.Px2.p1.7.m7.1.1.3" xref="S3.SS0.SSS0.Px2.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.7.m7.1b"><apply id="S3.SS0.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px2.p1.7.m7.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.7.m7.1.1.2">𝑝</ci><ci id="S3.SS0.SSS0.Px2.p1.7.m7.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p1.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.7.m7.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.7.m7.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to train the PRM. Formally,</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p_{i}=\texttt{MonteCarlo}(x,\hat{y}_{i},y)=\frac{\texttt{num(correct %
completions from }\hat{y}_{i})}{\texttt{num(total completions from }\hat{y}_{i%
})}" class="ltx_math_unparsed" display="block" id="S3.E1.m1.3"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3"><msub id="S3.E1.m1.3.3.3"><mi id="S3.E1.m1.3.3.3.2">p</mi><mi id="S3.E1.m1.3.3.3.3">i</mi></msub><mo id="S3.E1.m1.3.3.4">=</mo><mrow id="S3.E1.m1.3.3.1"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.3.3.1.3">MonteCarlo</mtext><mo id="S3.E1.m1.3.3.1.2">⁢</mo><mrow id="S3.E1.m1.3.3.1.1.1"><mo id="S3.E1.m1.3.3.1.1.1.2" stretchy="false">(</mo><mi id="S3.E1.m1.1.1">x</mi><mo id="S3.E1.m1.3.3.1.1.1.3">,</mo><msub id="S3.E1.m1.3.3.1.1.1.1"><mover accent="true" id="S3.E1.m1.3.3.1.1.1.1.2"><mi id="S3.E1.m1.3.3.1.1.1.1.2.2">y</mi><mo id="S3.E1.m1.3.3.1.1.1.1.2.1">^</mo></mover><mi id="S3.E1.m1.3.3.1.1.1.1.3">i</mi></msub><mo id="S3.E1.m1.3.3.1.1.1.4">,</mo><mi id="S3.E1.m1.2.2">y</mi><mo id="S3.E1.m1.3.3.1.1.1.5" stretchy="false">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.5">=</mo><mfrac id="S3.E1.m1.3.3.6"><mrow id="S3.E1.m1.3.3.6.2"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.3.3.6.2.1">num(correct completions from </mtext><msub id="S3.E1.m1.3.3.6.2.2"><mover accent="true" id="S3.E1.m1.3.3.6.2.2.2"><mi id="S3.E1.m1.3.3.6.2.2.2.2">y</mi><mo id="S3.E1.m1.3.3.6.2.2.2.1">^</mo></mover><mi id="S3.E1.m1.3.3.6.2.2.3">i</mi></msub><mo id="S3.E1.m1.3.3.6.2.3" stretchy="false">)</mo></mrow><mrow id="S3.E1.m1.3.3.6.3"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.3.3.6.3.1">num(total completions from </mtext><msub id="S3.E1.m1.3.3.6.3.2"><mover accent="true" id="S3.E1.m1.3.3.6.3.2.2"><mi id="S3.E1.m1.3.3.6.3.2.2.2">y</mi><mo id="S3.E1.m1.3.3.6.3.2.2.1">^</mo></mover><mi id="S3.E1.m1.3.3.6.3.2.3">i</mi></msub><mo id="S3.E1.m1.3.3.6.3.3" stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex" id="S3.E1.m1.3b">p_{i}=\texttt{MonteCarlo}(x,\hat{y}_{i},y)=\frac{\texttt{num(correct %
completions from }\hat{y}_{i})}{\texttt{num(total completions from }\hat{y}_{i%
})}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.3c">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = MonteCarlo ( italic_x , over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y ) = divide start_ARG num(correct completions from over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG num(total completions from over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">PRM-based inference with aggregation function.</h4>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="301" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.5.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text ltx_font_bold" id="S3.F2.6.2" style="font-size:90%;">General flow of training PRM and using PRM for inference. Training phase<span class="ltx_text ltx_font_medium" id="S3.F2.6.2.1">: Train PRM with Monte Carlo signals from intermediate steps of Chain-of-Thoughts (CoTs). </span>Inference phase<span class="ltx_text ltx_font_medium" id="S3.F2.6.2.2">: Use the trained PRM to verify CoTs step by step and select the best CoT. Conventional training of PRM has poor generalization capability due to <em class="ltx_emph ltx_font_italic" id="S3.F2.6.2.2.1">distribution shift</em> between training set and testing set.</span></span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.3">After training a PRM, a typical way of conducting PRM-based MLLM inference is to use aggregation function <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib60" title=""><span class="ltx_text" style="font-size:80%;">60</span></a>]</cite>. Specifically, for each candidate solution <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px3.p1.1.m1.1"><semantics id="S3.SS0.SSS0.Px3.p1.1.m1.1a"><mover accent="true" id="S3.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.cmml">y</mi><mo id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.1" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1"><ci id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.1">^</ci><ci id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.1.m1.1c">\hat{y}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px3.p1.1.m1.1d">over^ start_ARG italic_y end_ARG</annotation></semantics></math> from the MLLM, PRM will generate a list of predicted probabilities <math alttext="{p}=\{{p_{1}},{p_{2}},...,{p_{n}}\}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px3.p1.2.m2.4"><semantics id="S3.SS0.SSS0.Px3.p1.2.m2.4a"><mrow id="S3.SS0.SSS0.Px3.p1.2.m2.4.4" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.cmml"><mi id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.5" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.5.cmml">p</mi><mo id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.4" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.4.cmml">=</mo><mrow id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.4.cmml"><mo id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.4" stretchy="false" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.4.cmml">{</mo><msub id="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1" xref="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.cmml"><mi id="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.2" xref="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.2.cmml">p</mi><mn id="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.3" xref="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.5" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.4.cmml">,</mo><msub id="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2" xref="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.cmml"><mi id="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.2" xref="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.cmml">p</mi><mn id="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.3" xref="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.6" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.4.cmml">,</mo><mi id="S3.SS0.SSS0.Px3.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1.cmml">…</mi><mo id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.7" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.4.cmml">,</mo><msub id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.cmml"><mi id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.2" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.2.cmml">p</mi><mi id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.3" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.cmml">n</mi></msub><mo id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.8" stretchy="false" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.2.m2.4b"><apply id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4"><eq id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.4.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.4"></eq><ci id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.5.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.5">𝑝</ci><set id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.4.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3"><apply id="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.2">𝑝</ci><cn id="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS0.SSS0.Px3.p1.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.2">𝑝</ci><cn id="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS0.SSS0.Px3.p1.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.1.1">…</ci><apply id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.2">𝑝</ci><ci id="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.cmml" xref="S3.SS0.SSS0.Px3.p1.2.m2.4.4.3.3.3.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.2.m2.4c">{p}=\{{p_{1}},{p_{2}},...,{p_{n}}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px3.p1.2.m2.4d">italic_p = { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> accordingly, one for each step <math alttext="\hat{y}_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px3.p1.3.m3.1"><semantics id="S3.SS0.SSS0.Px3.p1.3.m3.1a"><msub id="S3.SS0.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.cmml"><mover accent="true" id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.cmml"><mi id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.2" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.2.cmml">y</mi><mo id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.1" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.3.m3.1b"><apply id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1">subscript</csymbol><apply id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2"><ci id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.1">^</ci><ci id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.2.2">𝑦</ci></apply><ci id="S3.SS0.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px3.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.3.m3.1c">\hat{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px3.p1.3.m3.1d">over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> in the solution. The list of predicted probabilities are then aggregated using the following function:</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{A}({p})=\sum_{i=1}^{n}\log\frac{{p_{i}}}{1-{p_{i}}}." class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.2.2" xref="S3.E2.m1.2.2.1.1.2.2.cmml">𝒜</mi><mo id="S3.E2.m1.2.2.1.1.2.1" xref="S3.E2.m1.2.2.1.1.2.1.cmml">⁢</mo><mrow id="S3.E2.m1.2.2.1.1.2.3.2" xref="S3.E2.m1.2.2.1.1.2.cmml"><mo id="S3.E2.m1.2.2.1.1.2.3.2.1" stretchy="false" xref="S3.E2.m1.2.2.1.1.2.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">p</mi><mo id="S3.E2.m1.2.2.1.1.2.3.2.2" stretchy="false" xref="S3.E2.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.1" rspace="0.111em" xref="S3.E2.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><munderover id="S3.E2.m1.2.2.1.1.3.1" xref="S3.E2.m1.2.2.1.1.3.1.cmml"><mo id="S3.E2.m1.2.2.1.1.3.1.2.2" movablelimits="false" xref="S3.E2.m1.2.2.1.1.3.1.2.2.cmml">∑</mo><mrow id="S3.E2.m1.2.2.1.1.3.1.2.3" xref="S3.E2.m1.2.2.1.1.3.1.2.3.cmml"><mi id="S3.E2.m1.2.2.1.1.3.1.2.3.2" xref="S3.E2.m1.2.2.1.1.3.1.2.3.2.cmml">i</mi><mo id="S3.E2.m1.2.2.1.1.3.1.2.3.1" xref="S3.E2.m1.2.2.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.E2.m1.2.2.1.1.3.1.2.3.3" xref="S3.E2.m1.2.2.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.2.2.1.1.3.1.3" xref="S3.E2.m1.2.2.1.1.3.1.3.cmml">n</mi></munderover><mrow id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.3.2.1" xref="S3.E2.m1.2.2.1.1.3.2.1.cmml">log</mi><mo id="S3.E2.m1.2.2.1.1.3.2a" lspace="0.167em" xref="S3.E2.m1.2.2.1.1.3.2.cmml">⁡</mo><mfrac id="S3.E2.m1.2.2.1.1.3.2.2" xref="S3.E2.m1.2.2.1.1.3.2.2.cmml"><msub id="S3.E2.m1.2.2.1.1.3.2.2.2" xref="S3.E2.m1.2.2.1.1.3.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.3.2.2.2.2" xref="S3.E2.m1.2.2.1.1.3.2.2.2.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.3.2.2.2.3" xref="S3.E2.m1.2.2.1.1.3.2.2.2.3.cmml">i</mi></msub><mrow id="S3.E2.m1.2.2.1.1.3.2.2.3" xref="S3.E2.m1.2.2.1.1.3.2.2.3.cmml"><mn id="S3.E2.m1.2.2.1.1.3.2.2.3.2" xref="S3.E2.m1.2.2.1.1.3.2.2.3.2.cmml">1</mn><mo id="S3.E2.m1.2.2.1.1.3.2.2.3.1" xref="S3.E2.m1.2.2.1.1.3.2.2.3.1.cmml">−</mo><msub id="S3.E2.m1.2.2.1.1.3.2.2.3.3" xref="S3.E2.m1.2.2.1.1.3.2.2.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.3.2.2.3.3.2" xref="S3.E2.m1.2.2.1.1.3.2.2.3.3.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.3.2.2.3.3.3" xref="S3.E2.m1.2.2.1.1.3.2.2.3.3.3.cmml">i</mi></msub></mrow></mfrac></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" lspace="0em" xref="S3.E2.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"></eq><apply id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"><times id="S3.E2.m1.2.2.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.1"></times><ci id="S3.E2.m1.2.2.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2">𝒜</ci><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑝</ci></apply><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><apply id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.1.1.cmml" xref="S3.E2.m1.2.2.1.1.3.1">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.3.1.2.cmml" xref="S3.E2.m1.2.2.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.3.1">subscript</csymbol><sum id="S3.E2.m1.2.2.1.1.3.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.3.1.2.2"></sum><apply id="S3.E2.m1.2.2.1.1.3.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.3.1.2.3"><eq id="S3.E2.m1.2.2.1.1.3.1.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.1.2.3.1"></eq><ci id="S3.E2.m1.2.2.1.1.3.1.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.1.2.3.2">𝑖</ci><cn id="S3.E2.m1.2.2.1.1.3.1.2.3.3.cmml" type="integer" xref="S3.E2.m1.2.2.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.2.2.1.1.3.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3.1.3">𝑛</ci></apply><apply id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2"><log id="S3.E2.m1.2.2.1.1.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.3.2.1"></log><apply id="S3.E2.m1.2.2.1.1.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2"><divide id="S3.E2.m1.2.2.1.1.3.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2"></divide><apply id="S3.E2.m1.2.2.1.1.3.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2.2.2">𝑝</ci><ci id="S3.E2.m1.2.2.1.1.3.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2.2.3">𝑖</ci></apply><apply id="S3.E2.m1.2.2.1.1.3.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2.3"><minus id="S3.E2.m1.2.2.1.1.3.2.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2.3.1"></minus><cn id="S3.E2.m1.2.2.1.1.3.2.2.3.2.cmml" type="integer" xref="S3.E2.m1.2.2.1.1.3.2.2.3.2">1</cn><apply id="S3.E2.m1.2.2.1.1.3.2.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.2.2.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2.3.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.2.2.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2.3.3.2">𝑝</ci><ci id="S3.E2.m1.2.2.1.1.3.2.2.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.2.2.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\mathcal{A}({p})=\sum_{i=1}^{n}\log\frac{{p_{i}}}{1-{p_{i}}}.</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">caligraphic_A ( italic_p ) = ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT roman_log divide start_ARG italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG 1 - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p3">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p3.1">The aggregated value corresponds to the score of a specific prediction <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px3.p3.1.m1.1"><semantics id="S3.SS0.SSS0.Px3.p3.1.m1.1a"><mover accent="true" id="S3.SS0.SSS0.Px3.p3.1.m1.1.1" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.2" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1.2.cmml">y</mi><mo id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.1" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p3.1.m1.1b"><apply id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1"><ci id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1.1">^</ci><ci id="S3.SS0.SSS0.Px3.p3.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px3.p3.1.m1.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p3.1.m1.1c">\hat{y}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px3.p3.1.m1.1d">over^ start_ARG italic_y end_ARG</annotation></semantics></math>, and the final PRM-based solution is the one with the highest aggregated score.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Bi-level optimization.</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px4.p1.1">Bi-level optimization (BLO) has been widely used in meta-learning <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib13" title=""><span class="ltx_text" style="font-size:80%;">13</span></a>]</cite>, neural architecture search <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib28" title=""><span class="ltx_text" style="font-size:80%;">28</span></a>]</cite>, and data reweighting <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib48" title=""><span class="ltx_text" style="font-size:80%;">48</span></a>]</cite>. A BLO problem is usually formulated as:</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px4.p2">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A6.EGx1">
<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\min_{\alpha}\mathcal{U}(\alpha,\phi^{*}(\alpha))" class="ltx_Math" display="inline" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mrow id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml"><munder id="S3.E3.m1.3.3.3.1" xref="S3.E3.m1.3.3.3.1.cmml"><mi id="S3.E3.m1.3.3.3.1.2" xref="S3.E3.m1.3.3.3.1.2.cmml">min</mi><mi id="S3.E3.m1.3.3.3.1.3" xref="S3.E3.m1.3.3.3.1.3.cmml">α</mi></munder><mo id="S3.E3.m1.3.3.3a" lspace="0.167em" xref="S3.E3.m1.3.3.3.cmml">⁡</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.3.2" xref="S3.E3.m1.3.3.3.2.cmml">𝒰</mi></mrow><mo id="S3.E3.m1.3.3.2" xref="S3.E3.m1.3.3.2.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.2.cmml"><mo id="S3.E3.m1.3.3.1.1.2" stretchy="false" xref="S3.E3.m1.3.3.1.2.cmml">(</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">α</mi><mo id="S3.E3.m1.3.3.1.1.3" xref="S3.E3.m1.3.3.1.2.cmml">,</mo><mrow id="S3.E3.m1.3.3.1.1.1" xref="S3.E3.m1.3.3.1.1.1.cmml"><msup id="S3.E3.m1.3.3.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.2.cmml"><mi id="S3.E3.m1.3.3.1.1.1.2.2" xref="S3.E3.m1.3.3.1.1.1.2.2.cmml">ϕ</mi><mo id="S3.E3.m1.3.3.1.1.1.2.3" xref="S3.E3.m1.3.3.1.1.1.2.3.cmml">∗</mo></msup><mo id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.cmml"><mo id="S3.E3.m1.3.3.1.1.1.3.2.1" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">α</mi><mo id="S3.E3.m1.3.3.1.1.1.3.2.2" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.4" stretchy="false" xref="S3.E3.m1.3.3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><times id="S3.E3.m1.3.3.2.cmml" xref="S3.E3.m1.3.3.2"></times><apply id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3"><apply id="S3.E3.m1.3.3.3.1.cmml" xref="S3.E3.m1.3.3.3.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.3.1.1.cmml" xref="S3.E3.m1.3.3.3.1">subscript</csymbol><min id="S3.E3.m1.3.3.3.1.2.cmml" xref="S3.E3.m1.3.3.3.1.2"></min><ci id="S3.E3.m1.3.3.3.1.3.cmml" xref="S3.E3.m1.3.3.3.1.3">𝛼</ci></apply><ci id="S3.E3.m1.3.3.3.2.cmml" xref="S3.E3.m1.3.3.3.2">𝒰</ci></apply><interval closure="open" id="S3.E3.m1.3.3.1.2.cmml" xref="S3.E3.m1.3.3.1.1"><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝛼</ci><apply id="S3.E3.m1.3.3.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1"></times><apply id="S3.E3.m1.3.3.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.2">superscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.2.2">italic-ϕ</ci><times id="S3.E3.m1.3.3.1.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.1.2.3"></times></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝛼</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\displaystyle\min_{\alpha}\mathcal{U}(\alpha,\phi^{*}(\alpha))</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">roman_min start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT caligraphic_U ( italic_α , italic_ϕ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_α ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle s.t." class="ltx_Math" display="inline" id="S3.E4.m1.3"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1"><mrow id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.1.cmml"><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">s</mi><mo id="S3.E4.m1.3.3.1.1.2.1" lspace="0em" rspace="0.167em" xref="S3.E4.m1.3.3.1.1.1a.cmml">.</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">t</mi></mrow><mo id="S3.E4.m1.3.3.1.2" lspace="0em">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1a.cmml" xref="S3.E4.m1.3.3.1.1.2.1">formulae-sequence</csymbol><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">𝑠</ci><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\displaystyle s.t.</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.3d">italic_s . italic_t .</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\phi^{*}(\alpha)=\underset{\mathbf{\phi}}{\arg\min}\mathcal{L}(%
\phi,\alpha)" class="ltx_Math" display="inline" id="S3.E4.m2.3"><semantics id="S3.E4.m2.3a"><mrow id="S3.E4.m2.3.4" xref="S3.E4.m2.3.4.cmml"><mrow id="S3.E4.m2.3.4.2" xref="S3.E4.m2.3.4.2.cmml"><msup id="S3.E4.m2.3.4.2.2" xref="S3.E4.m2.3.4.2.2.cmml"><mi id="S3.E4.m2.3.4.2.2.2" xref="S3.E4.m2.3.4.2.2.2.cmml">ϕ</mi><mo id="S3.E4.m2.3.4.2.2.3" xref="S3.E4.m2.3.4.2.2.3.cmml">∗</mo></msup><mo id="S3.E4.m2.3.4.2.1" xref="S3.E4.m2.3.4.2.1.cmml">⁢</mo><mrow id="S3.E4.m2.3.4.2.3.2" xref="S3.E4.m2.3.4.2.cmml"><mo id="S3.E4.m2.3.4.2.3.2.1" stretchy="false" xref="S3.E4.m2.3.4.2.cmml">(</mo><mi id="S3.E4.m2.1.1" xref="S3.E4.m2.1.1.cmml">α</mi><mo id="S3.E4.m2.3.4.2.3.2.2" stretchy="false" xref="S3.E4.m2.3.4.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m2.3.4.1" xref="S3.E4.m2.3.4.1.cmml">=</mo><mrow id="S3.E4.m2.3.4.3" xref="S3.E4.m2.3.4.3.cmml"><munder accentunder="true" id="S3.E4.m2.3.4.3.2" xref="S3.E4.m2.3.4.3.2.cmml"><mrow id="S3.E4.m2.3.4.3.2.2" xref="S3.E4.m2.3.4.3.2.2.cmml"><mi id="S3.E4.m2.3.4.3.2.2.1" xref="S3.E4.m2.3.4.3.2.2.1.cmml">arg</mi><mo id="S3.E4.m2.3.4.3.2.2a" lspace="0.167em" xref="S3.E4.m2.3.4.3.2.2.cmml">⁡</mo><mi id="S3.E4.m2.3.4.3.2.2.2" xref="S3.E4.m2.3.4.3.2.2.2.cmml">min</mi></mrow><mo class="ltx_mathvariant_italic" id="S3.E4.m2.3.4.3.2.1" mathvariant="italic" xref="S3.E4.m2.3.4.3.2.1.cmml">ϕ</mo></munder><mo id="S3.E4.m2.3.4.3.1" lspace="0.167em" xref="S3.E4.m2.3.4.3.1.cmml">⁢</mo><mi class="ltx_font_mathcaligraphic" id="S3.E4.m2.3.4.3.3" xref="S3.E4.m2.3.4.3.3.cmml">ℒ</mi><mo id="S3.E4.m2.3.4.3.1a" xref="S3.E4.m2.3.4.3.1.cmml">⁢</mo><mrow id="S3.E4.m2.3.4.3.4.2" xref="S3.E4.m2.3.4.3.4.1.cmml"><mo id="S3.E4.m2.3.4.3.4.2.1" stretchy="false" xref="S3.E4.m2.3.4.3.4.1.cmml">(</mo><mi id="S3.E4.m2.2.2" xref="S3.E4.m2.2.2.cmml">ϕ</mi><mo id="S3.E4.m2.3.4.3.4.2.2" xref="S3.E4.m2.3.4.3.4.1.cmml">,</mo><mi id="S3.E4.m2.3.3" xref="S3.E4.m2.3.3.cmml">α</mi><mo id="S3.E4.m2.3.4.3.4.2.3" stretchy="false" xref="S3.E4.m2.3.4.3.4.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m2.3b"><apply id="S3.E4.m2.3.4.cmml" xref="S3.E4.m2.3.4"><eq id="S3.E4.m2.3.4.1.cmml" xref="S3.E4.m2.3.4.1"></eq><apply id="S3.E4.m2.3.4.2.cmml" xref="S3.E4.m2.3.4.2"><times id="S3.E4.m2.3.4.2.1.cmml" xref="S3.E4.m2.3.4.2.1"></times><apply id="S3.E4.m2.3.4.2.2.cmml" xref="S3.E4.m2.3.4.2.2"><csymbol cd="ambiguous" id="S3.E4.m2.3.4.2.2.1.cmml" xref="S3.E4.m2.3.4.2.2">superscript</csymbol><ci id="S3.E4.m2.3.4.2.2.2.cmml" xref="S3.E4.m2.3.4.2.2.2">italic-ϕ</ci><times id="S3.E4.m2.3.4.2.2.3.cmml" xref="S3.E4.m2.3.4.2.2.3"></times></apply><ci id="S3.E4.m2.1.1.cmml" xref="S3.E4.m2.1.1">𝛼</ci></apply><apply id="S3.E4.m2.3.4.3.cmml" xref="S3.E4.m2.3.4.3"><times id="S3.E4.m2.3.4.3.1.cmml" xref="S3.E4.m2.3.4.3.1"></times><apply id="S3.E4.m2.3.4.3.2.cmml" xref="S3.E4.m2.3.4.3.2"><ci id="S3.E4.m2.3.4.3.2.1.cmml" xref="S3.E4.m2.3.4.3.2.1">italic-ϕ</ci><apply id="S3.E4.m2.3.4.3.2.2.cmml" xref="S3.E4.m2.3.4.3.2.2"><arg id="S3.E4.m2.3.4.3.2.2.1.cmml" xref="S3.E4.m2.3.4.3.2.2.1"></arg><min id="S3.E4.m2.3.4.3.2.2.2.cmml" xref="S3.E4.m2.3.4.3.2.2.2"></min></apply></apply><ci id="S3.E4.m2.3.4.3.3.cmml" xref="S3.E4.m2.3.4.3.3">ℒ</ci><interval closure="open" id="S3.E4.m2.3.4.3.4.1.cmml" xref="S3.E4.m2.3.4.3.4.2"><ci id="S3.E4.m2.2.2.cmml" xref="S3.E4.m2.2.2">italic-ϕ</ci><ci id="S3.E4.m2.3.3.cmml" xref="S3.E4.m2.3.3">𝛼</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m2.3c">\displaystyle\phi^{*}(\alpha)=\underset{\mathbf{\phi}}{\arg\min}\mathcal{L}(%
\phi,\alpha)</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m2.3d">italic_ϕ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_α ) = underitalic_ϕ start_ARG roman_arg roman_min end_ARG caligraphic_L ( italic_ϕ , italic_α )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px4.p3">
<p class="ltx_p" id="S3.SS0.SSS0.Px4.p3.4">where <math alttext="\mathcal{U}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p3.1.m1.1"><semantics id="S3.SS0.SSS0.Px4.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px4.p3.1.m1.1.1" xref="S3.SS0.SSS0.Px4.p3.1.m1.1.1.cmml">𝒰</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p3.1.m1.1b"><ci id="S3.SS0.SSS0.Px4.p3.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p3.1.m1.1.1">𝒰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p3.1.m1.1c">\mathcal{U}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px4.p3.1.m1.1d">caligraphic_U</annotation></semantics></math> is the upper-level optimization problem (OP) with parameter <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p3.2.m2.1"><semantics id="S3.SS0.SSS0.Px4.p3.2.m2.1a"><mi id="S3.SS0.SSS0.Px4.p3.2.m2.1.1" xref="S3.SS0.SSS0.Px4.p3.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p3.2.m2.1b"><ci id="S3.SS0.SSS0.Px4.p3.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px4.p3.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p3.2.m2.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px4.p3.2.m2.1d">italic_α</annotation></semantics></math>, and <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p3.3.m3.1"><semantics id="S3.SS0.SSS0.Px4.p3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px4.p3.3.m3.1.1" xref="S3.SS0.SSS0.Px4.p3.3.m3.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p3.3.m3.1b"><ci id="S3.SS0.SSS0.Px4.p3.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px4.p3.3.m3.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p3.3.m3.1c">\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px4.p3.3.m3.1d">caligraphic_L</annotation></semantics></math> is the lower-level OP with parameter <math alttext="\phi" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p3.4.m4.1"><semantics id="S3.SS0.SSS0.Px4.p3.4.m4.1a"><mi id="S3.SS0.SSS0.Px4.p3.4.m4.1.1" xref="S3.SS0.SSS0.Px4.p3.4.m4.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p3.4.m4.1b"><ci id="S3.SS0.SSS0.Px4.p3.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px4.p3.4.m4.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p3.4.m4.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px4.p3.4.m4.1d">italic_ϕ</annotation></semantics></math>. The lower-level OP is nested within the upper-level one, and the two OPs are mutually dependent.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>The Proposed Domain-reweighting Method</h2>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="342" id="S4.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.5.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F3.6.2" style="font-size:90%;">The proposed bi-level optimization based domain-reweighting method.<span class="ltx_text ltx_font_medium" id="S4.F3.6.2.1"> </span>Lower-level optimization:<span class="ltx_text ltx_font_medium" id="S4.F3.6.2.2"> In this stage, PRM’s parameters are updated on multiple datasets with domain weights, allowing the PRM to prioritize domains with better quality. </span>Upper-level optimization:<span class="ltx_text ltx_font_medium" id="S4.F3.6.2.3"> In this stage, the PRM is evaluated on a separate meta dataset to compute an aggregation function loss and optimize the domain weights. DreamPRM helps address dataset quality imbalance problems and leads to stronger and more generalizable reasoning performance.</span></span></figcaption>
</figure>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Overview.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">Training process reward models (PRMs) for MLLMs is challenging for two reasons: (1) dataset (domain) quality imbalance, and (2) discrepancy between training and inference procedures. To address these two challenges, we propose DreamPRM, which automatically searches for domain importance using a novel aggregation function loss that better simulates the inference process of PRM. Under a bi-level optimization framework, it optimizes PRM parameters with Monte Carlo signals at the lower level, and optimizes trainable domain importance weights with aggregation function loss at the upper level. An overview of DreamPRM method is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S4.F3" title="Figure 3 ‣ 4 The Proposed Domain-reweighting Method ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Datasets.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.4">We begin with <math alttext="K{+}1" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="S4.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">K</mi><mo id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">+</mo><mn id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1"><plus id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.1"></plus><ci id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2">𝐾</ci><cn id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.1.m1.1c">K{+}1</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.1.m1.1d">italic_K + 1</annotation></semantics></math> datasets, each from a distinct domain (e.g., science, geometry).
The first <math alttext="K" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="S4.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.2.m2.1d">italic_K</annotation></semantics></math> datasets form the training pool
<math alttext="\mathcal{D}_{\mathrm{tr}}=\{\mathcal{D}_{1},\dots,\mathcal{D}_{K}\}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.3.m3.3"><semantics id="S4.SS0.SSS0.Px2.p1.3.m3.3a"><mrow id="S4.SS0.SSS0.Px2.p1.3.m3.3.3" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.cmml"><msub id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.2" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.2.cmml">𝒟</mi><mi id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.3" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.3.cmml">tr</mi></msub><mo id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.3" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.3.cmml">=</mo><mrow id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.3.cmml"><mo id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.3" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.3.cmml">{</mo><msub id="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1" xref="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.2" xref="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.cmml">𝒟</mi><mn id="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.3" xref="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.4" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.3.cmml">,</mo><mi id="S4.SS0.SSS0.Px2.p1.3.m3.1.1" mathvariant="normal" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">…</mi><mo id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.5" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.3.cmml">,</mo><msub id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.2" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.cmml">𝒟</mi><mi id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.3" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.3.cmml">K</mi></msub><mo id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.6" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.3.m3.3b"><apply id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3"><eq id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.3.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.3"></eq><apply id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.1.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.2.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.2">𝒟</ci><ci id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.3.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.4.3">tr</ci></apply><set id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.3.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2"><apply id="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.2">𝒟</ci><cn id="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.3.m3.2.2.1.1.1.3">1</cn></apply><ci id="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1">…</ci><apply id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.1.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.2">𝒟</ci><ci id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.3.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.2.2.2.3">𝐾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.3.m3.3c">\mathcal{D}_{\mathrm{tr}}=\{\mathcal{D}_{1},\dots,\mathcal{D}_{K}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.3.m3.3d">caligraphic_D start_POSTSUBSCRIPT roman_tr end_POSTSUBSCRIPT = { caligraphic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , caligraphic_D start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT }</annotation></semantics></math>,
while the remaining dataset, <math alttext="\mathcal{D}_{\mathrm{meta}}=\mathcal{D}_{K+1}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.4.m4.1"><semantics id="S4.SS0.SSS0.Px2.p1.4.m4.1a"><mrow id="S4.SS0.SSS0.Px2.p1.4.m4.1.1" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.cmml"><msub id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.2" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.2.cmml">𝒟</mi><mi id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.3" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.3.cmml">meta</mi></msub><mo id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.1" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.1.cmml">=</mo><msub id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.2" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.2.cmml">𝒟</mi><mrow id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.cmml"><mi id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.2" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.2.cmml">K</mi><mo id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.1" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.1.cmml">+</mo><mn id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.3" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.4.m4.1b"><apply id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1"><eq id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.1"></eq><apply id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.2">𝒟</ci><ci id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.3.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.2.3">meta</ci></apply><apply id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.2">𝒟</ci><apply id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3"><plus id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.1.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.1"></plus><ci id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.2.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.2">𝐾</ci><cn id="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.3.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.4.m4.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.4.m4.1c">\mathcal{D}_{\mathrm{meta}}=\mathcal{D}_{K+1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.4.m4.1d">caligraphic_D start_POSTSUBSCRIPT roman_meta end_POSTSUBSCRIPT = caligraphic_D start_POSTSUBSCRIPT italic_K + 1 end_POSTSUBSCRIPT</annotation></semantics></math>, is a meta (validation) dataset with better quality.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Lower-level optimization: domain-reweighted training of PRM.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.4">In lower-level optimization, we aim to update the weights <math alttext="\phi" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px3.p1.1.m1.1a"><mi id="S4.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p1.1.m1.1b"><ci id="S4.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p1.1.m1.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p1.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p1.1.m1.1d">italic_ϕ</annotation></semantics></math> of PRM with domain-reweighted training. We first define the typical PRM training loss <math alttext="\mathcal{L}_{tr}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p1.2.m2.1"><semantics id="S4.SS0.SSS0.Px3.p1.2.m2.1a"><msub id="S4.SS0.SSS0.Px3.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.2" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml">ℒ</mi><mrow id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.2" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.2.cmml">t</mi><mo id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.1" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.3" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p1.2.m2.1b"><apply id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.2">ℒ</ci><apply id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3"><times id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.1"></times><ci id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.2">𝑡</ci><ci id="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px3.p1.2.m2.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p1.2.m2.1c">\mathcal{L}_{tr}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p1.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT</annotation></semantics></math> on a single domain <math alttext="\mathcal{D}_{k}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p1.3.m3.1"><semantics id="S4.SS0.SSS0.Px3.p1.3.m3.1a"><msub id="S4.SS0.SSS0.Px3.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px3.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px3.p1.3.m3.1.1.2" xref="S4.SS0.SSS0.Px3.p1.3.m3.1.1.2.cmml">𝒟</mi><mi id="S4.SS0.SSS0.Px3.p1.3.m3.1.1.3" xref="S4.SS0.SSS0.Px3.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p1.3.m3.1b"><apply id="S4.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p1.3.m3.1.1.2">𝒟</ci><ci id="S4.SS0.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p1.3.m3.1c">\mathcal{D}_{k}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p1.3.m3.1d">caligraphic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>, given PRM parameters <math alttext="\phi" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p1.4.m4.1"><semantics id="S4.SS0.SSS0.Px3.p1.4.m4.1a"><mi id="S4.SS0.SSS0.Px3.p1.4.m4.1.1" xref="S4.SS0.SSS0.Px3.p1.4.m4.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p1.4.m4.1b"><ci id="S4.SS0.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S4.SS0.SSS0.Px3.p1.4.m4.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p1.4.m4.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p1.4.m4.1d">italic_ϕ</annotation></semantics></math>, as follows:</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p2">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A6.EGx2">
<tbody id="S4.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{tr}(\mathcal{D}_{k},\phi)=\sum_{(x,y)\in\mathcal{D}_%
{k}}\sum_{i=1}^{n}\mathcal{L}_{MSE}(\mathcal{V}_{\phi}(x,\hat{y}_{i}),p_{i})" class="ltx_Math" display="inline" id="S4.E5.m1.7"><semantics id="S4.E5.m1.7a"><mrow id="S4.E5.m1.7.7" xref="S4.E5.m1.7.7.cmml"><mrow id="S4.E5.m1.5.5.1" xref="S4.E5.m1.5.5.1.cmml"><msub id="S4.E5.m1.5.5.1.3" xref="S4.E5.m1.5.5.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.5.5.1.3.2" xref="S4.E5.m1.5.5.1.3.2.cmml">ℒ</mi><mrow id="S4.E5.m1.5.5.1.3.3" xref="S4.E5.m1.5.5.1.3.3.cmml"><mi id="S4.E5.m1.5.5.1.3.3.2" xref="S4.E5.m1.5.5.1.3.3.2.cmml">t</mi><mo id="S4.E5.m1.5.5.1.3.3.1" xref="S4.E5.m1.5.5.1.3.3.1.cmml">⁢</mo><mi id="S4.E5.m1.5.5.1.3.3.3" xref="S4.E5.m1.5.5.1.3.3.3.cmml">r</mi></mrow></msub><mo id="S4.E5.m1.5.5.1.2" xref="S4.E5.m1.5.5.1.2.cmml">⁢</mo><mrow id="S4.E5.m1.5.5.1.1.1" xref="S4.E5.m1.5.5.1.1.2.cmml"><mo id="S4.E5.m1.5.5.1.1.1.2" stretchy="false" xref="S4.E5.m1.5.5.1.1.2.cmml">(</mo><msub id="S4.E5.m1.5.5.1.1.1.1" xref="S4.E5.m1.5.5.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.5.5.1.1.1.1.2" xref="S4.E5.m1.5.5.1.1.1.1.2.cmml">𝒟</mi><mi id="S4.E5.m1.5.5.1.1.1.1.3" xref="S4.E5.m1.5.5.1.1.1.1.3.cmml">k</mi></msub><mo id="S4.E5.m1.5.5.1.1.1.3" xref="S4.E5.m1.5.5.1.1.2.cmml">,</mo><mi id="S4.E5.m1.3.3" xref="S4.E5.m1.3.3.cmml">ϕ</mi><mo id="S4.E5.m1.5.5.1.1.1.4" stretchy="false" xref="S4.E5.m1.5.5.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.E5.m1.7.7.4" xref="S4.E5.m1.7.7.4.cmml">=</mo><mrow id="S4.E5.m1.7.7.3" xref="S4.E5.m1.7.7.3.cmml"><mstyle displaystyle="true" id="S4.E5.m1.7.7.3.3" xref="S4.E5.m1.7.7.3.3.cmml"><munder id="S4.E5.m1.7.7.3.3a" xref="S4.E5.m1.7.7.3.3.cmml"><mo id="S4.E5.m1.7.7.3.3.2" movablelimits="false" xref="S4.E5.m1.7.7.3.3.2.cmml">∑</mo><mrow id="S4.E5.m1.2.2.2" xref="S4.E5.m1.2.2.2.cmml"><mrow id="S4.E5.m1.2.2.2.4.2" xref="S4.E5.m1.2.2.2.4.1.cmml"><mo id="S4.E5.m1.2.2.2.4.2.1" stretchy="false" xref="S4.E5.m1.2.2.2.4.1.cmml">(</mo><mi id="S4.E5.m1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.cmml">x</mi><mo id="S4.E5.m1.2.2.2.4.2.2" xref="S4.E5.m1.2.2.2.4.1.cmml">,</mo><mi id="S4.E5.m1.2.2.2.2" xref="S4.E5.m1.2.2.2.2.cmml">y</mi><mo id="S4.E5.m1.2.2.2.4.2.3" stretchy="false" xref="S4.E5.m1.2.2.2.4.1.cmml">)</mo></mrow><mo id="S4.E5.m1.2.2.2.3" xref="S4.E5.m1.2.2.2.3.cmml">∈</mo><msub id="S4.E5.m1.2.2.2.5" xref="S4.E5.m1.2.2.2.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.2.2.2.5.2" xref="S4.E5.m1.2.2.2.5.2.cmml">𝒟</mi><mi id="S4.E5.m1.2.2.2.5.3" xref="S4.E5.m1.2.2.2.5.3.cmml">k</mi></msub></mrow></munder></mstyle><mrow id="S4.E5.m1.7.7.3.2" xref="S4.E5.m1.7.7.3.2.cmml"><mstyle displaystyle="true" id="S4.E5.m1.7.7.3.2.3" xref="S4.E5.m1.7.7.3.2.3.cmml"><munderover id="S4.E5.m1.7.7.3.2.3a" xref="S4.E5.m1.7.7.3.2.3.cmml"><mo id="S4.E5.m1.7.7.3.2.3.2.2" movablelimits="false" xref="S4.E5.m1.7.7.3.2.3.2.2.cmml">∑</mo><mrow id="S4.E5.m1.7.7.3.2.3.2.3" xref="S4.E5.m1.7.7.3.2.3.2.3.cmml"><mi id="S4.E5.m1.7.7.3.2.3.2.3.2" xref="S4.E5.m1.7.7.3.2.3.2.3.2.cmml">i</mi><mo id="S4.E5.m1.7.7.3.2.3.2.3.1" xref="S4.E5.m1.7.7.3.2.3.2.3.1.cmml">=</mo><mn id="S4.E5.m1.7.7.3.2.3.2.3.3" xref="S4.E5.m1.7.7.3.2.3.2.3.3.cmml">1</mn></mrow><mi id="S4.E5.m1.7.7.3.2.3.3" xref="S4.E5.m1.7.7.3.2.3.3.cmml">n</mi></munderover></mstyle><mrow id="S4.E5.m1.7.7.3.2.2" xref="S4.E5.m1.7.7.3.2.2.cmml"><msub id="S4.E5.m1.7.7.3.2.2.4" xref="S4.E5.m1.7.7.3.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.7.7.3.2.2.4.2" xref="S4.E5.m1.7.7.3.2.2.4.2.cmml">ℒ</mi><mrow id="S4.E5.m1.7.7.3.2.2.4.3" xref="S4.E5.m1.7.7.3.2.2.4.3.cmml"><mi id="S4.E5.m1.7.7.3.2.2.4.3.2" xref="S4.E5.m1.7.7.3.2.2.4.3.2.cmml">M</mi><mo id="S4.E5.m1.7.7.3.2.2.4.3.1" xref="S4.E5.m1.7.7.3.2.2.4.3.1.cmml">⁢</mo><mi id="S4.E5.m1.7.7.3.2.2.4.3.3" xref="S4.E5.m1.7.7.3.2.2.4.3.3.cmml">S</mi><mo id="S4.E5.m1.7.7.3.2.2.4.3.1a" xref="S4.E5.m1.7.7.3.2.2.4.3.1.cmml">⁢</mo><mi id="S4.E5.m1.7.7.3.2.2.4.3.4" xref="S4.E5.m1.7.7.3.2.2.4.3.4.cmml">E</mi></mrow></msub><mo id="S4.E5.m1.7.7.3.2.2.3" xref="S4.E5.m1.7.7.3.2.2.3.cmml">⁢</mo><mrow id="S4.E5.m1.7.7.3.2.2.2.2" xref="S4.E5.m1.7.7.3.2.2.2.3.cmml"><mo id="S4.E5.m1.7.7.3.2.2.2.2.3" stretchy="false" xref="S4.E5.m1.7.7.3.2.2.2.3.cmml">(</mo><mrow id="S4.E5.m1.6.6.2.1.1.1.1.1" xref="S4.E5.m1.6.6.2.1.1.1.1.1.cmml"><msub id="S4.E5.m1.6.6.2.1.1.1.1.1.3" xref="S4.E5.m1.6.6.2.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.6.6.2.1.1.1.1.1.3.2" xref="S4.E5.m1.6.6.2.1.1.1.1.1.3.2.cmml">𝒱</mi><mi id="S4.E5.m1.6.6.2.1.1.1.1.1.3.3" xref="S4.E5.m1.6.6.2.1.1.1.1.1.3.3.cmml">ϕ</mi></msub><mo id="S4.E5.m1.6.6.2.1.1.1.1.1.2" xref="S4.E5.m1.6.6.2.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.2.cmml"><mo id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.2.cmml">(</mo><mi id="S4.E5.m1.4.4" xref="S4.E5.m1.4.4.cmml">x</mi><mo id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.3" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.2.cmml">,</mo><msub id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2.2" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2.2.cmml">y</mi><mo id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2.1" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.3" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.4" stretchy="false" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.E5.m1.7.7.3.2.2.2.2.4" xref="S4.E5.m1.7.7.3.2.2.2.3.cmml">,</mo><msub id="S4.E5.m1.7.7.3.2.2.2.2.2" xref="S4.E5.m1.7.7.3.2.2.2.2.2.cmml"><mi id="S4.E5.m1.7.7.3.2.2.2.2.2.2" xref="S4.E5.m1.7.7.3.2.2.2.2.2.2.cmml">p</mi><mi id="S4.E5.m1.7.7.3.2.2.2.2.2.3" xref="S4.E5.m1.7.7.3.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S4.E5.m1.7.7.3.2.2.2.2.5" stretchy="false" xref="S4.E5.m1.7.7.3.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.7b"><apply id="S4.E5.m1.7.7.cmml" xref="S4.E5.m1.7.7"><eq id="S4.E5.m1.7.7.4.cmml" xref="S4.E5.m1.7.7.4"></eq><apply id="S4.E5.m1.5.5.1.cmml" xref="S4.E5.m1.5.5.1"><times id="S4.E5.m1.5.5.1.2.cmml" xref="S4.E5.m1.5.5.1.2"></times><apply id="S4.E5.m1.5.5.1.3.cmml" xref="S4.E5.m1.5.5.1.3"><csymbol cd="ambiguous" id="S4.E5.m1.5.5.1.3.1.cmml" xref="S4.E5.m1.5.5.1.3">subscript</csymbol><ci id="S4.E5.m1.5.5.1.3.2.cmml" xref="S4.E5.m1.5.5.1.3.2">ℒ</ci><apply id="S4.E5.m1.5.5.1.3.3.cmml" xref="S4.E5.m1.5.5.1.3.3"><times id="S4.E5.m1.5.5.1.3.3.1.cmml" xref="S4.E5.m1.5.5.1.3.3.1"></times><ci id="S4.E5.m1.5.5.1.3.3.2.cmml" xref="S4.E5.m1.5.5.1.3.3.2">𝑡</ci><ci id="S4.E5.m1.5.5.1.3.3.3.cmml" xref="S4.E5.m1.5.5.1.3.3.3">𝑟</ci></apply></apply><interval closure="open" id="S4.E5.m1.5.5.1.1.2.cmml" xref="S4.E5.m1.5.5.1.1.1"><apply id="S4.E5.m1.5.5.1.1.1.1.cmml" xref="S4.E5.m1.5.5.1.1.1.1"><csymbol cd="ambiguous" id="S4.E5.m1.5.5.1.1.1.1.1.cmml" xref="S4.E5.m1.5.5.1.1.1.1">subscript</csymbol><ci id="S4.E5.m1.5.5.1.1.1.1.2.cmml" xref="S4.E5.m1.5.5.1.1.1.1.2">𝒟</ci><ci id="S4.E5.m1.5.5.1.1.1.1.3.cmml" xref="S4.E5.m1.5.5.1.1.1.1.3">𝑘</ci></apply><ci id="S4.E5.m1.3.3.cmml" xref="S4.E5.m1.3.3">italic-ϕ</ci></interval></apply><apply id="S4.E5.m1.7.7.3.cmml" xref="S4.E5.m1.7.7.3"><apply id="S4.E5.m1.7.7.3.3.cmml" xref="S4.E5.m1.7.7.3.3"><csymbol cd="ambiguous" id="S4.E5.m1.7.7.3.3.1.cmml" xref="S4.E5.m1.7.7.3.3">subscript</csymbol><sum id="S4.E5.m1.7.7.3.3.2.cmml" xref="S4.E5.m1.7.7.3.3.2"></sum><apply id="S4.E5.m1.2.2.2.cmml" xref="S4.E5.m1.2.2.2"><in id="S4.E5.m1.2.2.2.3.cmml" xref="S4.E5.m1.2.2.2.3"></in><interval closure="open" id="S4.E5.m1.2.2.2.4.1.cmml" xref="S4.E5.m1.2.2.2.4.2"><ci id="S4.E5.m1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1">𝑥</ci><ci id="S4.E5.m1.2.2.2.2.cmml" xref="S4.E5.m1.2.2.2.2">𝑦</ci></interval><apply id="S4.E5.m1.2.2.2.5.cmml" xref="S4.E5.m1.2.2.2.5"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.2.5.1.cmml" xref="S4.E5.m1.2.2.2.5">subscript</csymbol><ci id="S4.E5.m1.2.2.2.5.2.cmml" xref="S4.E5.m1.2.2.2.5.2">𝒟</ci><ci id="S4.E5.m1.2.2.2.5.3.cmml" xref="S4.E5.m1.2.2.2.5.3">𝑘</ci></apply></apply></apply><apply id="S4.E5.m1.7.7.3.2.cmml" xref="S4.E5.m1.7.7.3.2"><apply id="S4.E5.m1.7.7.3.2.3.cmml" xref="S4.E5.m1.7.7.3.2.3"><csymbol cd="ambiguous" id="S4.E5.m1.7.7.3.2.3.1.cmml" xref="S4.E5.m1.7.7.3.2.3">superscript</csymbol><apply id="S4.E5.m1.7.7.3.2.3.2.cmml" xref="S4.E5.m1.7.7.3.2.3"><csymbol cd="ambiguous" id="S4.E5.m1.7.7.3.2.3.2.1.cmml" xref="S4.E5.m1.7.7.3.2.3">subscript</csymbol><sum id="S4.E5.m1.7.7.3.2.3.2.2.cmml" xref="S4.E5.m1.7.7.3.2.3.2.2"></sum><apply id="S4.E5.m1.7.7.3.2.3.2.3.cmml" xref="S4.E5.m1.7.7.3.2.3.2.3"><eq id="S4.E5.m1.7.7.3.2.3.2.3.1.cmml" xref="S4.E5.m1.7.7.3.2.3.2.3.1"></eq><ci id="S4.E5.m1.7.7.3.2.3.2.3.2.cmml" xref="S4.E5.m1.7.7.3.2.3.2.3.2">𝑖</ci><cn id="S4.E5.m1.7.7.3.2.3.2.3.3.cmml" type="integer" xref="S4.E5.m1.7.7.3.2.3.2.3.3">1</cn></apply></apply><ci id="S4.E5.m1.7.7.3.2.3.3.cmml" xref="S4.E5.m1.7.7.3.2.3.3">𝑛</ci></apply><apply id="S4.E5.m1.7.7.3.2.2.cmml" xref="S4.E5.m1.7.7.3.2.2"><times id="S4.E5.m1.7.7.3.2.2.3.cmml" xref="S4.E5.m1.7.7.3.2.2.3"></times><apply id="S4.E5.m1.7.7.3.2.2.4.cmml" xref="S4.E5.m1.7.7.3.2.2.4"><csymbol cd="ambiguous" id="S4.E5.m1.7.7.3.2.2.4.1.cmml" xref="S4.E5.m1.7.7.3.2.2.4">subscript</csymbol><ci id="S4.E5.m1.7.7.3.2.2.4.2.cmml" xref="S4.E5.m1.7.7.3.2.2.4.2">ℒ</ci><apply id="S4.E5.m1.7.7.3.2.2.4.3.cmml" xref="S4.E5.m1.7.7.3.2.2.4.3"><times id="S4.E5.m1.7.7.3.2.2.4.3.1.cmml" xref="S4.E5.m1.7.7.3.2.2.4.3.1"></times><ci id="S4.E5.m1.7.7.3.2.2.4.3.2.cmml" xref="S4.E5.m1.7.7.3.2.2.4.3.2">𝑀</ci><ci id="S4.E5.m1.7.7.3.2.2.4.3.3.cmml" xref="S4.E5.m1.7.7.3.2.2.4.3.3">𝑆</ci><ci id="S4.E5.m1.7.7.3.2.2.4.3.4.cmml" xref="S4.E5.m1.7.7.3.2.2.4.3.4">𝐸</ci></apply></apply><interval closure="open" id="S4.E5.m1.7.7.3.2.2.2.3.cmml" xref="S4.E5.m1.7.7.3.2.2.2.2"><apply id="S4.E5.m1.6.6.2.1.1.1.1.1.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1"><times id="S4.E5.m1.6.6.2.1.1.1.1.1.2.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.2"></times><apply id="S4.E5.m1.6.6.2.1.1.1.1.1.3.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E5.m1.6.6.2.1.1.1.1.1.3.1.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E5.m1.6.6.2.1.1.1.1.1.3.2.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.3.2">𝒱</ci><ci id="S4.E5.m1.6.6.2.1.1.1.1.1.3.3.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.3.3">italic-ϕ</ci></apply><interval closure="open" id="S4.E5.m1.6.6.2.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1"><ci id="S4.E5.m1.4.4.cmml" xref="S4.E5.m1.4.4">𝑥</ci><apply id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2"><ci id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2.1">^</ci><ci id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.2.2">𝑦</ci></apply><ci id="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.6.6.2.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></interval></apply><apply id="S4.E5.m1.7.7.3.2.2.2.2.2.cmml" xref="S4.E5.m1.7.7.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E5.m1.7.7.3.2.2.2.2.2.1.cmml" xref="S4.E5.m1.7.7.3.2.2.2.2.2">subscript</csymbol><ci id="S4.E5.m1.7.7.3.2.2.2.2.2.2.cmml" xref="S4.E5.m1.7.7.3.2.2.2.2.2.2">𝑝</ci><ci id="S4.E5.m1.7.7.3.2.2.2.2.2.3.cmml" xref="S4.E5.m1.7.7.3.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.7c">\displaystyle\mathcal{L}_{tr}(\mathcal{D}_{k},\phi)=\sum_{(x,y)\in\mathcal{D}_%
{k}}\sum_{i=1}^{n}\mathcal{L}_{MSE}(\mathcal{V}_{\phi}(x,\hat{y}_{i}),p_{i})</annotation><annotation encoding="application/x-llamapun" id="S4.E5.m1.7d">caligraphic_L start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT ( caligraphic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_ϕ ) = ∑ start_POSTSUBSCRIPT ( italic_x , italic_y ) ∈ caligraphic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_M italic_S italic_E end_POSTSUBSCRIPT ( caligraphic_V start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT ( italic_x , over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p3">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p3.10">where <math alttext="\hat{y}_{i}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p3.1.m1.1"><semantics id="S4.SS0.SSS0.Px3.p3.1.m1.1a"><msub id="S4.SS0.SSS0.Px3.p3.1.m1.1.1" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1.cmml"><mover accent="true" id="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2.cmml"><mi id="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2.2" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2.2.cmml">y</mi><mo id="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2.1" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S4.SS0.SSS0.Px3.p3.1.m1.1.1.3" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p3.1.m1.1b"><apply id="S4.SS0.SSS0.Px3.p3.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p3.1.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1">subscript</csymbol><apply id="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2"><ci id="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2.1">^</ci><ci id="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1.2.2">𝑦</ci></apply><ci id="S4.SS0.SSS0.Px3.p3.1.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p3.1.m1.1c">\hat{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p3.1.m1.1d">over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the prefix of MLLM generated text <math alttext="\hat{y}=M_{\theta}(x)" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p3.2.m2.1"><semantics id="S4.SS0.SSS0.Px3.p3.2.m2.1a"><mrow id="S4.SS0.SSS0.Px3.p3.2.m2.1.2" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.cmml"><mover accent="true" id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2.cmml"><mi id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2.2" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2.2.cmml">y</mi><mo id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2.1" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2.1.cmml">^</mo></mover><mo id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.1" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.1.cmml">=</mo><mrow id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.cmml"><msub id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.cmml"><mi id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.2" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.2.cmml">M</mi><mi id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.3" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.3.cmml">θ</mi></msub><mo id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.1" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.1.cmml">⁢</mo><mrow id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.3.2" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.cmml"><mo id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.3.2.1" stretchy="false" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.cmml">(</mo><mi id="S4.SS0.SSS0.Px3.p3.2.m2.1.1" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.1.cmml">x</mi><mo id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.3.2.2" stretchy="false" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p3.2.m2.1b"><apply id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2"><eq id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.1.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.1"></eq><apply id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2"><ci id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2.1.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2.1">^</ci><ci id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2.2.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.2.2">𝑦</ci></apply><apply id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3"><times id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.1.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.1"></times><apply id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.1.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2">subscript</csymbol><ci id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.2.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.2">𝑀</ci><ci id="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.3.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.2.3.2.3">𝜃</ci></apply><ci id="S4.SS0.SSS0.Px3.p3.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.2.m2.1.1">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p3.2.m2.1c">\hat{y}=M_{\theta}(x)</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p3.2.m2.1d">over^ start_ARG italic_y end_ARG = italic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x )</annotation></semantics></math> given input pair <math alttext="x=(t,I)" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p3.3.m3.2"><semantics id="S4.SS0.SSS0.Px3.p3.3.m3.2a"><mrow id="S4.SS0.SSS0.Px3.p3.3.m3.2.3" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3.cmml"><mi id="S4.SS0.SSS0.Px3.p3.3.m3.2.3.2" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3.2.cmml">x</mi><mo id="S4.SS0.SSS0.Px3.p3.3.m3.2.3.1" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3.1.cmml">=</mo><mrow id="S4.SS0.SSS0.Px3.p3.3.m3.2.3.3.2" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3.3.1.cmml"><mo id="S4.SS0.SSS0.Px3.p3.3.m3.2.3.3.2.1" stretchy="false" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3.3.1.cmml">(</mo><mi id="S4.SS0.SSS0.Px3.p3.3.m3.1.1" xref="S4.SS0.SSS0.Px3.p3.3.m3.1.1.cmml">t</mi><mo id="S4.SS0.SSS0.Px3.p3.3.m3.2.3.3.2.2" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3.3.1.cmml">,</mo><mi id="S4.SS0.SSS0.Px3.p3.3.m3.2.2" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.2.cmml">I</mi><mo id="S4.SS0.SSS0.Px3.p3.3.m3.2.3.3.2.3" stretchy="false" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p3.3.m3.2b"><apply id="S4.SS0.SSS0.Px3.p3.3.m3.2.3.cmml" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3"><eq id="S4.SS0.SSS0.Px3.p3.3.m3.2.3.1.cmml" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3.1"></eq><ci id="S4.SS0.SSS0.Px3.p3.3.m3.2.3.2.cmml" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3.2">𝑥</ci><interval closure="open" id="S4.SS0.SSS0.Px3.p3.3.m3.2.3.3.1.cmml" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.3.3.2"><ci id="S4.SS0.SSS0.Px3.p3.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.3.m3.1.1">𝑡</ci><ci id="S4.SS0.SSS0.Px3.p3.3.m3.2.2.cmml" xref="S4.SS0.SSS0.Px3.p3.3.m3.2.2">𝐼</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p3.3.m3.2c">x=(t,I)</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p3.3.m3.2d">italic_x = ( italic_t , italic_I )</annotation></semantics></math>, and <math alttext="p_{i}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p3.4.m4.1"><semantics id="S4.SS0.SSS0.Px3.p3.4.m4.1a"><msub id="S4.SS0.SSS0.Px3.p3.4.m4.1.1" xref="S4.SS0.SSS0.Px3.p3.4.m4.1.1.cmml"><mi id="S4.SS0.SSS0.Px3.p3.4.m4.1.1.2" xref="S4.SS0.SSS0.Px3.p3.4.m4.1.1.2.cmml">p</mi><mi id="S4.SS0.SSS0.Px3.p3.4.m4.1.1.3" xref="S4.SS0.SSS0.Px3.p3.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p3.4.m4.1b"><apply id="S4.SS0.SSS0.Px3.p3.4.m4.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p3.4.m4.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.4.m4.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px3.p3.4.m4.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.4.m4.1.1.2">𝑝</ci><ci id="S4.SS0.SSS0.Px3.p3.4.m4.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p3.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p3.4.m4.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p3.4.m4.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the process supervision signal value obtained by Monte Carlo estimation given input pair <math alttext="x" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p3.5.m5.1"><semantics id="S4.SS0.SSS0.Px3.p3.5.m5.1a"><mi id="S4.SS0.SSS0.Px3.p3.5.m5.1.1" xref="S4.SS0.SSS0.Px3.p3.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p3.5.m5.1b"><ci id="S4.SS0.SSS0.Px3.p3.5.m5.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p3.5.m5.1c">x</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p3.5.m5.1d">italic_x</annotation></semantics></math>, prefix <math alttext="\hat{y}_{i}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p3.6.m6.1"><semantics id="S4.SS0.SSS0.Px3.p3.6.m6.1a"><msub id="S4.SS0.SSS0.Px3.p3.6.m6.1.1" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1.cmml"><mover accent="true" id="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2.cmml"><mi id="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2.2" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2.2.cmml">y</mi><mo id="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2.1" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2.1.cmml">^</mo></mover><mi id="S4.SS0.SSS0.Px3.p3.6.m6.1.1.3" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p3.6.m6.1b"><apply id="S4.SS0.SSS0.Px3.p3.6.m6.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p3.6.m6.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1">subscript</csymbol><apply id="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2"><ci id="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2.1">^</ci><ci id="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1.2.2">𝑦</ci></apply><ci id="S4.SS0.SSS0.Px3.p3.6.m6.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p3.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p3.6.m6.1c">\hat{y}_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p3.6.m6.1d">over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and ground truth label <math alttext="y" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p3.7.m7.1"><semantics id="S4.SS0.SSS0.Px3.p3.7.m7.1a"><mi id="S4.SS0.SSS0.Px3.p3.7.m7.1.1" xref="S4.SS0.SSS0.Px3.p3.7.m7.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p3.7.m7.1b"><ci id="S4.SS0.SSS0.Px3.p3.7.m7.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.7.m7.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p3.7.m7.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p3.7.m7.1d">italic_y</annotation></semantics></math>, as previously defined in Equation <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S3.E1" title="In PRM training with Monte Carlo signals. ‣ 3 Problem Setting and Preliminaries ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">1</span></a>. The PRM is optimized by minimizing the mean squared error (MSE) between supervision signal and PRM predicted score <math alttext="\mathcal{V}_{\phi}(x,\hat{y}_{i})" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p3.8.m8.2"><semantics id="S4.SS0.SSS0.Px3.p3.8.m8.2a"><mrow id="S4.SS0.SSS0.Px3.p3.8.m8.2.2" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.cmml"><msub id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.2" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.2.cmml">𝒱</mi><mi id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.3" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.3.cmml">ϕ</mi></msub><mo id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.2" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.2.cmml">⁢</mo><mrow id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.2.cmml"><mo id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.2" stretchy="false" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.2.cmml">(</mo><mi id="S4.SS0.SSS0.Px3.p3.8.m8.1.1" xref="S4.SS0.SSS0.Px3.p3.8.m8.1.1.cmml">x</mi><mo id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.3" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.2.cmml">,</mo><msub id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.cmml"><mover accent="true" id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2.cmml"><mi id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2.2" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2.2.cmml">y</mi><mo id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2.1" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2.1.cmml">^</mo></mover><mi id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.3" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.4" stretchy="false" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p3.8.m8.2b"><apply id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2"><times id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.2.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.2"></times><apply id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.1.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3">subscript</csymbol><ci id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.2.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.2">𝒱</ci><ci id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.3.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.3.3">italic-ϕ</ci></apply><interval closure="open" id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1"><ci id="S4.SS0.SSS0.Px3.p3.8.m8.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.1.1">𝑥</ci><apply id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1">subscript</csymbol><apply id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2"><ci id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2.1">^</ci><ci id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.2.2">𝑦</ci></apply><ci id="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p3.8.m8.2.2.1.1.1.3">𝑖</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p3.8.m8.2c">\mathcal{V}_{\phi}(x,\hat{y}_{i})</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p3.8.m8.2d">caligraphic_V start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT ( italic_x , over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. With the PRM training loss on a single domain <math alttext="\mathcal{D}_{k}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p3.9.m9.1"><semantics id="S4.SS0.SSS0.Px3.p3.9.m9.1a"><msub id="S4.SS0.SSS0.Px3.p3.9.m9.1.1" xref="S4.SS0.SSS0.Px3.p3.9.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px3.p3.9.m9.1.1.2" xref="S4.SS0.SSS0.Px3.p3.9.m9.1.1.2.cmml">𝒟</mi><mi id="S4.SS0.SSS0.Px3.p3.9.m9.1.1.3" xref="S4.SS0.SSS0.Px3.p3.9.m9.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p3.9.m9.1b"><apply id="S4.SS0.SSS0.Px3.p3.9.m9.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p3.9.m9.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.9.m9.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px3.p3.9.m9.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.9.m9.1.1.2">𝒟</ci><ci id="S4.SS0.SSS0.Px3.p3.9.m9.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p3.9.m9.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p3.9.m9.1c">\mathcal{D}_{k}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p3.9.m9.1d">caligraphic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> above, we next define the domain-reweighted training objective of PRM on multiple training domains <math alttext="\mathcal{D}=\{\mathcal{D}_{k}\}_{k=1}^{K}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p3.10.m10.1"><semantics id="S4.SS0.SSS0.Px3.p3.10.m10.1a"><mrow id="S4.SS0.SSS0.Px3.p3.10.m10.1.1" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.3" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.3.cmml">𝒟</mi><mo id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.2" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.2.cmml">=</mo><msubsup id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.cmml"><mrow id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.2.cmml"><mo id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.2.cmml">{</mo><msub id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.2" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.2.cmml">𝒟</mi><mi id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.3" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.3.cmml">k</mi></msub><mo id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.2" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.2.cmml">k</mi><mo id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.1" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.3" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.3" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.3.cmml">K</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p3.10.m10.1b"><apply id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1"><eq id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.2"></eq><ci id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.3">𝒟</ci><apply id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1">superscript</csymbol><apply id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1">subscript</csymbol><set id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1"><apply id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.2">𝒟</ci><ci id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.1.1.1.3">𝑘</ci></apply></set><apply id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3"><eq id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.1"></eq><ci id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.2">𝑘</ci><cn id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.3.cmml" type="integer" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p3.10.m10.1.1.1.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p3.10.m10.1c">\mathcal{D}=\{\mathcal{D}_{k}\}_{k=1}^{K}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p3.10.m10.1d">caligraphic_D = { caligraphic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT</annotation></semantics></math>. The overall objective is a weighted sum of the single-domain PRM training losses, allowing the contribution of each domain to be adjusted during the learning process:</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p4">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A6.EGx3">
<tbody id="S4.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{tr}(\mathcal{D}_{tr},\phi,\alpha)=\sum_{k=1}^{K}%
\alpha_{k}\mathcal{L}_{tr}(\mathcal{D}_{k},\phi)" class="ltx_Math" display="inline" id="S4.E6.m1.5"><semantics id="S4.E6.m1.5a"><mrow id="S4.E6.m1.5.5" xref="S4.E6.m1.5.5.cmml"><mrow id="S4.E6.m1.4.4.1" xref="S4.E6.m1.4.4.1.cmml"><msub id="S4.E6.m1.4.4.1.3" xref="S4.E6.m1.4.4.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E6.m1.4.4.1.3.2" xref="S4.E6.m1.4.4.1.3.2.cmml">ℒ</mi><mrow id="S4.E6.m1.4.4.1.3.3" xref="S4.E6.m1.4.4.1.3.3.cmml"><mi id="S4.E6.m1.4.4.1.3.3.2" xref="S4.E6.m1.4.4.1.3.3.2.cmml">t</mi><mo id="S4.E6.m1.4.4.1.3.3.1" xref="S4.E6.m1.4.4.1.3.3.1.cmml">⁢</mo><mi id="S4.E6.m1.4.4.1.3.3.3" xref="S4.E6.m1.4.4.1.3.3.3.cmml">r</mi></mrow></msub><mo id="S4.E6.m1.4.4.1.2" xref="S4.E6.m1.4.4.1.2.cmml">⁢</mo><mrow id="S4.E6.m1.4.4.1.1.1" xref="S4.E6.m1.4.4.1.1.2.cmml"><mo id="S4.E6.m1.4.4.1.1.1.2" stretchy="false" xref="S4.E6.m1.4.4.1.1.2.cmml">(</mo><msub id="S4.E6.m1.4.4.1.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E6.m1.4.4.1.1.1.1.2" xref="S4.E6.m1.4.4.1.1.1.1.2.cmml">𝒟</mi><mrow id="S4.E6.m1.4.4.1.1.1.1.3" xref="S4.E6.m1.4.4.1.1.1.1.3.cmml"><mi id="S4.E6.m1.4.4.1.1.1.1.3.2" xref="S4.E6.m1.4.4.1.1.1.1.3.2.cmml">t</mi><mo id="S4.E6.m1.4.4.1.1.1.1.3.1" xref="S4.E6.m1.4.4.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.E6.m1.4.4.1.1.1.1.3.3" xref="S4.E6.m1.4.4.1.1.1.1.3.3.cmml">r</mi></mrow></msub><mo id="S4.E6.m1.4.4.1.1.1.3" xref="S4.E6.m1.4.4.1.1.2.cmml">,</mo><mi id="S4.E6.m1.1.1" xref="S4.E6.m1.1.1.cmml">ϕ</mi><mo id="S4.E6.m1.4.4.1.1.1.4" xref="S4.E6.m1.4.4.1.1.2.cmml">,</mo><mi id="S4.E6.m1.2.2" xref="S4.E6.m1.2.2.cmml">α</mi><mo id="S4.E6.m1.4.4.1.1.1.5" stretchy="false" xref="S4.E6.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.E6.m1.5.5.3" xref="S4.E6.m1.5.5.3.cmml">=</mo><mrow id="S4.E6.m1.5.5.2" xref="S4.E6.m1.5.5.2.cmml"><mstyle displaystyle="true" id="S4.E6.m1.5.5.2.2" xref="S4.E6.m1.5.5.2.2.cmml"><munderover id="S4.E6.m1.5.5.2.2a" xref="S4.E6.m1.5.5.2.2.cmml"><mo id="S4.E6.m1.5.5.2.2.2.2" movablelimits="false" xref="S4.E6.m1.5.5.2.2.2.2.cmml">∑</mo><mrow id="S4.E6.m1.5.5.2.2.2.3" xref="S4.E6.m1.5.5.2.2.2.3.cmml"><mi id="S4.E6.m1.5.5.2.2.2.3.2" xref="S4.E6.m1.5.5.2.2.2.3.2.cmml">k</mi><mo id="S4.E6.m1.5.5.2.2.2.3.1" xref="S4.E6.m1.5.5.2.2.2.3.1.cmml">=</mo><mn id="S4.E6.m1.5.5.2.2.2.3.3" xref="S4.E6.m1.5.5.2.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E6.m1.5.5.2.2.3" xref="S4.E6.m1.5.5.2.2.3.cmml">K</mi></munderover></mstyle><mrow id="S4.E6.m1.5.5.2.1" xref="S4.E6.m1.5.5.2.1.cmml"><msub id="S4.E6.m1.5.5.2.1.3" xref="S4.E6.m1.5.5.2.1.3.cmml"><mi id="S4.E6.m1.5.5.2.1.3.2" xref="S4.E6.m1.5.5.2.1.3.2.cmml">α</mi><mi id="S4.E6.m1.5.5.2.1.3.3" xref="S4.E6.m1.5.5.2.1.3.3.cmml">k</mi></msub><mo id="S4.E6.m1.5.5.2.1.2" xref="S4.E6.m1.5.5.2.1.2.cmml">⁢</mo><msub id="S4.E6.m1.5.5.2.1.4" xref="S4.E6.m1.5.5.2.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E6.m1.5.5.2.1.4.2" xref="S4.E6.m1.5.5.2.1.4.2.cmml">ℒ</mi><mrow id="S4.E6.m1.5.5.2.1.4.3" xref="S4.E6.m1.5.5.2.1.4.3.cmml"><mi id="S4.E6.m1.5.5.2.1.4.3.2" xref="S4.E6.m1.5.5.2.1.4.3.2.cmml">t</mi><mo id="S4.E6.m1.5.5.2.1.4.3.1" xref="S4.E6.m1.5.5.2.1.4.3.1.cmml">⁢</mo><mi id="S4.E6.m1.5.5.2.1.4.3.3" xref="S4.E6.m1.5.5.2.1.4.3.3.cmml">r</mi></mrow></msub><mo id="S4.E6.m1.5.5.2.1.2a" xref="S4.E6.m1.5.5.2.1.2.cmml">⁢</mo><mrow id="S4.E6.m1.5.5.2.1.1.1" xref="S4.E6.m1.5.5.2.1.1.2.cmml"><mo id="S4.E6.m1.5.5.2.1.1.1.2" stretchy="false" xref="S4.E6.m1.5.5.2.1.1.2.cmml">(</mo><msub id="S4.E6.m1.5.5.2.1.1.1.1" xref="S4.E6.m1.5.5.2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E6.m1.5.5.2.1.1.1.1.2" xref="S4.E6.m1.5.5.2.1.1.1.1.2.cmml">𝒟</mi><mi id="S4.E6.m1.5.5.2.1.1.1.1.3" xref="S4.E6.m1.5.5.2.1.1.1.1.3.cmml">k</mi></msub><mo id="S4.E6.m1.5.5.2.1.1.1.3" xref="S4.E6.m1.5.5.2.1.1.2.cmml">,</mo><mi id="S4.E6.m1.3.3" xref="S4.E6.m1.3.3.cmml">ϕ</mi><mo id="S4.E6.m1.5.5.2.1.1.1.4" stretchy="false" xref="S4.E6.m1.5.5.2.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.5b"><apply id="S4.E6.m1.5.5.cmml" xref="S4.E6.m1.5.5"><eq id="S4.E6.m1.5.5.3.cmml" xref="S4.E6.m1.5.5.3"></eq><apply id="S4.E6.m1.4.4.1.cmml" xref="S4.E6.m1.4.4.1"><times id="S4.E6.m1.4.4.1.2.cmml" xref="S4.E6.m1.4.4.1.2"></times><apply id="S4.E6.m1.4.4.1.3.cmml" xref="S4.E6.m1.4.4.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.4.4.1.3.1.cmml" xref="S4.E6.m1.4.4.1.3">subscript</csymbol><ci id="S4.E6.m1.4.4.1.3.2.cmml" xref="S4.E6.m1.4.4.1.3.2">ℒ</ci><apply id="S4.E6.m1.4.4.1.3.3.cmml" xref="S4.E6.m1.4.4.1.3.3"><times id="S4.E6.m1.4.4.1.3.3.1.cmml" xref="S4.E6.m1.4.4.1.3.3.1"></times><ci id="S4.E6.m1.4.4.1.3.3.2.cmml" xref="S4.E6.m1.4.4.1.3.3.2">𝑡</ci><ci id="S4.E6.m1.4.4.1.3.3.3.cmml" xref="S4.E6.m1.4.4.1.3.3.3">𝑟</ci></apply></apply><vector id="S4.E6.m1.4.4.1.1.2.cmml" xref="S4.E6.m1.4.4.1.1.1"><apply id="S4.E6.m1.4.4.1.1.1.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S4.E6.m1.4.4.1.1.1.1.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1">subscript</csymbol><ci id="S4.E6.m1.4.4.1.1.1.1.2.cmml" xref="S4.E6.m1.4.4.1.1.1.1.2">𝒟</ci><apply id="S4.E6.m1.4.4.1.1.1.1.3.cmml" xref="S4.E6.m1.4.4.1.1.1.1.3"><times id="S4.E6.m1.4.4.1.1.1.1.3.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1.3.1"></times><ci id="S4.E6.m1.4.4.1.1.1.1.3.2.cmml" xref="S4.E6.m1.4.4.1.1.1.1.3.2">𝑡</ci><ci id="S4.E6.m1.4.4.1.1.1.1.3.3.cmml" xref="S4.E6.m1.4.4.1.1.1.1.3.3">𝑟</ci></apply></apply><ci id="S4.E6.m1.1.1.cmml" xref="S4.E6.m1.1.1">italic-ϕ</ci><ci id="S4.E6.m1.2.2.cmml" xref="S4.E6.m1.2.2">𝛼</ci></vector></apply><apply id="S4.E6.m1.5.5.2.cmml" xref="S4.E6.m1.5.5.2"><apply id="S4.E6.m1.5.5.2.2.cmml" xref="S4.E6.m1.5.5.2.2"><csymbol cd="ambiguous" id="S4.E6.m1.5.5.2.2.1.cmml" xref="S4.E6.m1.5.5.2.2">superscript</csymbol><apply id="S4.E6.m1.5.5.2.2.2.cmml" xref="S4.E6.m1.5.5.2.2"><csymbol cd="ambiguous" id="S4.E6.m1.5.5.2.2.2.1.cmml" xref="S4.E6.m1.5.5.2.2">subscript</csymbol><sum id="S4.E6.m1.5.5.2.2.2.2.cmml" xref="S4.E6.m1.5.5.2.2.2.2"></sum><apply id="S4.E6.m1.5.5.2.2.2.3.cmml" xref="S4.E6.m1.5.5.2.2.2.3"><eq id="S4.E6.m1.5.5.2.2.2.3.1.cmml" xref="S4.E6.m1.5.5.2.2.2.3.1"></eq><ci id="S4.E6.m1.5.5.2.2.2.3.2.cmml" xref="S4.E6.m1.5.5.2.2.2.3.2">𝑘</ci><cn id="S4.E6.m1.5.5.2.2.2.3.3.cmml" type="integer" xref="S4.E6.m1.5.5.2.2.2.3.3">1</cn></apply></apply><ci id="S4.E6.m1.5.5.2.2.3.cmml" xref="S4.E6.m1.5.5.2.2.3">𝐾</ci></apply><apply id="S4.E6.m1.5.5.2.1.cmml" xref="S4.E6.m1.5.5.2.1"><times id="S4.E6.m1.5.5.2.1.2.cmml" xref="S4.E6.m1.5.5.2.1.2"></times><apply id="S4.E6.m1.5.5.2.1.3.cmml" xref="S4.E6.m1.5.5.2.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.5.5.2.1.3.1.cmml" xref="S4.E6.m1.5.5.2.1.3">subscript</csymbol><ci id="S4.E6.m1.5.5.2.1.3.2.cmml" xref="S4.E6.m1.5.5.2.1.3.2">𝛼</ci><ci id="S4.E6.m1.5.5.2.1.3.3.cmml" xref="S4.E6.m1.5.5.2.1.3.3">𝑘</ci></apply><apply id="S4.E6.m1.5.5.2.1.4.cmml" xref="S4.E6.m1.5.5.2.1.4"><csymbol cd="ambiguous" id="S4.E6.m1.5.5.2.1.4.1.cmml" xref="S4.E6.m1.5.5.2.1.4">subscript</csymbol><ci id="S4.E6.m1.5.5.2.1.4.2.cmml" xref="S4.E6.m1.5.5.2.1.4.2">ℒ</ci><apply id="S4.E6.m1.5.5.2.1.4.3.cmml" xref="S4.E6.m1.5.5.2.1.4.3"><times id="S4.E6.m1.5.5.2.1.4.3.1.cmml" xref="S4.E6.m1.5.5.2.1.4.3.1"></times><ci id="S4.E6.m1.5.5.2.1.4.3.2.cmml" xref="S4.E6.m1.5.5.2.1.4.3.2">𝑡</ci><ci id="S4.E6.m1.5.5.2.1.4.3.3.cmml" xref="S4.E6.m1.5.5.2.1.4.3.3">𝑟</ci></apply></apply><interval closure="open" id="S4.E6.m1.5.5.2.1.1.2.cmml" xref="S4.E6.m1.5.5.2.1.1.1"><apply id="S4.E6.m1.5.5.2.1.1.1.1.cmml" xref="S4.E6.m1.5.5.2.1.1.1.1"><csymbol cd="ambiguous" id="S4.E6.m1.5.5.2.1.1.1.1.1.cmml" xref="S4.E6.m1.5.5.2.1.1.1.1">subscript</csymbol><ci id="S4.E6.m1.5.5.2.1.1.1.1.2.cmml" xref="S4.E6.m1.5.5.2.1.1.1.1.2">𝒟</ci><ci id="S4.E6.m1.5.5.2.1.1.1.1.3.cmml" xref="S4.E6.m1.5.5.2.1.1.1.1.3">𝑘</ci></apply><ci id="S4.E6.m1.3.3.cmml" xref="S4.E6.m1.3.3">italic-ϕ</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.5c">\displaystyle\mathcal{L}_{tr}(\mathcal{D}_{tr},\phi,\alpha)=\sum_{k=1}^{K}%
\alpha_{k}\mathcal{L}_{tr}(\mathcal{D}_{k},\phi)</annotation><annotation encoding="application/x-llamapun" id="S4.E6.m1.5d">caligraphic_L start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT ( caligraphic_D start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT , italic_ϕ , italic_α ) = ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT italic_α start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT ( caligraphic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_ϕ )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p5">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p5.2">Here, <math alttext="\alpha=\{\alpha_{k}\}_{k=1}^{K}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p5.1.m1.1"><semantics id="S4.SS0.SSS0.Px3.p5.1.m1.1a"><mrow id="S4.SS0.SSS0.Px3.p5.1.m1.1.1" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.cmml"><mi id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.3" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.3.cmml">α</mi><mo id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.2" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.2.cmml">=</mo><msubsup id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.cmml"><mrow id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.2.cmml"><mo id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.2" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.2.cmml">α</mi><mi id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.3" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.3.cmml">k</mi></msub><mo id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.2" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.2.cmml">k</mi><mo id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.1" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.3" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.3" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.3.cmml">K</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p5.1.m1.1b"><apply id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1"><eq id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.2"></eq><ci id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.3">𝛼</ci><apply id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1">superscript</csymbol><apply id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1">subscript</csymbol><set id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1"><apply id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.2">𝛼</ci><ci id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.1.1.1.3">𝑘</ci></apply></set><apply id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3"><eq id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.1"></eq><ci id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.2">𝑘</ci><cn id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.3.cmml" type="integer" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p5.1.m1.1.1.1.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p5.1.m1.1c">\alpha=\{\alpha_{k}\}_{k=1}^{K}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p5.1.m1.1d">italic_α = { italic_α start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT</annotation></semantics></math> represents the trainable domain weight parameters, indicating the importance of each domain. By optimizing this objective, we obtain the optimal value of PRM parameters <math alttext="\phi^{*}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p5.2.m2.1"><semantics id="S4.SS0.SSS0.Px3.p5.2.m2.1a"><msup id="S4.SS0.SSS0.Px3.p5.2.m2.1.1" xref="S4.SS0.SSS0.Px3.p5.2.m2.1.1.cmml"><mi id="S4.SS0.SSS0.Px3.p5.2.m2.1.1.2" xref="S4.SS0.SSS0.Px3.p5.2.m2.1.1.2.cmml">ϕ</mi><mo id="S4.SS0.SSS0.Px3.p5.2.m2.1.1.3" xref="S4.SS0.SSS0.Px3.p5.2.m2.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p5.2.m2.1b"><apply id="S4.SS0.SSS0.Px3.p5.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px3.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px3.p5.2.m2.1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p5.2.m2.1.1">superscript</csymbol><ci id="S4.SS0.SSS0.Px3.p5.2.m2.1.1.2.cmml" xref="S4.SS0.SSS0.Px3.p5.2.m2.1.1.2">italic-ϕ</ci><times id="S4.SS0.SSS0.Px3.p5.2.m2.1.1.3.cmml" xref="S4.SS0.SSS0.Px3.p5.2.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p5.2.m2.1c">\phi^{*}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p5.2.m2.1d">italic_ϕ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math>:</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p6">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A6.EGx4">
<tbody id="S4.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\phi^{*}(\alpha)=" class="ltx_Math" display="inline" id="S4.E7.m1.1"><semantics id="S4.E7.m1.1a"><mrow id="S4.E7.m1.1.2" xref="S4.E7.m1.1.2.cmml"><mrow id="S4.E7.m1.1.2.2" xref="S4.E7.m1.1.2.2.cmml"><msup id="S4.E7.m1.1.2.2.2" xref="S4.E7.m1.1.2.2.2.cmml"><mi id="S4.E7.m1.1.2.2.2.2" xref="S4.E7.m1.1.2.2.2.2.cmml">ϕ</mi><mo id="S4.E7.m1.1.2.2.2.3" xref="S4.E7.m1.1.2.2.2.3.cmml">∗</mo></msup><mo id="S4.E7.m1.1.2.2.1" xref="S4.E7.m1.1.2.2.1.cmml">⁢</mo><mrow id="S4.E7.m1.1.2.2.3.2" xref="S4.E7.m1.1.2.2.cmml"><mo id="S4.E7.m1.1.2.2.3.2.1" stretchy="false" xref="S4.E7.m1.1.2.2.cmml">(</mo><mi id="S4.E7.m1.1.1" xref="S4.E7.m1.1.1.cmml">α</mi><mo id="S4.E7.m1.1.2.2.3.2.2" stretchy="false" xref="S4.E7.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S4.E7.m1.1.2.1" xref="S4.E7.m1.1.2.1.cmml">=</mo><mi id="S4.E7.m1.1.2.3" xref="S4.E7.m1.1.2.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m1.1b"><apply id="S4.E7.m1.1.2.cmml" xref="S4.E7.m1.1.2"><eq id="S4.E7.m1.1.2.1.cmml" xref="S4.E7.m1.1.2.1"></eq><apply id="S4.E7.m1.1.2.2.cmml" xref="S4.E7.m1.1.2.2"><times id="S4.E7.m1.1.2.2.1.cmml" xref="S4.E7.m1.1.2.2.1"></times><apply id="S4.E7.m1.1.2.2.2.cmml" xref="S4.E7.m1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E7.m1.1.2.2.2.1.cmml" xref="S4.E7.m1.1.2.2.2">superscript</csymbol><ci id="S4.E7.m1.1.2.2.2.2.cmml" xref="S4.E7.m1.1.2.2.2.2">italic-ϕ</ci><times id="S4.E7.m1.1.2.2.2.3.cmml" xref="S4.E7.m1.1.2.2.2.3"></times></apply><ci id="S4.E7.m1.1.1.cmml" xref="S4.E7.m1.1.1">𝛼</ci></apply><csymbol cd="latexml" id="S4.E7.m1.1.2.3.cmml" xref="S4.E7.m1.1.2.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.1c">\displaystyle\phi^{*}(\alpha)=</annotation><annotation encoding="application/x-llamapun" id="S4.E7.m1.1d">italic_ϕ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_α ) =</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\underset{\mathbf{\phi}}{\arg\min}\mathcal{L}_{tr}(\mathcal{D}_{%
tr},\phi,\alpha)" class="ltx_Math" display="inline" id="S4.E7.m2.3"><semantics id="S4.E7.m2.3a"><mrow id="S4.E7.m2.3.3" xref="S4.E7.m2.3.3.cmml"><munder accentunder="true" id="S4.E7.m2.3.3.3" xref="S4.E7.m2.3.3.3.cmml"><mrow id="S4.E7.m2.3.3.3.2" xref="S4.E7.m2.3.3.3.2.cmml"><mi id="S4.E7.m2.3.3.3.2.1" xref="S4.E7.m2.3.3.3.2.1.cmml">arg</mi><mo id="S4.E7.m2.3.3.3.2a" lspace="0.167em" xref="S4.E7.m2.3.3.3.2.cmml">⁡</mo><mi id="S4.E7.m2.3.3.3.2.2" xref="S4.E7.m2.3.3.3.2.2.cmml">min</mi></mrow><mo class="ltx_mathvariant_italic" id="S4.E7.m2.3.3.3.1" mathvariant="italic" xref="S4.E7.m2.3.3.3.1.cmml">ϕ</mo></munder><mo id="S4.E7.m2.3.3.2" xref="S4.E7.m2.3.3.2.cmml">⁢</mo><msub id="S4.E7.m2.3.3.4" xref="S4.E7.m2.3.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E7.m2.3.3.4.2" xref="S4.E7.m2.3.3.4.2.cmml">ℒ</mi><mrow id="S4.E7.m2.3.3.4.3" xref="S4.E7.m2.3.3.4.3.cmml"><mi id="S4.E7.m2.3.3.4.3.2" xref="S4.E7.m2.3.3.4.3.2.cmml">t</mi><mo id="S4.E7.m2.3.3.4.3.1" xref="S4.E7.m2.3.3.4.3.1.cmml">⁢</mo><mi id="S4.E7.m2.3.3.4.3.3" xref="S4.E7.m2.3.3.4.3.3.cmml">r</mi></mrow></msub><mo id="S4.E7.m2.3.3.2a" xref="S4.E7.m2.3.3.2.cmml">⁢</mo><mrow id="S4.E7.m2.3.3.1.1" xref="S4.E7.m2.3.3.1.2.cmml"><mo id="S4.E7.m2.3.3.1.1.2" stretchy="false" xref="S4.E7.m2.3.3.1.2.cmml">(</mo><msub id="S4.E7.m2.3.3.1.1.1" xref="S4.E7.m2.3.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E7.m2.3.3.1.1.1.2" xref="S4.E7.m2.3.3.1.1.1.2.cmml">𝒟</mi><mrow id="S4.E7.m2.3.3.1.1.1.3" xref="S4.E7.m2.3.3.1.1.1.3.cmml"><mi id="S4.E7.m2.3.3.1.1.1.3.2" xref="S4.E7.m2.3.3.1.1.1.3.2.cmml">t</mi><mo id="S4.E7.m2.3.3.1.1.1.3.1" xref="S4.E7.m2.3.3.1.1.1.3.1.cmml">⁢</mo><mi id="S4.E7.m2.3.3.1.1.1.3.3" xref="S4.E7.m2.3.3.1.1.1.3.3.cmml">r</mi></mrow></msub><mo id="S4.E7.m2.3.3.1.1.3" xref="S4.E7.m2.3.3.1.2.cmml">,</mo><mi id="S4.E7.m2.1.1" xref="S4.E7.m2.1.1.cmml">ϕ</mi><mo id="S4.E7.m2.3.3.1.1.4" xref="S4.E7.m2.3.3.1.2.cmml">,</mo><mi id="S4.E7.m2.2.2" xref="S4.E7.m2.2.2.cmml">α</mi><mo id="S4.E7.m2.3.3.1.1.5" stretchy="false" xref="S4.E7.m2.3.3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m2.3b"><apply id="S4.E7.m2.3.3.cmml" xref="S4.E7.m2.3.3"><times id="S4.E7.m2.3.3.2.cmml" xref="S4.E7.m2.3.3.2"></times><apply id="S4.E7.m2.3.3.3.cmml" xref="S4.E7.m2.3.3.3"><ci id="S4.E7.m2.3.3.3.1.cmml" xref="S4.E7.m2.3.3.3.1">italic-ϕ</ci><apply id="S4.E7.m2.3.3.3.2.cmml" xref="S4.E7.m2.3.3.3.2"><arg id="S4.E7.m2.3.3.3.2.1.cmml" xref="S4.E7.m2.3.3.3.2.1"></arg><min id="S4.E7.m2.3.3.3.2.2.cmml" xref="S4.E7.m2.3.3.3.2.2"></min></apply></apply><apply id="S4.E7.m2.3.3.4.cmml" xref="S4.E7.m2.3.3.4"><csymbol cd="ambiguous" id="S4.E7.m2.3.3.4.1.cmml" xref="S4.E7.m2.3.3.4">subscript</csymbol><ci id="S4.E7.m2.3.3.4.2.cmml" xref="S4.E7.m2.3.3.4.2">ℒ</ci><apply id="S4.E7.m2.3.3.4.3.cmml" xref="S4.E7.m2.3.3.4.3"><times id="S4.E7.m2.3.3.4.3.1.cmml" xref="S4.E7.m2.3.3.4.3.1"></times><ci id="S4.E7.m2.3.3.4.3.2.cmml" xref="S4.E7.m2.3.3.4.3.2">𝑡</ci><ci id="S4.E7.m2.3.3.4.3.3.cmml" xref="S4.E7.m2.3.3.4.3.3">𝑟</ci></apply></apply><vector id="S4.E7.m2.3.3.1.2.cmml" xref="S4.E7.m2.3.3.1.1"><apply id="S4.E7.m2.3.3.1.1.1.cmml" xref="S4.E7.m2.3.3.1.1.1"><csymbol cd="ambiguous" id="S4.E7.m2.3.3.1.1.1.1.cmml" xref="S4.E7.m2.3.3.1.1.1">subscript</csymbol><ci id="S4.E7.m2.3.3.1.1.1.2.cmml" xref="S4.E7.m2.3.3.1.1.1.2">𝒟</ci><apply id="S4.E7.m2.3.3.1.1.1.3.cmml" xref="S4.E7.m2.3.3.1.1.1.3"><times id="S4.E7.m2.3.3.1.1.1.3.1.cmml" xref="S4.E7.m2.3.3.1.1.1.3.1"></times><ci id="S4.E7.m2.3.3.1.1.1.3.2.cmml" xref="S4.E7.m2.3.3.1.1.1.3.2">𝑡</ci><ci id="S4.E7.m2.3.3.1.1.1.3.3.cmml" xref="S4.E7.m2.3.3.1.1.1.3.3">𝑟</ci></apply></apply><ci id="S4.E7.m2.1.1.cmml" xref="S4.E7.m2.1.1">italic-ϕ</ci><ci id="S4.E7.m2.2.2.cmml" xref="S4.E7.m2.2.2">𝛼</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m2.3c">\displaystyle\underset{\mathbf{\phi}}{\arg\min}\mathcal{L}_{tr}(\mathcal{D}_{%
tr},\phi,\alpha)</annotation><annotation encoding="application/x-llamapun" id="S4.E7.m2.3d">underitalic_ϕ start_ARG roman_arg roman_min end_ARG caligraphic_L start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT ( caligraphic_D start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT , italic_ϕ , italic_α )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p7">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p7.2">It is worth mentioning that only <math alttext="\phi" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p7.1.m1.1"><semantics id="S4.SS0.SSS0.Px3.p7.1.m1.1a"><mi id="S4.SS0.SSS0.Px3.p7.1.m1.1.1" xref="S4.SS0.SSS0.Px3.p7.1.m1.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p7.1.m1.1b"><ci id="S4.SS0.SSS0.Px3.p7.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p7.1.m1.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p7.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p7.1.m1.1d">italic_ϕ</annotation></semantics></math> is optimized at this level, while <math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p7.2.m2.1"><semantics id="S4.SS0.SSS0.Px3.p7.2.m2.1a"><mi id="S4.SS0.SSS0.Px3.p7.2.m2.1.1" xref="S4.SS0.SSS0.Px3.p7.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p7.2.m2.1b"><ci id="S4.SS0.SSS0.Px3.p7.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px3.p7.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p7.2.m2.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p7.2.m2.1d">italic_α</annotation></semantics></math> remains fixed.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Upper-level optimization: learning domain reweighting parameters.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p1.11">In upper-level optimization, we optimize the domain reweighting parameter <math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px4.p1.1.m1.1a"><mi id="S4.SS0.SSS0.Px4.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px4.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.1.m1.1b"><ci id="S4.SS0.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.1.m1.1d">italic_α</annotation></semantics></math> on meta dataset <math alttext="\mathcal{D}_{meta}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.2.m2.1"><semantics id="S4.SS0.SSS0.Px4.p1.2.m2.1a"><msub id="S4.SS0.SSS0.Px4.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.2" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.2.cmml">𝒟</mi><mrow id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.2" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.2.cmml">m</mi><mo id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.1" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.3" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.3.cmml">e</mi><mo id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.1a" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.4" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.4.cmml">t</mi><mo id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.1b" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.5" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.5.cmml">a</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.2.m2.1b"><apply id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.2">𝒟</ci><apply id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3"><times id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.1"></times><ci id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.2">𝑚</ci><ci id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.3">𝑒</ci><ci id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.4.cmml" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.4">𝑡</ci><ci id="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.5.cmml" xref="S4.SS0.SSS0.Px4.p1.2.m2.1.1.3.5">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.2.m2.1c">\mathcal{D}_{meta}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT</annotation></semantics></math> given optimal PRM weights <math alttext="\phi^{*}(\alpha)" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.3.m3.1"><semantics id="S4.SS0.SSS0.Px4.p1.3.m3.1a"><mrow id="S4.SS0.SSS0.Px4.p1.3.m3.1.2" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.cmml"><msup id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.cmml"><mi id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.2" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.2.cmml">ϕ</mi><mo id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.3" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.3.cmml">∗</mo></msup><mo id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.1" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.1.cmml">⁢</mo><mrow id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.3.2" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.cmml"><mo id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.3.2.1" stretchy="false" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.cmml">(</mo><mi id="S4.SS0.SSS0.Px4.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.1.cmml">α</mi><mo id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.3.2.2" stretchy="false" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.3.m3.1b"><apply id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.cmml" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2"><times id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.1.cmml" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.1"></times><apply id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.cmml" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.1.cmml" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2">superscript</csymbol><ci id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.2.cmml" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.2">italic-ϕ</ci><times id="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.3.cmml" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.2.2.3"></times></apply><ci id="S4.SS0.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.3.m3.1.1">𝛼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.3.m3.1c">\phi^{*}(\alpha)</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.3.m3.1d">italic_ϕ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_α )</annotation></semantics></math> obtained from the lower level. To make the meta learning target more closely reflect the actual PRM-based inference process, we propose a novel meta loss function <math alttext="\mathcal{L}_{meta}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.4.m4.1"><semantics id="S4.SS0.SSS0.Px4.p1.4.m4.1a"><msub id="S4.SS0.SSS0.Px4.p1.4.m4.1.1" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.2" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.2.cmml">ℒ</mi><mrow id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.2" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.2.cmml">m</mi><mo id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.1" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.3" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.3.cmml">e</mi><mo id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.1a" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.4" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.4.cmml">t</mi><mo id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.1b" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.5" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.5.cmml">a</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.4.m4.1b"><apply id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.2">ℒ</ci><apply id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3"><times id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.1"></times><ci id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.2">𝑚</ci><ci id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.3">𝑒</ci><ci id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.4.cmml" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.4">𝑡</ci><ci id="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.5.cmml" xref="S4.SS0.SSS0.Px4.p1.4.m4.1.1.3.5">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.4.m4.1c">\mathcal{L}_{meta}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.4.m4.1d">caligraphic_L start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT</annotation></semantics></math>, different from the training loss <math alttext="\mathcal{L}_{tr}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.5.m5.1"><semantics id="S4.SS0.SSS0.Px4.p1.5.m5.1a"><msub id="S4.SS0.SSS0.Px4.p1.5.m5.1.1" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.2" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.2.cmml">ℒ</mi><mrow id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.2" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.2.cmml">t</mi><mo id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.1" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.3" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.5.m5.1b"><apply id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.2">ℒ</ci><apply id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3"><times id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.1"></times><ci id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.2">𝑡</ci><ci id="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px4.p1.5.m5.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.5.m5.1c">\mathcal{L}_{tr}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.5.m5.1d">caligraphic_L start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT</annotation></semantics></math>. Specifically, we first obtain an aggregated score <math alttext="\mathcal{A}({p})" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.6.m6.1"><semantics id="S4.SS0.SSS0.Px4.p1.6.m6.1a"><mrow id="S4.SS0.SSS0.Px4.p1.6.m6.1.2" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p1.6.m6.1.2.2" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.2.2.cmml">𝒜</mi><mo id="S4.SS0.SSS0.Px4.p1.6.m6.1.2.1" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.2.1.cmml">⁢</mo><mrow id="S4.SS0.SSS0.Px4.p1.6.m6.1.2.3.2" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.2.cmml"><mo id="S4.SS0.SSS0.Px4.p1.6.m6.1.2.3.2.1" stretchy="false" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.2.cmml">(</mo><mi id="S4.SS0.SSS0.Px4.p1.6.m6.1.1" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.1.cmml">p</mi><mo id="S4.SS0.SSS0.Px4.p1.6.m6.1.2.3.2.2" stretchy="false" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.6.m6.1b"><apply id="S4.SS0.SSS0.Px4.p1.6.m6.1.2.cmml" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.2"><times id="S4.SS0.SSS0.Px4.p1.6.m6.1.2.1.cmml" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.2.1"></times><ci id="S4.SS0.SSS0.Px4.p1.6.m6.1.2.2.cmml" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.2.2">𝒜</ci><ci id="S4.SS0.SSS0.Px4.p1.6.m6.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.6.m6.1.1">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.6.m6.1c">\mathcal{A}({p})</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.6.m6.1d">caligraphic_A ( italic_p )</annotation></semantics></math> for each generated solution <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.7.m7.1"><semantics id="S4.SS0.SSS0.Px4.p1.7.m7.1a"><mover accent="true" id="S4.SS0.SSS0.Px4.p1.7.m7.1.1" xref="S4.SS0.SSS0.Px4.p1.7.m7.1.1.cmml"><mi id="S4.SS0.SSS0.Px4.p1.7.m7.1.1.2" xref="S4.SS0.SSS0.Px4.p1.7.m7.1.1.2.cmml">y</mi><mo id="S4.SS0.SSS0.Px4.p1.7.m7.1.1.1" xref="S4.SS0.SSS0.Px4.p1.7.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.7.m7.1b"><apply id="S4.SS0.SSS0.Px4.p1.7.m7.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.7.m7.1.1"><ci id="S4.SS0.SSS0.Px4.p1.7.m7.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.7.m7.1.1.1">^</ci><ci id="S4.SS0.SSS0.Px4.p1.7.m7.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p1.7.m7.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.7.m7.1c">\hat{y}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.7.m7.1d">over^ start_ARG italic_y end_ARG</annotation></semantics></math> from the MLLM given input pair <math alttext="x=(t,I)" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.8.m8.2"><semantics id="S4.SS0.SSS0.Px4.p1.8.m8.2a"><mrow id="S4.SS0.SSS0.Px4.p1.8.m8.2.3" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3.cmml"><mi id="S4.SS0.SSS0.Px4.p1.8.m8.2.3.2" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3.2.cmml">x</mi><mo id="S4.SS0.SSS0.Px4.p1.8.m8.2.3.1" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3.1.cmml">=</mo><mrow id="S4.SS0.SSS0.Px4.p1.8.m8.2.3.3.2" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3.3.1.cmml"><mo id="S4.SS0.SSS0.Px4.p1.8.m8.2.3.3.2.1" stretchy="false" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3.3.1.cmml">(</mo><mi id="S4.SS0.SSS0.Px4.p1.8.m8.1.1" xref="S4.SS0.SSS0.Px4.p1.8.m8.1.1.cmml">t</mi><mo id="S4.SS0.SSS0.Px4.p1.8.m8.2.3.3.2.2" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3.3.1.cmml">,</mo><mi id="S4.SS0.SSS0.Px4.p1.8.m8.2.2" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.2.cmml">I</mi><mo id="S4.SS0.SSS0.Px4.p1.8.m8.2.3.3.2.3" stretchy="false" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.8.m8.2b"><apply id="S4.SS0.SSS0.Px4.p1.8.m8.2.3.cmml" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3"><eq id="S4.SS0.SSS0.Px4.p1.8.m8.2.3.1.cmml" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3.1"></eq><ci id="S4.SS0.SSS0.Px4.p1.8.m8.2.3.2.cmml" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3.2">𝑥</ci><interval closure="open" id="S4.SS0.SSS0.Px4.p1.8.m8.2.3.3.1.cmml" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.3.3.2"><ci id="S4.SS0.SSS0.Px4.p1.8.m8.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.8.m8.1.1">𝑡</ci><ci id="S4.SS0.SSS0.Px4.p1.8.m8.2.2.cmml" xref="S4.SS0.SSS0.Px4.p1.8.m8.2.2">𝐼</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.8.m8.2c">x=(t,I)</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.8.m8.2d">italic_x = ( italic_t , italic_I )</annotation></semantics></math>, following process in Section <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S3.SS0.SSS0.Px3" title="PRM-based inference with aggregation function. ‣ 3 Problem Setting and Preliminaries ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">3</span></a>. We then create a ground truth signal <math alttext="r(\hat{y},y)" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.9.m9.2"><semantics id="S4.SS0.SSS0.Px4.p1.9.m9.2a"><mrow id="S4.SS0.SSS0.Px4.p1.9.m9.2.3" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3.cmml"><mi id="S4.SS0.SSS0.Px4.p1.9.m9.2.3.2" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3.2.cmml">r</mi><mo id="S4.SS0.SSS0.Px4.p1.9.m9.2.3.1" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3.1.cmml">⁢</mo><mrow id="S4.SS0.SSS0.Px4.p1.9.m9.2.3.3.2" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3.3.1.cmml"><mo id="S4.SS0.SSS0.Px4.p1.9.m9.2.3.3.2.1" stretchy="false" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3.3.1.cmml">(</mo><mover accent="true" id="S4.SS0.SSS0.Px4.p1.9.m9.1.1" xref="S4.SS0.SSS0.Px4.p1.9.m9.1.1.cmml"><mi id="S4.SS0.SSS0.Px4.p1.9.m9.1.1.2" xref="S4.SS0.SSS0.Px4.p1.9.m9.1.1.2.cmml">y</mi><mo id="S4.SS0.SSS0.Px4.p1.9.m9.1.1.1" xref="S4.SS0.SSS0.Px4.p1.9.m9.1.1.1.cmml">^</mo></mover><mo id="S4.SS0.SSS0.Px4.p1.9.m9.2.3.3.2.2" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3.3.1.cmml">,</mo><mi id="S4.SS0.SSS0.Px4.p1.9.m9.2.2" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.2.cmml">y</mi><mo id="S4.SS0.SSS0.Px4.p1.9.m9.2.3.3.2.3" stretchy="false" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.9.m9.2b"><apply id="S4.SS0.SSS0.Px4.p1.9.m9.2.3.cmml" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3"><times id="S4.SS0.SSS0.Px4.p1.9.m9.2.3.1.cmml" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3.1"></times><ci id="S4.SS0.SSS0.Px4.p1.9.m9.2.3.2.cmml" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3.2">𝑟</ci><interval closure="open" id="S4.SS0.SSS0.Px4.p1.9.m9.2.3.3.1.cmml" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.3.3.2"><apply id="S4.SS0.SSS0.Px4.p1.9.m9.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.9.m9.1.1"><ci id="S4.SS0.SSS0.Px4.p1.9.m9.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.9.m9.1.1.1">^</ci><ci id="S4.SS0.SSS0.Px4.p1.9.m9.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p1.9.m9.1.1.2">𝑦</ci></apply><ci id="S4.SS0.SSS0.Px4.p1.9.m9.2.2.cmml" xref="S4.SS0.SSS0.Px4.p1.9.m9.2.2">𝑦</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.9.m9.2c">r(\hat{y},y)</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.9.m9.2d">italic_r ( over^ start_ARG italic_y end_ARG , italic_y )</annotation></semantics></math> by assigning it a value of 1 if the generated <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.10.m10.1"><semantics id="S4.SS0.SSS0.Px4.p1.10.m10.1a"><mover accent="true" id="S4.SS0.SSS0.Px4.p1.10.m10.1.1" xref="S4.SS0.SSS0.Px4.p1.10.m10.1.1.cmml"><mi id="S4.SS0.SSS0.Px4.p1.10.m10.1.1.2" xref="S4.SS0.SSS0.Px4.p1.10.m10.1.1.2.cmml">y</mi><mo id="S4.SS0.SSS0.Px4.p1.10.m10.1.1.1" xref="S4.SS0.SSS0.Px4.p1.10.m10.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.10.m10.1b"><apply id="S4.SS0.SSS0.Px4.p1.10.m10.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.10.m10.1.1"><ci id="S4.SS0.SSS0.Px4.p1.10.m10.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.10.m10.1.1.1">^</ci><ci id="S4.SS0.SSS0.Px4.p1.10.m10.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p1.10.m10.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.10.m10.1c">\hat{y}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.10.m10.1d">over^ start_ARG italic_y end_ARG</annotation></semantics></math> contains ground truth <math alttext="y" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p1.11.m11.1"><semantics id="S4.SS0.SSS0.Px4.p1.11.m11.1a"><mi id="S4.SS0.SSS0.Px4.p1.11.m11.1.1" xref="S4.SS0.SSS0.Px4.p1.11.m11.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p1.11.m11.1b"><ci id="S4.SS0.SSS0.Px4.p1.11.m11.1.1.cmml" xref="S4.SS0.SSS0.Px4.p1.11.m11.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p1.11.m11.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p1.11.m11.1d">italic_y</annotation></semantics></math>, and 0 otherwise. The meta loss is defined as the mean squared error between aggregated score and ground truth signal:</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p2">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A6.EGx5">
<tbody id="S4.E8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{meta}(\mathcal{D}_{meta},\phi^{*}(\alpha))=\sum_{(x,%
y)\in\mathcal{D}_{meta}}\mathcal{L}_{MSE}(\sigma(\mathcal{A}(\mathcal{V}_{\phi%
^{*}(\alpha)}(x,\hat{y}))),r(\hat{y},y))" class="ltx_Math" display="inline" id="S4.E8.m1.12"><semantics id="S4.E8.m1.12a"><mrow id="S4.E8.m1.12.12" xref="S4.E8.m1.12.12.cmml"><mrow id="S4.E8.m1.10.10.2" xref="S4.E8.m1.10.10.2.cmml"><msub id="S4.E8.m1.10.10.2.4" xref="S4.E8.m1.10.10.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E8.m1.10.10.2.4.2" xref="S4.E8.m1.10.10.2.4.2.cmml">ℒ</mi><mrow id="S4.E8.m1.10.10.2.4.3" xref="S4.E8.m1.10.10.2.4.3.cmml"><mi id="S4.E8.m1.10.10.2.4.3.2" xref="S4.E8.m1.10.10.2.4.3.2.cmml">m</mi><mo id="S4.E8.m1.10.10.2.4.3.1" xref="S4.E8.m1.10.10.2.4.3.1.cmml">⁢</mo><mi id="S4.E8.m1.10.10.2.4.3.3" xref="S4.E8.m1.10.10.2.4.3.3.cmml">e</mi><mo id="S4.E8.m1.10.10.2.4.3.1a" xref="S4.E8.m1.10.10.2.4.3.1.cmml">⁢</mo><mi id="S4.E8.m1.10.10.2.4.3.4" xref="S4.E8.m1.10.10.2.4.3.4.cmml">t</mi><mo id="S4.E8.m1.10.10.2.4.3.1b" xref="S4.E8.m1.10.10.2.4.3.1.cmml">⁢</mo><mi id="S4.E8.m1.10.10.2.4.3.5" xref="S4.E8.m1.10.10.2.4.3.5.cmml">a</mi></mrow></msub><mo id="S4.E8.m1.10.10.2.3" xref="S4.E8.m1.10.10.2.3.cmml">⁢</mo><mrow id="S4.E8.m1.10.10.2.2.2" xref="S4.E8.m1.10.10.2.2.3.cmml"><mo id="S4.E8.m1.10.10.2.2.2.3" stretchy="false" xref="S4.E8.m1.10.10.2.2.3.cmml">(</mo><msub id="S4.E8.m1.9.9.1.1.1.1" xref="S4.E8.m1.9.9.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E8.m1.9.9.1.1.1.1.2" xref="S4.E8.m1.9.9.1.1.1.1.2.cmml">𝒟</mi><mrow id="S4.E8.m1.9.9.1.1.1.1.3" xref="S4.E8.m1.9.9.1.1.1.1.3.cmml"><mi id="S4.E8.m1.9.9.1.1.1.1.3.2" xref="S4.E8.m1.9.9.1.1.1.1.3.2.cmml">m</mi><mo id="S4.E8.m1.9.9.1.1.1.1.3.1" xref="S4.E8.m1.9.9.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.E8.m1.9.9.1.1.1.1.3.3" xref="S4.E8.m1.9.9.1.1.1.1.3.3.cmml">e</mi><mo id="S4.E8.m1.9.9.1.1.1.1.3.1a" xref="S4.E8.m1.9.9.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.E8.m1.9.9.1.1.1.1.3.4" xref="S4.E8.m1.9.9.1.1.1.1.3.4.cmml">t</mi><mo id="S4.E8.m1.9.9.1.1.1.1.3.1b" xref="S4.E8.m1.9.9.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.E8.m1.9.9.1.1.1.1.3.5" xref="S4.E8.m1.9.9.1.1.1.1.3.5.cmml">a</mi></mrow></msub><mo id="S4.E8.m1.10.10.2.2.2.4" xref="S4.E8.m1.10.10.2.2.3.cmml">,</mo><mrow id="S4.E8.m1.10.10.2.2.2.2" xref="S4.E8.m1.10.10.2.2.2.2.cmml"><msup id="S4.E8.m1.10.10.2.2.2.2.2" xref="S4.E8.m1.10.10.2.2.2.2.2.cmml"><mi id="S4.E8.m1.10.10.2.2.2.2.2.2" xref="S4.E8.m1.10.10.2.2.2.2.2.2.cmml">ϕ</mi><mo id="S4.E8.m1.10.10.2.2.2.2.2.3" xref="S4.E8.m1.10.10.2.2.2.2.2.3.cmml">∗</mo></msup><mo id="S4.E8.m1.10.10.2.2.2.2.1" xref="S4.E8.m1.10.10.2.2.2.2.1.cmml">⁢</mo><mrow id="S4.E8.m1.10.10.2.2.2.2.3.2" xref="S4.E8.m1.10.10.2.2.2.2.cmml"><mo id="S4.E8.m1.10.10.2.2.2.2.3.2.1" stretchy="false" xref="S4.E8.m1.10.10.2.2.2.2.cmml">(</mo><mi id="S4.E8.m1.4.4" xref="S4.E8.m1.4.4.cmml">α</mi><mo id="S4.E8.m1.10.10.2.2.2.2.3.2.2" stretchy="false" xref="S4.E8.m1.10.10.2.2.2.2.cmml">)</mo></mrow></mrow><mo id="S4.E8.m1.10.10.2.2.2.5" stretchy="false" xref="S4.E8.m1.10.10.2.2.3.cmml">)</mo></mrow></mrow><mo id="S4.E8.m1.12.12.5" xref="S4.E8.m1.12.12.5.cmml">=</mo><mrow id="S4.E8.m1.12.12.4" xref="S4.E8.m1.12.12.4.cmml"><mstyle displaystyle="true" id="S4.E8.m1.12.12.4.3" xref="S4.E8.m1.12.12.4.3.cmml"><munder id="S4.E8.m1.12.12.4.3a" xref="S4.E8.m1.12.12.4.3.cmml"><mo id="S4.E8.m1.12.12.4.3.2" movablelimits="false" xref="S4.E8.m1.12.12.4.3.2.cmml">∑</mo><mrow id="S4.E8.m1.2.2.2" xref="S4.E8.m1.2.2.2.cmml"><mrow id="S4.E8.m1.2.2.2.4.2" xref="S4.E8.m1.2.2.2.4.1.cmml"><mo id="S4.E8.m1.2.2.2.4.2.1" stretchy="false" xref="S4.E8.m1.2.2.2.4.1.cmml">(</mo><mi id="S4.E8.m1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.cmml">x</mi><mo id="S4.E8.m1.2.2.2.4.2.2" xref="S4.E8.m1.2.2.2.4.1.cmml">,</mo><mi id="S4.E8.m1.2.2.2.2" xref="S4.E8.m1.2.2.2.2.cmml">y</mi><mo id="S4.E8.m1.2.2.2.4.2.3" stretchy="false" xref="S4.E8.m1.2.2.2.4.1.cmml">)</mo></mrow><mo id="S4.E8.m1.2.2.2.3" xref="S4.E8.m1.2.2.2.3.cmml">∈</mo><msub id="S4.E8.m1.2.2.2.5" xref="S4.E8.m1.2.2.2.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E8.m1.2.2.2.5.2" xref="S4.E8.m1.2.2.2.5.2.cmml">𝒟</mi><mrow id="S4.E8.m1.2.2.2.5.3" xref="S4.E8.m1.2.2.2.5.3.cmml"><mi id="S4.E8.m1.2.2.2.5.3.2" xref="S4.E8.m1.2.2.2.5.3.2.cmml">m</mi><mo id="S4.E8.m1.2.2.2.5.3.1" xref="S4.E8.m1.2.2.2.5.3.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.2.5.3.3" xref="S4.E8.m1.2.2.2.5.3.3.cmml">e</mi><mo id="S4.E8.m1.2.2.2.5.3.1a" xref="S4.E8.m1.2.2.2.5.3.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.2.5.3.4" xref="S4.E8.m1.2.2.2.5.3.4.cmml">t</mi><mo id="S4.E8.m1.2.2.2.5.3.1b" xref="S4.E8.m1.2.2.2.5.3.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.2.5.3.5" xref="S4.E8.m1.2.2.2.5.3.5.cmml">a</mi></mrow></msub></mrow></munder></mstyle><mrow id="S4.E8.m1.12.12.4.2" xref="S4.E8.m1.12.12.4.2.cmml"><msub id="S4.E8.m1.12.12.4.2.4" xref="S4.E8.m1.12.12.4.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E8.m1.12.12.4.2.4.2" xref="S4.E8.m1.12.12.4.2.4.2.cmml">ℒ</mi><mrow id="S4.E8.m1.12.12.4.2.4.3" xref="S4.E8.m1.12.12.4.2.4.3.cmml"><mi id="S4.E8.m1.12.12.4.2.4.3.2" xref="S4.E8.m1.12.12.4.2.4.3.2.cmml">M</mi><mo id="S4.E8.m1.12.12.4.2.4.3.1" xref="S4.E8.m1.12.12.4.2.4.3.1.cmml">⁢</mo><mi id="S4.E8.m1.12.12.4.2.4.3.3" xref="S4.E8.m1.12.12.4.2.4.3.3.cmml">S</mi><mo id="S4.E8.m1.12.12.4.2.4.3.1a" xref="S4.E8.m1.12.12.4.2.4.3.1.cmml">⁢</mo><mi id="S4.E8.m1.12.12.4.2.4.3.4" xref="S4.E8.m1.12.12.4.2.4.3.4.cmml">E</mi></mrow></msub><mo id="S4.E8.m1.12.12.4.2.3" xref="S4.E8.m1.12.12.4.2.3.cmml">⁢</mo><mrow id="S4.E8.m1.12.12.4.2.2.2" xref="S4.E8.m1.12.12.4.2.2.3.cmml"><mo id="S4.E8.m1.12.12.4.2.2.2.3" stretchy="false" xref="S4.E8.m1.12.12.4.2.2.3.cmml">(</mo><mrow id="S4.E8.m1.11.11.3.1.1.1.1" xref="S4.E8.m1.11.11.3.1.1.1.1.cmml"><mi id="S4.E8.m1.11.11.3.1.1.1.1.3" xref="S4.E8.m1.11.11.3.1.1.1.1.3.cmml">σ</mi><mo id="S4.E8.m1.11.11.3.1.1.1.1.2" xref="S4.E8.m1.11.11.3.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E8.m1.11.11.3.1.1.1.1.1.1" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.cmml"><mo id="S4.E8.m1.11.11.3.1.1.1.1.1.1.2" stretchy="false" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.3" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.3.cmml">𝒜</mi><mo id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.2" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.2.2.cmml">𝒱</mi><mrow id="S4.E8.m1.3.3.1" xref="S4.E8.m1.3.3.1.cmml"><msup id="S4.E8.m1.3.3.1.3" xref="S4.E8.m1.3.3.1.3.cmml"><mi id="S4.E8.m1.3.3.1.3.2" xref="S4.E8.m1.3.3.1.3.2.cmml">ϕ</mi><mo id="S4.E8.m1.3.3.1.3.3" xref="S4.E8.m1.3.3.1.3.3.cmml">∗</mo></msup><mo id="S4.E8.m1.3.3.1.2" xref="S4.E8.m1.3.3.1.2.cmml">⁢</mo><mrow id="S4.E8.m1.3.3.1.4.2" xref="S4.E8.m1.3.3.1.cmml"><mo id="S4.E8.m1.3.3.1.4.2.1" stretchy="false" xref="S4.E8.m1.3.3.1.cmml">(</mo><mi id="S4.E8.m1.3.3.1.1" xref="S4.E8.m1.3.3.1.1.cmml">α</mi><mo id="S4.E8.m1.3.3.1.4.2.2" stretchy="false" xref="S4.E8.m1.3.3.1.cmml">)</mo></mrow></mrow></msub><mo id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml"><mo id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml">(</mo><mi id="S4.E8.m1.5.5" xref="S4.E8.m1.5.5.cmml">x</mi><mo id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml">,</mo><mover accent="true" id="S4.E8.m1.6.6" xref="S4.E8.m1.6.6.cmml"><mi id="S4.E8.m1.6.6.2" xref="S4.E8.m1.6.6.2.cmml">y</mi><mo id="S4.E8.m1.6.6.1" xref="S4.E8.m1.6.6.1.cmml">^</mo></mover><mo id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.3.2.3" stretchy="false" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E8.m1.11.11.3.1.1.1.1.1.1.3" stretchy="false" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E8.m1.12.12.4.2.2.2.4" xref="S4.E8.m1.12.12.4.2.2.3.cmml">,</mo><mrow id="S4.E8.m1.12.12.4.2.2.2.2" xref="S4.E8.m1.12.12.4.2.2.2.2.cmml"><mi id="S4.E8.m1.12.12.4.2.2.2.2.2" xref="S4.E8.m1.12.12.4.2.2.2.2.2.cmml">r</mi><mo id="S4.E8.m1.12.12.4.2.2.2.2.1" xref="S4.E8.m1.12.12.4.2.2.2.2.1.cmml">⁢</mo><mrow id="S4.E8.m1.12.12.4.2.2.2.2.3.2" xref="S4.E8.m1.12.12.4.2.2.2.2.3.1.cmml"><mo id="S4.E8.m1.12.12.4.2.2.2.2.3.2.1" stretchy="false" xref="S4.E8.m1.12.12.4.2.2.2.2.3.1.cmml">(</mo><mover accent="true" id="S4.E8.m1.7.7" xref="S4.E8.m1.7.7.cmml"><mi id="S4.E8.m1.7.7.2" xref="S4.E8.m1.7.7.2.cmml">y</mi><mo id="S4.E8.m1.7.7.1" xref="S4.E8.m1.7.7.1.cmml">^</mo></mover><mo id="S4.E8.m1.12.12.4.2.2.2.2.3.2.2" xref="S4.E8.m1.12.12.4.2.2.2.2.3.1.cmml">,</mo><mi id="S4.E8.m1.8.8" xref="S4.E8.m1.8.8.cmml">y</mi><mo id="S4.E8.m1.12.12.4.2.2.2.2.3.2.3" stretchy="false" xref="S4.E8.m1.12.12.4.2.2.2.2.3.1.cmml">)</mo></mrow></mrow><mo id="S4.E8.m1.12.12.4.2.2.2.5" stretchy="false" xref="S4.E8.m1.12.12.4.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E8.m1.12b"><apply id="S4.E8.m1.12.12.cmml" xref="S4.E8.m1.12.12"><eq id="S4.E8.m1.12.12.5.cmml" xref="S4.E8.m1.12.12.5"></eq><apply id="S4.E8.m1.10.10.2.cmml" xref="S4.E8.m1.10.10.2"><times id="S4.E8.m1.10.10.2.3.cmml" xref="S4.E8.m1.10.10.2.3"></times><apply id="S4.E8.m1.10.10.2.4.cmml" xref="S4.E8.m1.10.10.2.4"><csymbol cd="ambiguous" id="S4.E8.m1.10.10.2.4.1.cmml" xref="S4.E8.m1.10.10.2.4">subscript</csymbol><ci id="S4.E8.m1.10.10.2.4.2.cmml" xref="S4.E8.m1.10.10.2.4.2">ℒ</ci><apply id="S4.E8.m1.10.10.2.4.3.cmml" xref="S4.E8.m1.10.10.2.4.3"><times id="S4.E8.m1.10.10.2.4.3.1.cmml" xref="S4.E8.m1.10.10.2.4.3.1"></times><ci id="S4.E8.m1.10.10.2.4.3.2.cmml" xref="S4.E8.m1.10.10.2.4.3.2">𝑚</ci><ci id="S4.E8.m1.10.10.2.4.3.3.cmml" xref="S4.E8.m1.10.10.2.4.3.3">𝑒</ci><ci id="S4.E8.m1.10.10.2.4.3.4.cmml" xref="S4.E8.m1.10.10.2.4.3.4">𝑡</ci><ci id="S4.E8.m1.10.10.2.4.3.5.cmml" xref="S4.E8.m1.10.10.2.4.3.5">𝑎</ci></apply></apply><interval closure="open" id="S4.E8.m1.10.10.2.2.3.cmml" xref="S4.E8.m1.10.10.2.2.2"><apply id="S4.E8.m1.9.9.1.1.1.1.cmml" xref="S4.E8.m1.9.9.1.1.1.1"><csymbol cd="ambiguous" id="S4.E8.m1.9.9.1.1.1.1.1.cmml" xref="S4.E8.m1.9.9.1.1.1.1">subscript</csymbol><ci id="S4.E8.m1.9.9.1.1.1.1.2.cmml" xref="S4.E8.m1.9.9.1.1.1.1.2">𝒟</ci><apply id="S4.E8.m1.9.9.1.1.1.1.3.cmml" xref="S4.E8.m1.9.9.1.1.1.1.3"><times id="S4.E8.m1.9.9.1.1.1.1.3.1.cmml" xref="S4.E8.m1.9.9.1.1.1.1.3.1"></times><ci id="S4.E8.m1.9.9.1.1.1.1.3.2.cmml" xref="S4.E8.m1.9.9.1.1.1.1.3.2">𝑚</ci><ci id="S4.E8.m1.9.9.1.1.1.1.3.3.cmml" xref="S4.E8.m1.9.9.1.1.1.1.3.3">𝑒</ci><ci id="S4.E8.m1.9.9.1.1.1.1.3.4.cmml" xref="S4.E8.m1.9.9.1.1.1.1.3.4">𝑡</ci><ci id="S4.E8.m1.9.9.1.1.1.1.3.5.cmml" xref="S4.E8.m1.9.9.1.1.1.1.3.5">𝑎</ci></apply></apply><apply id="S4.E8.m1.10.10.2.2.2.2.cmml" xref="S4.E8.m1.10.10.2.2.2.2"><times id="S4.E8.m1.10.10.2.2.2.2.1.cmml" xref="S4.E8.m1.10.10.2.2.2.2.1"></times><apply id="S4.E8.m1.10.10.2.2.2.2.2.cmml" xref="S4.E8.m1.10.10.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E8.m1.10.10.2.2.2.2.2.1.cmml" xref="S4.E8.m1.10.10.2.2.2.2.2">superscript</csymbol><ci id="S4.E8.m1.10.10.2.2.2.2.2.2.cmml" xref="S4.E8.m1.10.10.2.2.2.2.2.2">italic-ϕ</ci><times id="S4.E8.m1.10.10.2.2.2.2.2.3.cmml" xref="S4.E8.m1.10.10.2.2.2.2.2.3"></times></apply><ci id="S4.E8.m1.4.4.cmml" xref="S4.E8.m1.4.4">𝛼</ci></apply></interval></apply><apply id="S4.E8.m1.12.12.4.cmml" xref="S4.E8.m1.12.12.4"><apply id="S4.E8.m1.12.12.4.3.cmml" xref="S4.E8.m1.12.12.4.3"><csymbol cd="ambiguous" id="S4.E8.m1.12.12.4.3.1.cmml" xref="S4.E8.m1.12.12.4.3">subscript</csymbol><sum id="S4.E8.m1.12.12.4.3.2.cmml" xref="S4.E8.m1.12.12.4.3.2"></sum><apply id="S4.E8.m1.2.2.2.cmml" xref="S4.E8.m1.2.2.2"><in id="S4.E8.m1.2.2.2.3.cmml" xref="S4.E8.m1.2.2.2.3"></in><interval closure="open" id="S4.E8.m1.2.2.2.4.1.cmml" xref="S4.E8.m1.2.2.2.4.2"><ci id="S4.E8.m1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1">𝑥</ci><ci id="S4.E8.m1.2.2.2.2.cmml" xref="S4.E8.m1.2.2.2.2">𝑦</ci></interval><apply id="S4.E8.m1.2.2.2.5.cmml" xref="S4.E8.m1.2.2.2.5"><csymbol cd="ambiguous" id="S4.E8.m1.2.2.2.5.1.cmml" xref="S4.E8.m1.2.2.2.5">subscript</csymbol><ci id="S4.E8.m1.2.2.2.5.2.cmml" xref="S4.E8.m1.2.2.2.5.2">𝒟</ci><apply id="S4.E8.m1.2.2.2.5.3.cmml" xref="S4.E8.m1.2.2.2.5.3"><times id="S4.E8.m1.2.2.2.5.3.1.cmml" xref="S4.E8.m1.2.2.2.5.3.1"></times><ci id="S4.E8.m1.2.2.2.5.3.2.cmml" xref="S4.E8.m1.2.2.2.5.3.2">𝑚</ci><ci id="S4.E8.m1.2.2.2.5.3.3.cmml" xref="S4.E8.m1.2.2.2.5.3.3">𝑒</ci><ci id="S4.E8.m1.2.2.2.5.3.4.cmml" xref="S4.E8.m1.2.2.2.5.3.4">𝑡</ci><ci id="S4.E8.m1.2.2.2.5.3.5.cmml" xref="S4.E8.m1.2.2.2.5.3.5">𝑎</ci></apply></apply></apply></apply><apply id="S4.E8.m1.12.12.4.2.cmml" xref="S4.E8.m1.12.12.4.2"><times id="S4.E8.m1.12.12.4.2.3.cmml" xref="S4.E8.m1.12.12.4.2.3"></times><apply id="S4.E8.m1.12.12.4.2.4.cmml" xref="S4.E8.m1.12.12.4.2.4"><csymbol cd="ambiguous" id="S4.E8.m1.12.12.4.2.4.1.cmml" xref="S4.E8.m1.12.12.4.2.4">subscript</csymbol><ci id="S4.E8.m1.12.12.4.2.4.2.cmml" xref="S4.E8.m1.12.12.4.2.4.2">ℒ</ci><apply id="S4.E8.m1.12.12.4.2.4.3.cmml" xref="S4.E8.m1.12.12.4.2.4.3"><times id="S4.E8.m1.12.12.4.2.4.3.1.cmml" xref="S4.E8.m1.12.12.4.2.4.3.1"></times><ci id="S4.E8.m1.12.12.4.2.4.3.2.cmml" xref="S4.E8.m1.12.12.4.2.4.3.2">𝑀</ci><ci id="S4.E8.m1.12.12.4.2.4.3.3.cmml" xref="S4.E8.m1.12.12.4.2.4.3.3">𝑆</ci><ci id="S4.E8.m1.12.12.4.2.4.3.4.cmml" xref="S4.E8.m1.12.12.4.2.4.3.4">𝐸</ci></apply></apply><interval closure="open" id="S4.E8.m1.12.12.4.2.2.3.cmml" xref="S4.E8.m1.12.12.4.2.2.2"><apply id="S4.E8.m1.11.11.3.1.1.1.1.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1"><times id="S4.E8.m1.11.11.3.1.1.1.1.2.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.2"></times><ci id="S4.E8.m1.11.11.3.1.1.1.1.3.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.3">𝜎</ci><apply id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1"><times id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.2.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.2"></times><ci id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.3.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.3">𝒜</ci><apply id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1"><times id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.1"></times><apply id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.2.2">𝒱</ci><apply id="S4.E8.m1.3.3.1.cmml" xref="S4.E8.m1.3.3.1"><times id="S4.E8.m1.3.3.1.2.cmml" xref="S4.E8.m1.3.3.1.2"></times><apply id="S4.E8.m1.3.3.1.3.cmml" xref="S4.E8.m1.3.3.1.3"><csymbol cd="ambiguous" id="S4.E8.m1.3.3.1.3.1.cmml" xref="S4.E8.m1.3.3.1.3">superscript</csymbol><ci id="S4.E8.m1.3.3.1.3.2.cmml" xref="S4.E8.m1.3.3.1.3.2">italic-ϕ</ci><times id="S4.E8.m1.3.3.1.3.3.cmml" xref="S4.E8.m1.3.3.1.3.3"></times></apply><ci id="S4.E8.m1.3.3.1.1.cmml" xref="S4.E8.m1.3.3.1.1">𝛼</ci></apply></apply><interval closure="open" id="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E8.m1.11.11.3.1.1.1.1.1.1.1.1.1.1.3.2"><ci id="S4.E8.m1.5.5.cmml" xref="S4.E8.m1.5.5">𝑥</ci><apply id="S4.E8.m1.6.6.cmml" xref="S4.E8.m1.6.6"><ci id="S4.E8.m1.6.6.1.cmml" xref="S4.E8.m1.6.6.1">^</ci><ci id="S4.E8.m1.6.6.2.cmml" xref="S4.E8.m1.6.6.2">𝑦</ci></apply></interval></apply></apply></apply><apply id="S4.E8.m1.12.12.4.2.2.2.2.cmml" xref="S4.E8.m1.12.12.4.2.2.2.2"><times id="S4.E8.m1.12.12.4.2.2.2.2.1.cmml" xref="S4.E8.m1.12.12.4.2.2.2.2.1"></times><ci id="S4.E8.m1.12.12.4.2.2.2.2.2.cmml" xref="S4.E8.m1.12.12.4.2.2.2.2.2">𝑟</ci><interval closure="open" id="S4.E8.m1.12.12.4.2.2.2.2.3.1.cmml" xref="S4.E8.m1.12.12.4.2.2.2.2.3.2"><apply id="S4.E8.m1.7.7.cmml" xref="S4.E8.m1.7.7"><ci id="S4.E8.m1.7.7.1.cmml" xref="S4.E8.m1.7.7.1">^</ci><ci id="S4.E8.m1.7.7.2.cmml" xref="S4.E8.m1.7.7.2">𝑦</ci></apply><ci id="S4.E8.m1.8.8.cmml" xref="S4.E8.m1.8.8">𝑦</ci></interval></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E8.m1.12c">\displaystyle\mathcal{L}_{meta}(\mathcal{D}_{meta},\phi^{*}(\alpha))=\sum_{(x,%
y)\in\mathcal{D}_{meta}}\mathcal{L}_{MSE}(\sigma(\mathcal{A}(\mathcal{V}_{\phi%
^{*}(\alpha)}(x,\hat{y}))),r(\hat{y},y))</annotation><annotation encoding="application/x-llamapun" id="S4.E8.m1.12d">caligraphic_L start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT ( caligraphic_D start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT , italic_ϕ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_α ) ) = ∑ start_POSTSUBSCRIPT ( italic_x , italic_y ) ∈ caligraphic_D start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_M italic_S italic_E end_POSTSUBSCRIPT ( italic_σ ( caligraphic_A ( caligraphic_V start_POSTSUBSCRIPT italic_ϕ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_α ) end_POSTSUBSCRIPT ( italic_x , over^ start_ARG italic_y end_ARG ) ) ) , italic_r ( over^ start_ARG italic_y end_ARG , italic_y ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p3">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p3.2">where <math alttext="\mathcal{A}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p3.1.m1.1"><semantics id="S4.SS0.SSS0.Px4.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p3.1.m1.1.1" xref="S4.SS0.SSS0.Px4.p3.1.m1.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p3.1.m1.1b"><ci id="S4.SS0.SSS0.Px4.p3.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p3.1.m1.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p3.1.m1.1c">\mathcal{A}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p3.1.m1.1d">caligraphic_A</annotation></semantics></math> represents the aggregation function as previously defined in Equation <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S3.E2" title="In PRM-based inference with aggregation function. ‣ 3 Problem Setting and Preliminaries ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">2</span></a>, and <math alttext="\sigma" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px4.p3.2.m2.1"><semantics id="S4.SS0.SSS0.Px4.p3.2.m2.1a"><mi id="S4.SS0.SSS0.Px4.p3.2.m2.1.1" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p3.2.m2.1b"><ci id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p3.2.m2.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px4.p3.2.m2.1d">italic_σ</annotation></semantics></math> denotes the sigmoid function to map the aggregated score to a probability. Accordingly, the optimization problem at the upper level is formulated as follows:</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p4">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A6.EGx6">
<tbody id="S4.E9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\underset{\alpha}{\min}\mathcal{L}_{meta}(\mathcal{D}_{meta},\phi%
^{*}(\alpha))" class="ltx_Math" display="inline" id="S4.E9.m1.3"><semantics id="S4.E9.m1.3a"><mrow id="S4.E9.m1.3.3" xref="S4.E9.m1.3.3.cmml"><munder accentunder="true" id="S4.E9.m1.3.3.4" xref="S4.E9.m1.3.3.4.cmml"><mi id="S4.E9.m1.3.3.4.2" xref="S4.E9.m1.3.3.4.2.cmml">min</mi><mo id="S4.E9.m1.3.3.4.1" xref="S4.E9.m1.3.3.4.1.cmml">𝛼</mo></munder><mo id="S4.E9.m1.3.3.3" lspace="0.167em" xref="S4.E9.m1.3.3.3.cmml">⁢</mo><msub id="S4.E9.m1.3.3.5" xref="S4.E9.m1.3.3.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E9.m1.3.3.5.2" xref="S4.E9.m1.3.3.5.2.cmml">ℒ</mi><mrow id="S4.E9.m1.3.3.5.3" xref="S4.E9.m1.3.3.5.3.cmml"><mi id="S4.E9.m1.3.3.5.3.2" xref="S4.E9.m1.3.3.5.3.2.cmml">m</mi><mo id="S4.E9.m1.3.3.5.3.1" xref="S4.E9.m1.3.3.5.3.1.cmml">⁢</mo><mi id="S4.E9.m1.3.3.5.3.3" xref="S4.E9.m1.3.3.5.3.3.cmml">e</mi><mo id="S4.E9.m1.3.3.5.3.1a" xref="S4.E9.m1.3.3.5.3.1.cmml">⁢</mo><mi id="S4.E9.m1.3.3.5.3.4" xref="S4.E9.m1.3.3.5.3.4.cmml">t</mi><mo id="S4.E9.m1.3.3.5.3.1b" xref="S4.E9.m1.3.3.5.3.1.cmml">⁢</mo><mi id="S4.E9.m1.3.3.5.3.5" xref="S4.E9.m1.3.3.5.3.5.cmml">a</mi></mrow></msub><mo id="S4.E9.m1.3.3.3a" xref="S4.E9.m1.3.3.3.cmml">⁢</mo><mrow id="S4.E9.m1.3.3.2.2" xref="S4.E9.m1.3.3.2.3.cmml"><mo id="S4.E9.m1.3.3.2.2.3" stretchy="false" xref="S4.E9.m1.3.3.2.3.cmml">(</mo><msub id="S4.E9.m1.2.2.1.1.1" xref="S4.E9.m1.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E9.m1.2.2.1.1.1.2" xref="S4.E9.m1.2.2.1.1.1.2.cmml">𝒟</mi><mrow id="S4.E9.m1.2.2.1.1.1.3" xref="S4.E9.m1.2.2.1.1.1.3.cmml"><mi id="S4.E9.m1.2.2.1.1.1.3.2" xref="S4.E9.m1.2.2.1.1.1.3.2.cmml">m</mi><mo id="S4.E9.m1.2.2.1.1.1.3.1" xref="S4.E9.m1.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S4.E9.m1.2.2.1.1.1.3.3" xref="S4.E9.m1.2.2.1.1.1.3.3.cmml">e</mi><mo id="S4.E9.m1.2.2.1.1.1.3.1a" xref="S4.E9.m1.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S4.E9.m1.2.2.1.1.1.3.4" xref="S4.E9.m1.2.2.1.1.1.3.4.cmml">t</mi><mo id="S4.E9.m1.2.2.1.1.1.3.1b" xref="S4.E9.m1.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S4.E9.m1.2.2.1.1.1.3.5" xref="S4.E9.m1.2.2.1.1.1.3.5.cmml">a</mi></mrow></msub><mo id="S4.E9.m1.3.3.2.2.4" xref="S4.E9.m1.3.3.2.3.cmml">,</mo><mrow id="S4.E9.m1.3.3.2.2.2" xref="S4.E9.m1.3.3.2.2.2.cmml"><msup id="S4.E9.m1.3.3.2.2.2.2" xref="S4.E9.m1.3.3.2.2.2.2.cmml"><mi id="S4.E9.m1.3.3.2.2.2.2.2" xref="S4.E9.m1.3.3.2.2.2.2.2.cmml">ϕ</mi><mo id="S4.E9.m1.3.3.2.2.2.2.3" xref="S4.E9.m1.3.3.2.2.2.2.3.cmml">∗</mo></msup><mo id="S4.E9.m1.3.3.2.2.2.1" xref="S4.E9.m1.3.3.2.2.2.1.cmml">⁢</mo><mrow id="S4.E9.m1.3.3.2.2.2.3.2" xref="S4.E9.m1.3.3.2.2.2.cmml"><mo id="S4.E9.m1.3.3.2.2.2.3.2.1" stretchy="false" xref="S4.E9.m1.3.3.2.2.2.cmml">(</mo><mi id="S4.E9.m1.1.1" xref="S4.E9.m1.1.1.cmml">α</mi><mo id="S4.E9.m1.3.3.2.2.2.3.2.2" stretchy="false" xref="S4.E9.m1.3.3.2.2.2.cmml">)</mo></mrow></mrow><mo id="S4.E9.m1.3.3.2.2.5" stretchy="false" xref="S4.E9.m1.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E9.m1.3b"><apply id="S4.E9.m1.3.3.cmml" xref="S4.E9.m1.3.3"><times id="S4.E9.m1.3.3.3.cmml" xref="S4.E9.m1.3.3.3"></times><apply id="S4.E9.m1.3.3.4.cmml" xref="S4.E9.m1.3.3.4"><ci id="S4.E9.m1.3.3.4.1.cmml" xref="S4.E9.m1.3.3.4.1">𝛼</ci><min id="S4.E9.m1.3.3.4.2.cmml" xref="S4.E9.m1.3.3.4.2"></min></apply><apply id="S4.E9.m1.3.3.5.cmml" xref="S4.E9.m1.3.3.5"><csymbol cd="ambiguous" id="S4.E9.m1.3.3.5.1.cmml" xref="S4.E9.m1.3.3.5">subscript</csymbol><ci id="S4.E9.m1.3.3.5.2.cmml" xref="S4.E9.m1.3.3.5.2">ℒ</ci><apply id="S4.E9.m1.3.3.5.3.cmml" xref="S4.E9.m1.3.3.5.3"><times id="S4.E9.m1.3.3.5.3.1.cmml" xref="S4.E9.m1.3.3.5.3.1"></times><ci id="S4.E9.m1.3.3.5.3.2.cmml" xref="S4.E9.m1.3.3.5.3.2">𝑚</ci><ci id="S4.E9.m1.3.3.5.3.3.cmml" xref="S4.E9.m1.3.3.5.3.3">𝑒</ci><ci id="S4.E9.m1.3.3.5.3.4.cmml" xref="S4.E9.m1.3.3.5.3.4">𝑡</ci><ci id="S4.E9.m1.3.3.5.3.5.cmml" xref="S4.E9.m1.3.3.5.3.5">𝑎</ci></apply></apply><interval closure="open" id="S4.E9.m1.3.3.2.3.cmml" xref="S4.E9.m1.3.3.2.2"><apply id="S4.E9.m1.2.2.1.1.1.cmml" xref="S4.E9.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.E9.m1.2.2.1.1.1.1.cmml" xref="S4.E9.m1.2.2.1.1.1">subscript</csymbol><ci id="S4.E9.m1.2.2.1.1.1.2.cmml" xref="S4.E9.m1.2.2.1.1.1.2">𝒟</ci><apply id="S4.E9.m1.2.2.1.1.1.3.cmml" xref="S4.E9.m1.2.2.1.1.1.3"><times id="S4.E9.m1.2.2.1.1.1.3.1.cmml" xref="S4.E9.m1.2.2.1.1.1.3.1"></times><ci id="S4.E9.m1.2.2.1.1.1.3.2.cmml" xref="S4.E9.m1.2.2.1.1.1.3.2">𝑚</ci><ci id="S4.E9.m1.2.2.1.1.1.3.3.cmml" xref="S4.E9.m1.2.2.1.1.1.3.3">𝑒</ci><ci id="S4.E9.m1.2.2.1.1.1.3.4.cmml" xref="S4.E9.m1.2.2.1.1.1.3.4">𝑡</ci><ci id="S4.E9.m1.2.2.1.1.1.3.5.cmml" xref="S4.E9.m1.2.2.1.1.1.3.5">𝑎</ci></apply></apply><apply id="S4.E9.m1.3.3.2.2.2.cmml" xref="S4.E9.m1.3.3.2.2.2"><times id="S4.E9.m1.3.3.2.2.2.1.cmml" xref="S4.E9.m1.3.3.2.2.2.1"></times><apply id="S4.E9.m1.3.3.2.2.2.2.cmml" xref="S4.E9.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S4.E9.m1.3.3.2.2.2.2.1.cmml" xref="S4.E9.m1.3.3.2.2.2.2">superscript</csymbol><ci id="S4.E9.m1.3.3.2.2.2.2.2.cmml" xref="S4.E9.m1.3.3.2.2.2.2.2">italic-ϕ</ci><times id="S4.E9.m1.3.3.2.2.2.2.3.cmml" xref="S4.E9.m1.3.3.2.2.2.2.3"></times></apply><ci id="S4.E9.m1.1.1.cmml" xref="S4.E9.m1.1.1">𝛼</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E9.m1.3c">\displaystyle\underset{\alpha}{\min}\mathcal{L}_{meta}(\mathcal{D}_{meta},\phi%
^{*}(\alpha))</annotation><annotation encoding="application/x-llamapun" id="S4.E9.m1.3d">underitalic_α start_ARG roman_min end_ARG caligraphic_L start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT ( caligraphic_D start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT , italic_ϕ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_α ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p5">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p5.1">To solve this optimization problem, we propose an efficient gradient-based algorithm, which is detailed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A2" title="Appendix B Optimization algorithm ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Results</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Datasets and benchmarks</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">For datasets used in lower-level optimization (<math alttext="\mathcal{D}_{tr}" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><msub id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p1.1.m1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.2.cmml">𝒟</mi><mrow id="S5.SS1.p1.1.m1.1.1.3" xref="S5.SS1.p1.1.m1.1.1.3.cmml"><mi id="S5.SS1.p1.1.m1.1.1.3.2" xref="S5.SS1.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="S5.SS1.p1.1.m1.1.1.3.1" xref="S5.SS1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p1.1.m1.1.1.3.3" xref="S5.SS1.p1.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.2">𝒟</ci><apply id="S5.SS1.p1.1.m1.1.1.3.cmml" xref="S5.SS1.p1.1.m1.1.1.3"><times id="S5.SS1.p1.1.m1.1.1.3.1.cmml" xref="S5.SS1.p1.1.m1.1.1.3.1"></times><ci id="S5.SS1.p1.1.m1.1.1.3.2.cmml" xref="S5.SS1.p1.1.m1.1.1.3.2">𝑡</ci><ci id="S5.SS1.p1.1.m1.1.1.3.3.cmml" xref="S5.SS1.p1.1.m1.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">\mathcal{D}_{tr}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT</annotation></semantics></math> in Section <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S4" title="4 The Proposed Domain-reweighting Method ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">4</span></a>), our study utilizes a diverse set of datasets spanning multiple domains to ensure comprehensive coverage of multimodal reasoning tasks. The selected 15 multimodal datasets cover 4 major categories, including science, chart, geometry and commonsense, with a wide range of task types (e.g., visual question answering, optical character recognition, spatial understanding). Details of these datasets are provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A3" title="Appendix C Dataset Details ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">For the dataset used in upper-level optimization (<math alttext="\mathcal{D}_{meta}" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.1"><semantics id="S5.SS1.p2.1.m1.1a"><msub id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">𝒟</mi><mrow id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml"><mi id="S5.SS1.p2.1.m1.1.1.3.2" xref="S5.SS1.p2.1.m1.1.1.3.2.cmml">m</mi><mo id="S5.SS1.p2.1.m1.1.1.3.1" xref="S5.SS1.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p2.1.m1.1.1.3.3" xref="S5.SS1.p2.1.m1.1.1.3.3.cmml">e</mi><mo id="S5.SS1.p2.1.m1.1.1.3.1a" xref="S5.SS1.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p2.1.m1.1.1.3.4" xref="S5.SS1.p2.1.m1.1.1.3.4.cmml">t</mi><mo id="S5.SS1.p2.1.m1.1.1.3.1b" xref="S5.SS1.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p2.1.m1.1.1.3.5" xref="S5.SS1.p2.1.m1.1.1.3.5.cmml">a</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">𝒟</ci><apply id="S5.SS1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3"><times id="S5.SS1.p2.1.m1.1.1.3.1.cmml" xref="S5.SS1.p2.1.m1.1.1.3.1"></times><ci id="S5.SS1.p2.1.m1.1.1.3.2.cmml" xref="S5.SS1.p2.1.m1.1.1.3.2">𝑚</ci><ci id="S5.SS1.p2.1.m1.1.1.3.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3.3">𝑒</ci><ci id="S5.SS1.p2.1.m1.1.1.3.4.cmml" xref="S5.SS1.p2.1.m1.1.1.3.4">𝑡</ci><ci id="S5.SS1.p2.1.m1.1.1.3.5.cmml" xref="S5.SS1.p2.1.m1.1.1.3.5">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">\mathcal{D}_{meta}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT</annotation></semantics></math> in Section <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S4" title="4 The Proposed Domain-reweighting Method ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">4</span></a>), we select data from <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p2.1.1">MMMU</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib70" title=""><span class="ltx_text" style="font-size:80%;">70</span></a>]</cite> to simulate a realistic and diverse reasoning scenario. <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p2.1.2">MMMU</span> focuses on advanced perception and reasoning with domain-specific knowledge. Its questions span 30 subjects and 183 subfields, comprising 30 highly heterogeneous image types, such as charts, diagrams, maps, tables, music sheets, and chemical structures.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">At evaluation time, we use five multimodal reasoning benchmarks for testing the capability of DreamPRM. <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p3.1.1">WeMath</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib42" title=""><span class="ltx_text" style="font-size:80%;">42</span></a>]</cite>, <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p3.1.2">MathVista</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib30" title=""><span class="ltx_text" style="font-size:80%;">30</span></a>]</cite>, and <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p3.1.3">MathVision</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib54" title=""><span class="ltx_text" style="font-size:80%;">54</span></a>]</cite> focus more on math-related reasoning tasks and logic and critical thinking, while <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p3.1.4">MMVet</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib69" title=""><span class="ltx_text" style="font-size:80%;">69</span></a>]</cite> and <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p3.1.5">MMStar</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib4" title=""><span class="ltx_text" style="font-size:80%;">4</span></a>]</cite> focus more on real-life tasks that require common knowledge and general reasoning abilities.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experimental settings</h3>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Multistage reasoning.</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">To elicit consistent steady reasoning responses from current MLLMs, we draw on the Llava-CoT approach <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib66" title=""><span class="ltx_text" style="font-size:80%;">66</span></a>]</cite>, which fosters structured thinking prior to answer generation. Specifically, we prompt MLLMs to follow five reasoning steps: <span class="ltx_text ltx_font_typewriter" id="S5.SS2.SSS0.Px1.p1.1.1">(1) Restate the question. (2) Gather evidence from the image. (3) Identify any background knowledge needed. (4) Reason with the current evidence. (5) Summarize and conclude with all the information.</span> We also explore zero-shot prompting settings in conjunction with structural reasoning, which can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A4" title="Appendix D Structural Thinking Prompt ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">D</span></a>. We use 8 different chain-of-thought reasoning trajectories for all test-time scaling methods, unless otherwise stated.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Base models.</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.1">For inference, we use InternVL-2.5-8B-MPO <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib58" title=""><span class="ltx_text" style="font-size:80%;">58</span></a>]</cite> as the base MLLM, which has undergone post-training to enhance its reasoning abilities and is well-suited for our experiment. For fine-tuning PRM, we adopt Qwen2-VL-2B-Instruct <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib57" title=""><span class="ltx_text" style="font-size:80%;">57</span></a>]</cite>. Qwen2-VL is a state-of-the-art multimodal model pretrained for general vision-language understanding tasks. This pretrained model serves as the initialization for our fine-tuning process.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Training hyperparameters.</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px3.p1.4">In the lower-level optimization, we perform 5 inner gradient steps per outer update (unroll steps = 5) using the AdamW <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib29" title=""><span class="ltx_text" style="font-size:80%;">29</span></a>]</cite> optimizer with learning rate set to <math alttext="5\times 10^{-7}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.1.m1.1"><semantics id="S5.SS2.SSS0.Px3.p1.1.m1.1a"><mrow id="S5.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.cmml"><mn id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.2" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml">5</mn><mo id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml">×</mo><msup id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml"><mn id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.2" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3.cmml"><mo id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3a" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3.2" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3.2.cmml">7</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1"><times id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.1"></times><cn id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml" type="integer" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.2">5</cn><apply id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3">superscript</csymbol><cn id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.2.cmml" type="integer" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.2">10</cn><apply id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3"><minus id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3.1.cmml" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3"></minus><cn id="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3.2.cmml" type="integer" xref="S5.SS2.SSS0.Px3.p1.1.m1.1.1.3.3.2">7</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px3.p1.1.m1.1c">5\times 10^{-7}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px3.p1.1.m1.1d">5 × 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT</annotation></semantics></math>.
In the upper-level optimization, we use the AdamW optimizer (<math alttext="\mathrm{lr}=0.01" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.2.m2.1"><semantics id="S5.SS2.SSS0.Px3.p1.2.m2.1a"><mrow id="S5.SS2.SSS0.Px3.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.cmml"><mi id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.2" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml">lr</mi><mo id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.1" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px3.p1.2.m2.1b"><apply id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1"><eq id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.1"></eq><ci id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.2">lr</ci><cn id="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml" type="float" xref="S5.SS2.SSS0.Px3.p1.2.m2.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px3.p1.2.m2.1c">\mathrm{lr}=0.01</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px3.p1.2.m2.1d">roman_lr = 0.01</annotation></semantics></math>, weight decay <math alttext="=10^{-3}" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.3.m3.1"><semantics id="S5.SS2.SSS0.Px3.p1.3.m3.1a"><mrow id="S5.SS2.SSS0.Px3.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.cmml"><mi id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.2" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.2.cmml"></mi><mo id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.1" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.1.cmml">=</mo><msup id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.cmml"><mn id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.2" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.2.cmml">10</mn><mrow id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.cmml"><mo id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3a" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.cmml">−</mo><mn id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.2" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px3.p1.3.m3.1b"><apply id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1"><eq id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.1"></eq><csymbol cd="latexml" id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.2">absent</csymbol><apply id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3">superscript</csymbol><cn id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.2.cmml" type="integer" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.2">10</cn><apply id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3"><minus id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.1.cmml" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3"></minus><cn id="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.2.cmml" type="integer" xref="S5.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px3.p1.3.m3.1c">=10^{-3}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px3.p1.3.m3.1d">= 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math>) and a StepLR scheduler (step size = 5000, <math alttext="\gamma=0.5" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px3.p1.4.m4.1"><semantics id="S5.SS2.SSS0.Px3.p1.4.m4.1a"><mrow id="S5.SS2.SSS0.Px3.p1.4.m4.1.1" xref="S5.SS2.SSS0.Px3.p1.4.m4.1.1.cmml"><mi id="S5.SS2.SSS0.Px3.p1.4.m4.1.1.2" xref="S5.SS2.SSS0.Px3.p1.4.m4.1.1.2.cmml">γ</mi><mo id="S5.SS2.SSS0.Px3.p1.4.m4.1.1.1" xref="S5.SS2.SSS0.Px3.p1.4.m4.1.1.1.cmml">=</mo><mn id="S5.SS2.SSS0.Px3.p1.4.m4.1.1.3" xref="S5.SS2.SSS0.Px3.p1.4.m4.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px3.p1.4.m4.1b"><apply id="S5.SS2.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.4.m4.1.1"><eq id="S5.SS2.SSS0.Px3.p1.4.m4.1.1.1.cmml" xref="S5.SS2.SSS0.Px3.p1.4.m4.1.1.1"></eq><ci id="S5.SS2.SSS0.Px3.p1.4.m4.1.1.2.cmml" xref="S5.SS2.SSS0.Px3.p1.4.m4.1.1.2">𝛾</ci><cn id="S5.SS2.SSS0.Px3.p1.4.m4.1.1.3.cmml" type="float" xref="S5.SS2.SSS0.Px3.p1.4.m4.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px3.p1.4.m4.1c">\gamma=0.5</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px3.p1.4.m4.1d">italic_γ = 0.5</annotation></semantics></math>). In total, DreamPRM is fine-tuned for 10000 iterations. Our method is implemented with Betty <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib6" title=""><span class="ltx_text" style="font-size:80%;">6</span></a>]</cite>, and the fine-tuning process takes approximately 10 hours on two NVIDIA A100 GPUs.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Baselines.</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px4.p1.1">We use three major categories of baselines: <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS0.Px4.p1.1.1">(1)</span> State-of-the-art models on public leaderboards, including Gemini-1.5-Pro <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">44</span></a>]</cite>, GPT-4V <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib40" title=""><span class="ltx_text" style="font-size:80%;">40</span></a>]</cite>, LLaVA-OneVision-7B <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib23" title=""><span class="ltx_text" style="font-size:80%;">23</span></a>]</cite>, Qwen2-VL-7B <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib57" title=""><span class="ltx_text" style="font-size:80%;">57</span></a>]</cite>. We also carefully reproduce the results of InternVL-2.5-8B-MPO with structural thinking. <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS0.Px4.p1.1.2">(2)</span> Test-time scaling methods (excluding PRM) based on the InternVL-2.5-8B-MPO model, including: (i) Self-consistency <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib59" title=""><span class="ltx_text" style="font-size:80%;">59</span></a>]</cite>, which selects the most consistent reasoning chain via majority voting over multiple responses; (ii) Self-correction <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib16" title=""><span class="ltx_text" style="font-size:80%;">16</span></a>]</cite>, which prompts the model to critically reflect on and revise its initial answers; and (iii) Outcome Reward Model (ORM) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib46" title=""><span class="ltx_text" style="font-size:80%;">46</span></a>]</cite>, which evaluates and scores the final response to select the most promising one. <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS0.Px4.p1.1.3">(3)</span> PRM-based methods, including: (i) Vanilla PRM trained without any data selection, as commonly used in LLM settings <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib26" title=""><span class="ltx_text" style="font-size:80%;">26</span></a>]</cite>; (ii) s1-PRM, which selects high-quality reasoning responses based on three criteria - difficulty, quality, and diversity - following the s1 strategy <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib38" title=""><span class="ltx_text" style="font-size:80%;">38</span></a>]</cite>; and (iii) CaR-PRM, which filters high-quality visual questions using clustering and ranking techniques, as proposed in CaR <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib15" title=""><span class="ltx_text" style="font-size:80%;">15</span></a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Benchmark evaluation of DreamPRM</h3>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T1.10.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text ltx_font_bold" id="S5.T1.11.2" style="font-size:90%;">Comparative evaluation of DreamPRM and baselines on multimodal reasoning benchmarks.<span class="ltx_text ltx_font_medium" id="S5.T1.11.2.1">
</span>Bold numbers<span class="ltx_text ltx_font_medium" id="S5.T1.11.2.2"> indicate the best performance, while <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.11.2.2.1">underlined numbers</span> indicate the second best.
The table reports accuracy (%) on five datasets: <span class="ltx_text ltx_font_smallcaps" id="S5.T1.11.2.2.2">WeMath</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.T1.11.2.2.3">MathVista</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.T1.11.2.2.4">MathVision</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.T1.11.2.2.5">MMVet</span>, and <span class="ltx_text ltx_font_smallcaps" id="S5.T1.11.2.2.6">MMStar</span>.</span></span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.12" style="width:433.6pt;height:212.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-94.8pt,46.6pt) scale(0.695711585462466,0.695711585462466) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T1.12.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.12.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T1.12.1.1.1.1" style="padding-top:1pt;padding-bottom:1pt;"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T1.12.1.1.1.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.12.1.1.1.2.1">Math Reasoning</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T1.12.1.1.1.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.12.1.1.1.3.1">General Reasoning</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T1.12.1.2.2.1" style="padding-top:1pt;padding-bottom:1pt;"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.2.2.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T1.12.1.2.2.2.1">WeMath</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.2.2.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T1.12.1.2.2.3.1">MathVista</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.2.2.4" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T1.12.1.2.2.4.1">MathVision</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.2.2.5" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T1.12.1.2.2.5.1">MMVet</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.2.2.6" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T1.12.1.2.2.6.1">MMStar</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.3.3">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T1.12.1.3.3.1" style="padding-top:1pt;padding-bottom:1pt;"></th>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.3.3.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_italic" id="S5.T1.12.1.3.3.2.1">(loose)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.3.3.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_italic" id="S5.T1.12.1.3.3.3.1">(testmini)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.3.3.4" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_italic" id="S5.T1.12.1.3.3.4.1">(test)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.3.3.5" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_italic" id="S5.T1.12.1.3.3.5.1">(v1)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.3.3.6" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_italic" id="S5.T1.12.1.3.3.6.1">(test)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S5.T1.12.1.4.4.1" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_italic" id="S5.T1.12.1.4.4.1.1">Zero-shot Methods</span></th>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.12.1.5.5.1" style="padding-top:1pt;padding-bottom:1pt;">Gemini-1.5-Pro <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">44</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.5.5.2" style="padding-top:1pt;padding-bottom:1pt;">46.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.5.5.3" style="padding-top:1pt;padding-bottom:1pt;">63.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.5.5.4" style="padding-top:1pt;padding-bottom:1pt;">19.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.5.5.5" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.12.1.5.5.5.1">64.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.5.5.6" style="padding-top:1pt;padding-bottom:1pt;">59.1</td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.12.1.6.6.1" style="padding-top:1pt;padding-bottom:1pt;">GPT-4v <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib40" title=""><span class="ltx_text" style="font-size:80%;">40</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.6.6.2" style="padding-top:1pt;padding-bottom:1pt;">51.4</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.6.6.3" style="padding-top:1pt;padding-bottom:1pt;">49.9</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.6.6.4" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.12.1.6.6.4.1">21.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.6.6.5" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.12.1.6.6.5.1">67.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.6.6.6" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.12.1.6.6.6.1">62.0</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.12.1.7.7.1" style="padding-top:1pt;padding-bottom:1pt;">LLaVA-OneVision-7B <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib23" title=""><span class="ltx_text" style="font-size:80%;">23</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.7.7.2" style="padding-top:1pt;padding-bottom:1pt;">44.8</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.7.7.3" style="padding-top:1pt;padding-bottom:1pt;">63.2</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.7.7.4" style="padding-top:1pt;padding-bottom:1pt;">18.4</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.7.7.5" style="padding-top:1pt;padding-bottom:1pt;">57.5</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.7.7.6" style="padding-top:1pt;padding-bottom:1pt;">61.7</td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.12.1.8.8.1" style="padding-top:1pt;padding-bottom:1pt;">Qwen2-VL-7B <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib57" title=""><span class="ltx_text" style="font-size:80%;">57</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.8.8.2" style="padding-top:1pt;padding-bottom:1pt;">42.9</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.8.8.3" style="padding-top:1pt;padding-bottom:1pt;">58.2</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.8.8.4" style="padding-top:1pt;padding-bottom:1pt;">16.3</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.8.8.5" style="padding-top:1pt;padding-bottom:1pt;">62.0</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.8.8.6" style="padding-top:1pt;padding-bottom:1pt;">60.7</td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.12.1.9.9.1" style="padding-top:1pt;padding-bottom:1pt;">InternVL-2.5-8B-MPO <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib58" title=""><span class="ltx_text" style="font-size:80%;">58</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.9.9.2" style="padding-top:1pt;padding-bottom:1pt;">51.7</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.9.9.3" style="padding-top:1pt;padding-bottom:1pt;">65.4</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.9.9.4" style="padding-top:1pt;padding-bottom:1pt;">20.4</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.9.9.5" style="padding-top:1pt;padding-bottom:1pt;">55.9</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.9.9.6" style="padding-top:1pt;padding-bottom:1pt;">58.9</td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.10.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S5.T1.12.1.10.10.1" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_italic" id="S5.T1.12.1.10.10.1.1">Test-time Scaling Methods (InternVL-2.5-8B-MPO based)</span></th>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.12.1.11.11.1" style="padding-top:1pt;padding-bottom:1pt;">Self-consistency <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib59" title=""><span class="ltx_text" style="font-size:80%;">59</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.11.11.2" style="padding-top:1pt;padding-bottom:1pt;">56.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.11.11.3" style="padding-top:1pt;padding-bottom:1pt;">67.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.11.11.4" style="padding-top:1pt;padding-bottom:1pt;">20.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.11.11.5" style="padding-top:1pt;padding-bottom:1pt;">57.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.11.11.6" style="padding-top:1pt;padding-bottom:1pt;">59.6</td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.12.1.12.12.1" style="padding-top:1pt;padding-bottom:1pt;">Self-correction <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib16" title=""><span class="ltx_text" style="font-size:80%;">16</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.12.12.2" style="padding-top:1pt;padding-bottom:1pt;">54.0</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.12.12.3" style="padding-top:1pt;padding-bottom:1pt;">63.8</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.12.12.4" style="padding-top:1pt;padding-bottom:1pt;">21.6</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.12.12.5" style="padding-top:1pt;padding-bottom:1pt;">54.9</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.12.12.6" style="padding-top:1pt;padding-bottom:1pt;">59.7</td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.12.1.13.13.1" style="padding-top:1pt;padding-bottom:1pt;">ORM <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib46" title=""><span class="ltx_text" style="font-size:80%;">46</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.13.13.2" style="padding-top:1pt;padding-bottom:1pt;">56.9</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.13.13.3" style="padding-top:1pt;padding-bottom:1pt;">65.3</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.13.13.4" style="padding-top:1pt;padding-bottom:1pt;">20.5</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.13.13.5" style="padding-top:1pt;padding-bottom:1pt;">55.9</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.13.13.6" style="padding-top:1pt;padding-bottom:1pt;">60.1</td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.12.1.14.14.1" style="padding-top:1pt;padding-bottom:1pt;">Vanilla PRM <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib26" title=""><span class="ltx_text" style="font-size:80%;">26</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.14.14.2" style="padding-top:1pt;padding-bottom:1pt;">54.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.14.14.3" style="padding-top:1pt;padding-bottom:1pt;">67.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.14.14.4" style="padding-top:1pt;padding-bottom:1pt;">20.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.14.14.5" style="padding-top:1pt;padding-bottom:1pt;">58.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.12.1.14.14.6" style="padding-top:1pt;padding-bottom:1pt;">60.8</td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.12.1.15.15.1" style="padding-top:1pt;padding-bottom:1pt;">CaR-PRM <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib15" title=""><span class="ltx_text" style="font-size:80%;">15</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.15.15.2" style="padding-top:1pt;padding-bottom:1pt;">54.7</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.15.15.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.12.1.15.15.3.1">67.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.15.15.4" style="padding-top:1pt;padding-bottom:1pt;">21.0</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.15.15.5" style="padding-top:1pt;padding-bottom:1pt;">60.6</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.15.15.6" style="padding-top:1pt;padding-bottom:1pt;">61.1</td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.12.1.16.16.1" style="padding-top:1pt;padding-bottom:1pt;">s1-PRM <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib38" title=""><span class="ltx_text" style="font-size:80%;">38</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.16.16.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.12.1.16.16.2.1">57.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.16.16.3" style="padding-top:1pt;padding-bottom:1pt;">65.8</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.16.16.4" style="padding-top:1pt;padding-bottom:1pt;">20.2</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.16.16.5" style="padding-top:1pt;padding-bottom:1pt;">60.1</td>
<td class="ltx_td ltx_align_center" id="S5.T1.12.1.16.16.6" style="padding-top:1pt;padding-bottom:1pt;">60.4</td>
</tr>
<tr class="ltx_tr" id="S5.T1.12.1.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T1.12.1.17.17.1" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.12.1.17.17.1.1">DreamPRM (ours)</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.12.1.17.17.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.12.1.17.17.2.1">57.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.12.1.17.17.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.12.1.17.17.3.1">68.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.12.1.17.17.4" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.12.1.17.17.4.1">22.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.12.1.17.17.5" style="padding-top:1pt;padding-bottom:1pt;">61.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.12.1.17.17.6" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.12.1.17.17.6.1">62.3</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">Tab. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.T1" title="Table 1 ‣ 5.3 Benchmark evaluation of DreamPRM ‣ 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">1</span></a> presents the primary experimental results. We observe that: <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.1">(1) DreamPRM outperforms other PRM-based methods</span>, highlighting the effectiveness of our domain reweighting strategy. Compared to the vanilla PRM trained without any data selection, DreamPRM achieves a consistent performance gain of 2%-3% across all five datasets, suggesting that effective data selection is crucial for training high-quality multimodal PRMs. Moreover, DreamPRM also outperforms s1-PRM and CaR-PRM, which rely on manually designed heuristic rules for data selection. These results indicate that selecting suitable reasoning datasets for PRM training is a complex task, and handcrafted rules are often suboptimal. In contrast, our automatic domain-reweighting approach enables the model to adaptively optimize its learning process, illustrating how data-driven optimization offers a scalable solution to dataset selection challenges. <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.2">(2) DreamPRM outperforms SOTA MLLMs with much fewer parameters</span>, highlighting the effectiveness of DreamPRM. For example, DreamPRM significantly surpasses two trillion-scale closed-source LLMs (GPT-4v and Gemini-1.5-Pro) on 4 out of 5 datasets. In addition, it consistently improves the performance of the base model, InternVL-2.5-8B-MPO, achieving an average gain of 4% on the five datasets. These results confirm that DreamPRM effectively yields a high-quality PRM, which is capable of enhancing multimodal reasoning across a wide range of benchmarks. <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.3">(3) DreamPRM outperforms other test-time scaling methods</span>, primarily because it enables the training of a high-quality PRM that conducts fine-grained, step-level evaluation. While most test-time scaling methods yield moderate improvements, DreamPRM leads to the most substantial gains, suggesting that the quality of the reward model is critical for effective test-time scaling. We further provide case studies in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A5" title="Appendix E Additional Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">E</span></a>, which intuitively illustrate how DreamPRM assigns higher scores to coherent and high-quality reasoning trajectories.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="315" id="S5.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.11.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text ltx_font_bold" id="S5.F4.12.2" style="font-size:90%;">Comparative evaluation of DreamPRM on multimodal reasoning benchmarks.<span class="ltx_text ltx_font_medium" id="S5.F4.12.2.1">
Radar charts report accuracy (%) on five datasets (<span class="ltx_text ltx_font_smallcaps" id="S5.F4.12.2.1.1">WeMath</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.F4.12.2.1.2">MathVista</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.F4.12.2.1.3">MathVision</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.F4.12.2.1.4">MMVet</span>, and <span class="ltx_text ltx_font_smallcaps" id="S5.F4.12.2.1.5">MMStar</span>).
</span>(a)<span class="ltx_text ltx_font_medium" id="S5.F4.12.2.2"> Impact of different data selection strategies.
</span>(b)<span class="ltx_text ltx_font_medium" id="S5.F4.12.2.3"> Comparison with existing test-time scaling methods.
</span>(c)<span class="ltx_text ltx_font_medium" id="S5.F4.12.2.4"> Ablation study of three key components, i.e. w/o aggregation function loss (AFL), w/o bi-level optimization (BLO), and w/o structural thinking (ST).</span></span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="905" id="S5.F5.1.g1" src="x5.png" width="830"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="553" id="S5.F5.2.g1" src="x6.png" width="830"/>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.14.2.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text ltx_font_bold" id="S5.F5.4.1" style="font-size:90%;">Scaling ability and cross-model generalization.<span class="ltx_text ltx_font_medium" id="S5.F5.4.1.2">
</span>(a)<span class="ltx_text ltx_font_medium" id="S5.F5.4.1.3"> Radar chart of five multimodal reasoning benchmarks shows that DreamPRM delivers monotonic accuracy gains as the number of selected chains-of-thought increases (<span class="ltx_text" id="S5.F5.4.1.3.1">@2</span>, <span class="ltx_text" id="S5.F5.4.1.3.2">@4</span>, <span class="ltx_text" id="S5.F5.4.1.3.3">@8</span>) over the pass@1 baseline.
</span>(b)<span class="ltx_text ltx_font_medium" id="S5.F5.4.1.1"> Best-of-<span class="ltx_text ltx_font_italic" id="S5.F5.4.1.1.1">N</span> accuracy curves for InternVL-2.5-8B-MPO (blue) and GPT-4.1-mini (red) on <span class="ltx_text ltx_font_smallcaps" id="S5.F5.4.1.1.2">MathVista</span> confirm that the same DreamPRM-ranked CoTs generalize across models, consistently outperforming pass@1 performance (dashed lines) as <math alttext="k" class="ltx_Math" display="inline" id="S5.F5.4.1.1.m1.1"><semantics id="S5.F5.4.1.1.m1.1b"><mi id="S5.F5.4.1.1.m1.1.1" xref="S5.F5.4.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.F5.4.1.1.m1.1c"><ci id="S5.F5.4.1.1.m1.1.1.cmml" xref="S5.F5.4.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.4.1.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S5.F5.4.1.1.m1.1e">italic_k</annotation></semantics></math> grows.</span></span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Scaling and generalization analysis of DreamPRM</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.2"><span class="ltx_text ltx_font_bold" id="S5.SS4.p1.2.1">DreamPRM scales reliably with more CoT candidates.</span> As shown in the left panel of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.F5" title="Figure 5 ‣ 5.3 Benchmark evaluation of DreamPRM ‣ 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">5</span></a>, the accuracy of DreamPRM consistently improves on all five benchmarks as the number of CoTs increases from <math alttext="k{=}2" class="ltx_Math" display="inline" id="S5.SS4.p1.1.m1.1"><semantics id="S5.SS4.p1.1.m1.1a"><mrow id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml"><mi id="S5.SS4.p1.1.m1.1.1.2" xref="S5.SS4.p1.1.m1.1.1.2.cmml">k</mi><mo id="S5.SS4.p1.1.m1.1.1.1" xref="S5.SS4.p1.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS4.p1.1.m1.1.1.3" xref="S5.SS4.p1.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><apply id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1"><eq id="S5.SS4.p1.1.m1.1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1.1"></eq><ci id="S5.SS4.p1.1.m1.1.1.2.cmml" xref="S5.SS4.p1.1.m1.1.1.2">𝑘</ci><cn id="S5.SS4.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS4.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">k{=}2</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.1.m1.1d">italic_k = 2</annotation></semantics></math> to <math alttext="k{=}8" class="ltx_Math" display="inline" id="S5.SS4.p1.2.m2.1"><semantics id="S5.SS4.p1.2.m2.1a"><mrow id="S5.SS4.p1.2.m2.1.1" xref="S5.SS4.p1.2.m2.1.1.cmml"><mi id="S5.SS4.p1.2.m2.1.1.2" xref="S5.SS4.p1.2.m2.1.1.2.cmml">k</mi><mo id="S5.SS4.p1.2.m2.1.1.1" xref="S5.SS4.p1.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS4.p1.2.m2.1.1.3" xref="S5.SS4.p1.2.m2.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.2.m2.1b"><apply id="S5.SS4.p1.2.m2.1.1.cmml" xref="S5.SS4.p1.2.m2.1.1"><eq id="S5.SS4.p1.2.m2.1.1.1.cmml" xref="S5.SS4.p1.2.m2.1.1.1"></eq><ci id="S5.SS4.p1.2.m2.1.1.2.cmml" xref="S5.SS4.p1.2.m2.1.1.2">𝑘</ci><cn id="S5.SS4.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS4.p1.2.m2.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.2.m2.1c">k{=}8</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.2.m2.1d">italic_k = 8</annotation></semantics></math>, expanding the radar plot outward. Intuitively, a larger set of candidates increases the likelihood of including high-quality reasoning trajectories, but it also makes identifying the best ones more challenging. The consistent performance gains indicate that DreamPRM effectively verifies and ranks CoTs, demonstrating its robustness in selecting high-quality reasoning trajectories under more complex candidate pools.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.2"><span class="ltx_text ltx_font_bold" id="S5.SS4.p2.2.1">DreamPRM transfers seamlessly to stronger base MLLMs.</span> The right panel of Fig.<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.F5" title="Figure 5 ‣ 5.3 Benchmark evaluation of DreamPRM ‣ 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">5</span></a> shows the <span class="ltx_text ltx_font_smallcaps" id="S5.SS4.p2.2.2">MathVista</span> accuracy when applying DreamPRM to a recent MLLM, GPT-4.1-mini <span class="ltx_text ltx_font_italic" id="S5.SS4.p2.2.3">(2025-04-14)</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib40" title=""><span class="ltx_text" style="font-size:80%;">40</span></a>]</cite>. The pass@1 score of 71.5% steadily increases to 74.4% at <math alttext="k{=}8" class="ltx_Math" display="inline" id="S5.SS4.p2.1.m1.1"><semantics id="S5.SS4.p2.1.m1.1a"><mrow id="S5.SS4.p2.1.m1.1.1" xref="S5.SS4.p2.1.m1.1.1.cmml"><mi id="S5.SS4.p2.1.m1.1.1.2" xref="S5.SS4.p2.1.m1.1.1.2.cmml">k</mi><mo id="S5.SS4.p2.1.m1.1.1.1" xref="S5.SS4.p2.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS4.p2.1.m1.1.1.3" xref="S5.SS4.p2.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.1.m1.1b"><apply id="S5.SS4.p2.1.m1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1"><eq id="S5.SS4.p2.1.m1.1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1.1"></eq><ci id="S5.SS4.p2.1.m1.1.1.2.cmml" xref="S5.SS4.p2.1.m1.1.1.2">𝑘</ci><cn id="S5.SS4.p2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS4.p2.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.1.m1.1c">k{=}8</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p2.1.m1.1d">italic_k = 8</annotation></semantics></math>, surpassing the previous state-of-the-art performance. This best-of-<math alttext="N" class="ltx_Math" display="inline" id="S5.SS4.p2.2.m2.1"><semantics id="S5.SS4.p2.2.m2.1a"><mi id="S5.SS4.p2.2.m2.1.1" xref="S5.SS4.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.2.m2.1b"><ci id="S5.SS4.p2.2.m2.1.1.cmml" xref="S5.SS4.p2.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p2.2.m2.1d">italic_N</annotation></semantics></math> trend, previously observed with InternVL, also holds for GPT-4.1-mini, demonstrating the generalization ability of DreamPRM. Full results of these experiments are provided in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A4.T3" title="Table 3 ‣ Appendix D Structural Thinking Prompt ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">3</span></a> in Appendix.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Ablation study</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">In this section, we investigate the importance of three components in DreamPRM: <span class="ltx_text ltx_font_bold" id="S5.SS5.p1.1.1">(1)</span> bi-level optimization, <span class="ltx_text ltx_font_bold" id="S5.SS5.p1.1.2">(2)</span> aggregation function loss in upper-level, and <span class="ltx_text ltx_font_bold" id="S5.SS5.p1.1.3">(3)</span> structural thinking prompt (detailed in Section <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.SS2" title="5.2 Experimental settings ‣ 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">5.2</span></a>). As shown in the rightmost panel of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.F4" title="Figure 4 ‣ 5.3 Benchmark evaluation of DreamPRM ‣ 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">4</span></a>, the complete DreamPRM achieves the best results compared to three ablation baselines across all five benchmarks. Eliminating bi-level optimization causes large performance drop (e.g., -3.5% on <span class="ltx_text ltx_font_smallcaps" id="S5.SS5.p1.1.4">MathVista</span> and -3.4% on <span class="ltx_text ltx_font_smallcaps" id="S5.SS5.p1.1.5">MMStar</span>). Removing aggregation function loss leads to a consistent 1%-2% decline (e.g., 57.4% <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS5.p1.1.m1.1"><semantics id="S5.SS5.p1.1.m1.1a"><mo id="S5.SS5.p1.1.m1.1.1" stretchy="false" xref="S5.SS5.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.1.m1.1b"><ci id="S5.SS5.p1.1.m1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.1.m1.1d">→</annotation></semantics></math> 56.3% on <span class="ltx_text ltx_font_smallcaps" id="S5.SS5.p1.1.6">WeMath</span>). Excluding structural thinking also degrades performance (e.g., -1.8% on <span class="ltx_text ltx_font_smallcaps" id="S5.SS5.p1.1.7">MathVision</span>). These results indicate that all three components are critical for DreamPRM to achieve the best performance. More detailed results are shown in Appendix Tab. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A4.T4" title="Table 4 ‣ Appendix D Structural Thinking Prompt ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Analysis of learned domain weights</h3>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="261" id="S5.F6.g1" src="x7.png" width="872"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S5.F6.3.2" style="font-size:90%;">Learned domain weights after the convergence of the DreamPRM training process.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS6.p1">
<p class="ltx_p" id="S5.SS6.p1.1">The final domain weights (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S5.F6" title="Figure 6 ‣ 5.6 Analysis of learned domain weights ‣ 5 Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">6</span></a>) range from 0.55 to 1.49: <span class="ltx_text ltx_font_smallcaps" id="S5.SS6.p1.1.1">M3CoT</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib5" title=""><span class="ltx_text" style="font-size:80%;">5</span></a>]</cite> and <span class="ltx_text ltx_font_smallcaps" id="S5.SS6.p1.1.2">FigureQA</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib19" title=""><span class="ltx_text" style="font-size:80%;">19</span></a>]</cite> receive the highest weights (approximately 1.5), while <span class="ltx_text ltx_font_smallcaps" id="S5.SS6.p1.1.3">AI2D</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib21" title=""><span class="ltx_text" style="font-size:80%;">21</span></a>]</cite> and <span class="ltx_text ltx_font_smallcaps" id="S5.SS6.p1.1.4">IconQA</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib33" title=""><span class="ltx_text" style="font-size:80%;">33</span></a>]</cite> are assigned lower weights (less than 0.8). This learned weighting pattern contributes to improved PRM performance, indicating that the quality imbalance problem across reasoning datasets is real and consequential. Additionally, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A5.F8" title="Figure 8 ‣ Appendix E Additional Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">8</span></a> in Appendix, all domain weights are initialized to 1.0 and eventually converge during the training process of DreamPRM.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusions</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We propose DreamPRM, the first domain-reweighted PRM framework for multimodal reasoning. By automatically searching for domain weights using a bi-level optimization framework, DreamPRM effectively mitigates issues caused by dataset quality imbalance and significantly enhances the generalizability of multimodal PRMs. Extensive experiments on five diverse benchmarks confirm that DreamPRM outperforms both vanilla PRMs without domain reweighting and PRMs using heuristic data selection methods. We also observe that the domain weights learned by DreamPRM correlate with dataset quality, effectively separating challenging, informative sources from overly simplistic or noisy ones. These results highlight the effectiveness of our proposed automatic domain reweighting strategy.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.2.2.1" style="font-size:80%;">[1]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.4.1" style="font-size:80%;">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.5.1" style="font-size:80%;">Language models are few-shot learners, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.2.2.1" style="font-size:80%;">[2]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.4.1" style="font-size:80%;">
Shuaichen Chang, David Palzer, Jialin Li, Eric Fosler-Lussier, and Ningchuan Xiao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.5.1" style="font-size:80%;">Mapqa: A dataset for question answering on choropleth maps, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.2.2.1" style="font-size:80%;">[3]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.4.1" style="font-size:80%;">
Jiaqi Chen, Tong Li, Jinghui Qin, Pan Lu, Liang Lin, Chongyu Chen, and Xiaodan Liang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.5.1" style="font-size:80%;">Unigeo: Unifying geometry logical reasoning via reformulating mathematical expression, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.2.2.1" style="font-size:80%;">[4]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.4.1" style="font-size:80%;">
Lin Chen, Jinsong Li, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Zehui Chen, Haodong Duan, Jiaqi Wang, Yu Qiao, Dahua Lin, and Feng Zhao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.5.1" style="font-size:80%;">Are we on the right way for evaluating large vision-language models?, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.3.2.1" style="font-size:80%;">[5]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.5.1" style="font-size:80%;">
Qiguang Chen, Libo Qin, Jin Zhang, Zhi Chen, Xiao Xu, and Wanxiang Che.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.6.1" style="font-size:80%;">M</span><sup class="ltx_sup" id="bib.bib5.7.2"><span class="ltx_text" id="bib.bib5.7.2.1" style="font-size:80%;">3</span></sup><span class="ltx_text" id="bib.bib5.8.3" style="font-size:80%;">cot: A novel benchmark for multi-domain multi-step multi-modal chain-of-thought, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.2.2.1" style="font-size:80%;">[6]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.4.1" style="font-size:80%;">
Sang Keun Choe, Willie Neiswanger, Pengtao Xie, and Eric Xing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.5.1" style="font-size:80%;">Betty: An automatic differentiation library for multilevel optimization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib6.7.2" style="font-size:80%;">The Eleventh International Conference on Learning Representations</span><span class="ltx_text" id="bib.bib6.8.3" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.2.2.1" style="font-size:80%;">[7]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.4.1" style="font-size:80%;">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.5.1" style="font-size:80%;">Palm: Scaling language modeling with pathways, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.2.2.1" style="font-size:80%;">[8]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.4.1" style="font-size:80%;">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.5.1" style="font-size:80%;">Training verifiers to solve math word problems, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.2.2.1" style="font-size:80%;">[9]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.4.1" style="font-size:80%;">
DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J. L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang Zhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Meng Li, Miaojun Wang, Mingming Li, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang, Qinyu Chen, Qiushi Du, Ruiqi Ge, Ruisong
Zhang, Ruizhe Pan, Runji Wang, R. J. Chen, R. L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang, Shuiping Yu, Shunfeng Zhou, Shuting Pan, S. S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao Yun, Tian Pei, Tianyu Sun, T. Wang, Wangding Zeng, Wanjia Zhao, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, W. L. Xiao, Wei An, Xiaodong Liu, Xiaohan Wang, Xiaokang Chen, Xiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, X. Q. Li, Xiangyue Jin, Xiaojin Shen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song, Xinyi Zhou, Xianzu Wang, Xinxia Shan, Y. K. Li, Y. Q. Wang, Y. X. Wei, Yang Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Wang, Yi Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y. X. Zhu,
Yanhong Xu, Yanping Huang, Yaohui Li, Yi Zheng, Yuchen Zhu, Yunxian Ma, Ying Tang, Yukun Zha, Yuting Yan, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu Zhang, and Zhen Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.5.1" style="font-size:80%;">Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.2.2.1" style="font-size:80%;">[10]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.4.1" style="font-size:80%;">
Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, and Ji-Rong Wen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.5.1" style="font-size:80%;">Progressive multimodal reasoning via active retrieval, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.2.2.1" style="font-size:80%;">[11]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.4.1" style="font-size:80%;">
Simin Fan, Matteo Pagliardini, and Martin Jaggi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.5.1" style="font-size:80%;">Doge: Domain reweighting with generalization estimation, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.2.2.1" style="font-size:80%;">[12]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.4.1" style="font-size:80%;">
Simin Fan, Matteo Pagliardini, and Martin Jaggi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.5.1" style="font-size:80%;">DOGE: Domain reweighting with generalization estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.6.1" style="font-size:80%;">In Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib12.7.2" style="font-size:80%;">Proceedings of the 41st International Conference on Machine Learning</span><span class="ltx_text" id="bib.bib12.8.3" style="font-size:80%;">, volume 235 of </span><span class="ltx_text ltx_font_italic" id="bib.bib12.9.4" style="font-size:80%;">Proceedings of Machine Learning Research</span><span class="ltx_text" id="bib.bib12.10.5" style="font-size:80%;">, pages 12895–12915. PMLR, 21–27 Jul 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.2.2.1" style="font-size:80%;">[13]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.4.1" style="font-size:80%;">
Chelsea Finn, P. Abbeel, and Sergey Levine.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.5.1" style="font-size:80%;">Model-agnostic meta-learning for fast adaptation of deep networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib13.7.2" style="font-size:80%;">International Conference on Machine Learning</span><span class="ltx_text" id="bib.bib13.8.3" style="font-size:80%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.2.2.1" style="font-size:80%;">[14]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.4.1" style="font-size:80%;">
Jiahui Gao, Renjie Pi, Jipeng Zhang, Jiacheng Ye, Wanjun Zhong, Yufei Wang, Lanqing Hong, Jianhua Han, Hang Xu, Zhenguo Li, and Lingpeng Kong.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.5.1" style="font-size:80%;">G-llava: Solving geometric problem with multi-modal large language model, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.2.2.1" style="font-size:80%;">[15]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.4.1" style="font-size:80%;">
Yuan Ge, Yilun Liu, Chi Hu, Weibin Meng, Shimin Tao, Xiaofeng Zhao, Hongxia Ma, Li Zhang, Boxing Chen, Hao Yang, Bei Li, Tong Xiao, and Jingbo Zhu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.5.1" style="font-size:80%;">Clustering and ranking: Diversity-preserved instruction selection through expert-aligned quality estimation, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.2.2.1" style="font-size:80%;">[16]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.4.1" style="font-size:80%;">
Jiayi He, Hehai Lin, Qingyun Wang, Yi Fung, and Heng Ji.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.5.1" style="font-size:80%;">Self-correction is more than refinement: A learning framework for visual and language reasoning tasks, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.2.2.1" style="font-size:80%;">[17]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.4.1" style="font-size:80%;">
Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanwei Li, Yu Qi, Xinyan Chen, Liuhui Wang, Jianhan Jin, Claire Guo, Shen Yan, Bo Zhang, Chaoyou Fu, Peng Gao, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.5.1" style="font-size:80%;">Mme-cot: Benchmarking chain-of-thought in large multimodal models for reasoning quality, robustness, and efficiency, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib18.2.2.1" style="font-size:80%;">[18]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.4.1" style="font-size:80%;">
Kushal Kafle, Brian Price, Scott Cohen, and Christopher Kanan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.5.1" style="font-size:80%;">Dvqa: Understanding data visualizations via question answering, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib19.2.2.1" style="font-size:80%;">[19]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.4.1" style="font-size:80%;">
Samira Ebrahimi Kahou, Vincent Michalski, Adam Atkinson, Akos Kadar, Adam Trischler, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.5.1" style="font-size:80%;">Figureqa: An annotated figure dataset for visual reasoning, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib20.2.2.1" style="font-size:80%;">[20]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.4.1" style="font-size:80%;">
Mehran Kazemi, Hamidreza Alvari, Ankit Anand, Jialin Wu, Xi Chen, and Radu Soricut.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.5.1" style="font-size:80%;">Geomverse: A systematic evaluation of large models for geometric reasoning, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib21.2.2.1" style="font-size:80%;">[21]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.4.1" style="font-size:80%;">
Aniruddha Kembhavi, Mike Salvato, Eric Kolve, Minjoon Seo, Hannaneh Hajishirzi, and Ali Farhadi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.5.1" style="font-size:80%;">A diagram is worth a dozen images, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib22.2.2.1" style="font-size:80%;">[22]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.4.1" style="font-size:80%;">
Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.5.1" style="font-size:80%;">Large language models are zero-shot reasoners.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib22.7.2" style="font-size:80%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib22.8.3" style="font-size:80%;">, volume 35, pages 22199–22213, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib23.2.2.1" style="font-size:80%;">[23]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.4.1" style="font-size:80%;">
Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Peiyuan Zhang, Yanwei Li, Ziwei Liu, and Chunyuan Li.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.5.1" style="font-size:80%;">Llava-onevision: Easy visual task transfer, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib24.2.2.1" style="font-size:80%;">[24]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.4.1" style="font-size:80%;">
Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.5.1" style="font-size:80%;">Making large language models better reasoners with step-aware verifier, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib25.2.2.1" style="font-size:80%;">[25]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.4.1" style="font-size:80%;">
Zongxia Li, Xiyang Wu, Hongyang Du, Fuxiao Liu, Huy Nghiem, and Guangyao Shi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.5.1" style="font-size:80%;">A survey of state of the art large vision language models: Alignment, benchmark, evaluations and challenges.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.6.1" style="font-size:80%;">arXiv preprint arXiv:2501.02189</span><span class="ltx_text" id="bib.bib25.7.2" style="font-size:80%;">, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib26.2.2.1" style="font-size:80%;">[26]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.4.1" style="font-size:80%;">
Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.5.1" style="font-size:80%;">Let’s verify step by step.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib26.7.2" style="font-size:80%;">The Twelfth International Conference on Learning Representations</span><span class="ltx_text" id="bib.bib26.8.3" style="font-size:80%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib27.2.2.1" style="font-size:80%;">[27]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.4.1" style="font-size:80%;">
Adam Dahlgren Lindström and Savitha Sam Abraham.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.5.1" style="font-size:80%;">Clevr-math: A dataset for compositional language, visual and mathematical reasoning, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib28.2.2.1" style="font-size:80%;">[28]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.4.1" style="font-size:80%;">
Hanxiao Liu, Karen Simonyan, and Yiming Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.5.1" style="font-size:80%;">DARTS: Differentiable architecture search.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib28.7.2" style="font-size:80%;">International Conference on Learning Representations</span><span class="ltx_text" id="bib.bib28.8.3" style="font-size:80%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib29.2.2.1" style="font-size:80%;">[29]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.4.1" style="font-size:80%;">
Ilya Loshchilov and Frank Hutter.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.5.1" style="font-size:80%;">Decoupled weight decay regularization, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib30.2.2.1" style="font-size:80%;">[30]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.4.1" style="font-size:80%;">
Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, and Jianfeng Gao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.5.1" style="font-size:80%;">Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib30.7.2" style="font-size:80%;">International Conference on Learning Representations (ICLR)</span><span class="ltx_text" id="bib.bib30.8.3" style="font-size:80%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib31.2.2.1" style="font-size:80%;">[31]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.4.1" style="font-size:80%;">
Pan Lu, Ran Gong, Shibiao Jiang, Liang Qiu, Siyuan Huang, Xiaodan Liang, and Song-Chun Zhu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.5.1" style="font-size:80%;">Inter-gps: Interpretable geometry problem solving with formal language and symbolic reasoning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib31.7.2" style="font-size:80%;">The 59th Annual Meeting of the Association for Computational Linguistics (ACL)</span><span class="ltx_text" id="bib.bib31.8.3" style="font-size:80%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib32.2.2.1" style="font-size:80%;">[32]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.4.1" style="font-size:80%;">
Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.5.1" style="font-size:80%;">Learn to explain: Multimodal reasoning via thought chains for science question answering, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib33.2.2.1" style="font-size:80%;">[33]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.4.1" style="font-size:80%;">
Pan Lu, Liang Qiu, Jiaqi Chen, Tony Xia, Yizhou Zhao, Wei Zhang, Zhou Yu, Xiaodan Liang, and Song-Chun Zhu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.5.1" style="font-size:80%;">Iconqa: A new benchmark for abstract diagram understanding and visual language reasoning, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib34.2.2.1" style="font-size:80%;">[34]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.4.1" style="font-size:80%;">
Liangchen Luo, Yinxiao Liu, Rosanne Liu, Samrat Phatale, Meiqi Guo, Harsh Lara, Yunxuan Li, Lei Shu, Yun Zhu, Lei Meng, Jiao Sun, and Abhinav Rastogi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.5.1" style="font-size:80%;">Improve mathematical reasoning in language models by automated process supervision, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib35.2.2.1" style="font-size:80%;">[35]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.4.1" style="font-size:80%;">
Qianli Ma, Haotian Zhou, Tingkai Liu, Jianbo Yuan, Pengfei Liu, Yang You, and Hongxia Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.5.1" style="font-size:80%;">Let’s reward step by step: Step-level reward model as the navigators for reasoning, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib36.2.2.1" style="font-size:80%;">[36]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.4.1" style="font-size:80%;">
Ahmed Masry, Do Xuan Long, Jia Qing Tan, Shafiq Joty, and Enamul Hoque.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.5.1" style="font-size:80%;">Chartqa: A benchmark for question answering about charts with visual and logical reasoning, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib37.2.2.1" style="font-size:80%;">[37]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.4.1" style="font-size:80%;">
Minesh Mathew, Viraj Bagal, Rubèn Pérez Tito, Dimosthenis Karatzas, Ernest Valveny, and C. V Jawahar.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.5.1" style="font-size:80%;">Infographicvqa, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib38.2.2.1" style="font-size:80%;">[38]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.4.1" style="font-size:80%;">
Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Candès, and Tatsunori Hashimoto.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.5.1" style="font-size:80%;">s1: Simple test-time scaling, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib39.2.2.1" style="font-size:80%;">[39]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.4.1" style="font-size:80%;">
OpenAI, :, Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, Alex Iftimie, Alex Karpenko, Alex Tachard Passos, Alexander Neitz, Alexander Prokofiev, Alexander Wei, Allison Tam, Ally Bennett, Ananya Kumar, Andre Saraiva, Andrea Vallone, Andrew Duberstein, Andrew Kondrich, Andrey Mishchenko, Andy Applebaum, Angela Jiang, Ashvin Nair, Barret Zoph, Behrooz Ghorbani, Ben Rossen, Benjamin Sokolowsky, Boaz Barak, Bob McGrew, Borys Minaiev, Botao Hao, Bowen Baker, Brandon Houghton, Brandon McKinzie, Brydon Eastman, Camillo Lugaresi, Cary Bassin, Cary Hudson, Chak Ming Li, Charles de Bourcy, Chelsea Voss, Chen Shen, Chong Zhang, Chris Koch, Chris Orsinger, Christopher Hesse, Claudia Fischer, Clive Chan, Dan Roberts, Daniel Kappler, Daniel Levy, Daniel Selsam, David Dohan, David Farhi, David Mely, David Robinson, Dimitris Tsipras, Doug Li, Dragos Oprica, Eben Freeman, Eddie Zhang, Edmund Wong, Elizabeth Proehl, Enoch Cheung, Eric
Mitchell, Eric Wallace, Erik Ritter, Evan Mays, Fan Wang, Felipe Petroski Such, Filippo Raso, Florencia Leoni, Foivos Tsimpourlas, Francis Song, Fred von Lohmann, Freddie Sulit, Geoff Salmon, Giambattista Parascandolo, Gildas Chabot, Grace Zhao, Greg Brockman, Guillaume Leclerc, Hadi Salman, Haiming Bao, Hao Sheng, Hart Andrin, Hessam Bagherinezhad, Hongyu Ren, Hunter Lightman, Hyung Won Chung, Ian Kivlichan, Ian O’Connell, Ian Osband, Ignasi Clavera Gilaberte, Ilge Akkaya, Ilya Kostrikov, Ilya Sutskever, Irina Kofman, Jakub Pachocki, James Lennon, Jason Wei, Jean Harb, Jerry Twore, Jiacheng Feng, Jiahui Yu, Jiayi Weng, Jie Tang, Jieqi Yu, Joaquin Quiñonero Candela, Joe Palermo, Joel Parish, Johannes Heidecke, John Hallman, John Rizzo, Jonathan Gordon, Jonathan Uesato, Jonathan Ward, Joost Huizinga, Julie Wang, Kai Chen, Kai Xiao, Karan Singhal, Karina Nguyen, Karl Cobbe, Katy Shi, Kayla Wood, Kendra Rimbach, Keren Gu-Lemberg, Kevin Liu, Kevin Lu, Kevin Stone, Kevin Yu, Lama Ahmad, Lauren Yang, Leo Liu,
Leon Maksin, Leyton Ho, Liam Fedus, Lilian Weng, Linden Li, Lindsay McCallum, Lindsey Held, Lorenz Kuhn, Lukas Kondraciuk, Lukasz Kaiser, Luke Metz, Madelaine Boyd, Maja Trebacz, Manas Joglekar, Mark Chen, Marko Tintor, Mason Meyer, Matt Jones, Matt Kaufer, Max Schwarzer, Meghan Shah, Mehmet Yatbaz, Melody Y. Guan, Mengyuan Xu, Mengyuan Yan, Mia Glaese, Mianna Chen, Michael Lampe, Michael Malek, Michele Wang, Michelle Fradin, Mike McClay, Mikhail Pavlov, Miles Wang, Mingxuan Wang, Mira Murati, Mo Bavarian, Mostafa Rohaninejad, Nat McAleese, Neil Chowdhury, Neil Chowdhury, Nick Ryder, Nikolas Tezak, Noam Brown, Ofir Nachum, Oleg Boiko, Oleg Murk, Olivia Watkins, Patrick Chao, Paul Ashbourne, Pavel Izmailov, Peter Zhokhov, Rachel Dias, Rahul Arora, Randall Lin, Rapha Gontijo Lopes, Raz Gaon, Reah Miyara, Reimar Leike, Renny Hwang, Rhythm Garg, Robin Brown, Roshan James, Rui Shu, Ryan Cheu, Ryan Greene, Saachi Jain, Sam Altman, Sam Toizer, Sam Toyer, Samuel Miserendino, Sandhini Agarwal, Santiago Hernandez,
Sasha Baker, Scott McKinney, Scottie Yan, Shengjia Zhao, Shengli Hu, Shibani Santurkar, Shraman Ray Chaudhuri, Shuyuan Zhang, Siyuan Fu, Spencer Papay, Steph Lin, Suchir Balaji, Suvansh Sanjeev, Szymon Sidor, Tal Broda, Aidan Clark, Tao Wang, Taylor Gordon, Ted Sanders, Tejal Patwardhan, Thibault Sottiaux, Thomas Degry, Thomas Dimson, Tianhao Zheng, Timur Garipov, Tom Stasi, Trapit Bansal, Trevor Creech, Troy Peterson, Tyna Eloundou, Valerie Qi, Vineet Kosaraju, Vinnie Monaco, Vitchyr Pong, Vlad Fomenko, Weiyi Zheng, Wenda Zhou, Wes McCabe, Wojciech Zaremba, Yann Dubois, Yinghai Lu, Yining Chen, Young Cha, Yu Bai, Yuchen He, Yuchen Zhang, Yunyun Wang, Zheng Shao, and Zhuohan Li.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.5.1" style="font-size:80%;">Openai o1 system card, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib40.2.2.1" style="font-size:80%;">[40]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.4.1" style="font-size:80%;">
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo
Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan
Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez,
Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia
Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.5.1" style="font-size:80%;">Gpt-4 technical report, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib41.2.2.1" style="font-size:80%;">[41]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.4.1" style="font-size:80%;">
Guilherme Penedo, Anton Lozhkov, Hynek Kydlíček, Loubna Ben Allal, Edward Beeching, Agustín Piqueres Lajarín, Quentin Gallouédec, Nathan Habib, Lewis Tunstall, and Leandro von Werra.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.5.1" style="font-size:80%;">Codeforces.
</span>
</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/open-r1/codeforces" style="font-size:80%;" title="">https://huggingface.co/datasets/open-r1/codeforces</a><span class="ltx_text" id="bib.bib41.6.1" style="font-size:80%;">, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib42.2.2.1" style="font-size:80%;">[42]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.4.1" style="font-size:80%;">
Runqi Qiao, Qiuna Tan, Guanting Dong, Minhui Wu, Chong Sun, Xiaoshuai Song, Zhuoma GongQue, Shanglin Lei, Zhe Wei, Miaoxuan Zhang, Runfeng Qiao, Yifan Zhang, Xiao Zong, Yida Xu, Muxi Diao, Zhimin Bao, Chen Li, and Honggang Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.5.1" style="font-size:80%;">We-math: Does your large multimodal model achieve human-like mathematical reasoning?, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib43.2.2.1" style="font-size:80%;">[43]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.4.1" style="font-size:80%;">
Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.5.1" style="font-size:80%;">Qwen2.5 technical report, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib44.2.2.1" style="font-size:80%;">[44]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.4.1" style="font-size:80%;">
Alex Reid et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.5.1" style="font-size:80%;">Gemini 1.5: Unlocking multimodal understanding across millions of tokens, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib45.2.2.1" style="font-size:80%;">[45]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.4.1" style="font-size:80%;">
Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi, Oren Etzioni, and Clint Malcolm.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.5.1" style="font-size:80%;">Solving geometry problems: Combining text and diagram interpretation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.6.1" style="font-size:80%;">In Lluís Màrquez, Chris Callison-Burch, and Jian Su, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib45.7.2" style="font-size:80%;">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</span><span class="ltx_text" id="bib.bib45.8.3" style="font-size:80%;">, pages 1466–1476, Lisbon, Portugal, September 2015. Association for Computational Linguistics.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib46.2.2.1" style="font-size:80%;">[46]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.4.1" style="font-size:80%;">
Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.5.1" style="font-size:80%;">Deepseekmath: Pushing the limits of mathematical reasoning in open language models, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib47.2.2.1" style="font-size:80%;">[47]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.4.1" style="font-size:80%;">
Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, and Deyu Meng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.5.1" style="font-size:80%;">Meta-weight-net: Learning an explicit mapping for sample weighting, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib48.2.2.1" style="font-size:80%;">[48]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.4.1" style="font-size:80%;">
Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, and Deyu Meng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.5.1" style="font-size:80%;">Meta-weight-net: Learning an explicit mapping for sample weighting.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.6.1" style="font-size:80%;">In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib48.7.2" style="font-size:80%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib48.8.3" style="font-size:80%;">, volume 32. Curran Associates, Inc., 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib49.2.2.1" style="font-size:80%;">[49]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.4.1" style="font-size:80%;">
Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.5.1" style="font-size:80%;">Scaling llm test-time compute optimally can be more effective than scaling model parameters, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib50.2.2.1" style="font-size:80%;">[50]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.4.1" style="font-size:80%;">
Shezheng Song, Xiaopeng Li, Shasha Li, Shan Zhao, Jie Yu, Jun Ma, Xiaoguang Mao, and Weimin Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.5.1" style="font-size:80%;">How to bridge the gap between modalities: Survey on multimodal large language model, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib51.2.2.1" style="font-size:80%;">[51]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.4.1" style="font-size:80%;">
Daouda Sow, Herbert Woisetschläger, Saikiran Bulusu, Shiqiang Wang, Hans-Arno Jacobsen, and Yingbin Liang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.5.1" style="font-size:80%;">Dynamic loss-based sample reweighting for improved large language model pretraining, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib52.2.2.1" style="font-size:80%;">[52]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.4.1" style="font-size:80%;">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.5.1" style="font-size:80%;">Llama: Open and efficient foundation language models, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib53.2.2.1" style="font-size:80%;">[53]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.4.1" style="font-size:80%;">
Chaojie Wang, Yanchen Deng, Zhiyi Lyu, Liang Zeng, Jujie He, Shuicheng Yan, and Bo An.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.5.1" style="font-size:80%;">Q*: Improving multi-step reasoning for llms with deliberative planning, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib54.2.2.1" style="font-size:80%;">[54]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.4.1" style="font-size:80%;">
Ke Wang, Junting Pan, Weikang Shi, Zimu Lu, Mingjie Zhan, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.5.1" style="font-size:80%;">Measuring multimodal mathematical reasoning with math-vision dataset, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib55.2.2.1" style="font-size:80%;">[55]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.4.1" style="font-size:80%;">
Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, Yu Wu, and Zhifang Sui.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.5.1" style="font-size:80%;">Math-shepherd: Verify and reinforce LLMs step-by-step without human annotations.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.6.1" style="font-size:80%;">In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib55.7.2" style="font-size:80%;">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span><span class="ltx_text" id="bib.bib55.8.3" style="font-size:80%;">, pages 9426–9439, Bangkok, Thailand, August 2024. Association for Computational Linguistics.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib56.2.2.1" style="font-size:80%;">[56]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.4.1" style="font-size:80%;">
Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, Yu Wu, and Zhifang Sui.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.5.1" style="font-size:80%;">Math-shepherd: Verify and reinforce LLMs step-by-step without human annotations.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.6.1" style="font-size:80%;">In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib56.7.2" style="font-size:80%;">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span><span class="ltx_text" id="bib.bib56.8.3" style="font-size:80%;">, pages 9426–9439, Bangkok, Thailand, August 2024. Association for Computational Linguistics.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib57.2.2.1" style="font-size:80%;">[57]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.4.1" style="font-size:80%;">
Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Yang Fan, Kai Dang, Mengfei Du, Xuancheng Ren, Rui Men, Dayiheng Liu, Chang Zhou, Jingren Zhou, and Junyang Lin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.5.1" style="font-size:80%;">Qwen2-vl: Enhancing vision-language model’s perception of the world at any resolution.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib57.6.1" style="font-size:80%;">arXiv preprint arXiv:2409.12191</span><span class="ltx_text" id="bib.bib57.7.2" style="font-size:80%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib58.2.2.1" style="font-size:80%;">[58]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.4.1" style="font-size:80%;">
Weiyun Wang, Zhe Chen, Wenhai Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Jinguo Zhu, Xizhou Zhu, Lewei Lu, Yu Qiao, and Jifeng Dai.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.5.1" style="font-size:80%;">Enhancing the reasoning ability of multimodal large language models via mixed preference optimization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib58.6.1" style="font-size:80%;">arXiv preprint arXiv:2411.10442</span><span class="ltx_text" id="bib.bib58.7.2" style="font-size:80%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib59.2.2.1" style="font-size:80%;">[59]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.4.1" style="font-size:80%;">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.5.1" style="font-size:80%;">Self-consistency improves chain of thought reasoning in language models, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib60.2.2.1" style="font-size:80%;">[60]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.4.1" style="font-size:80%;">
Zihan Wang, Yunxuan Li, Yuexin Wu, Liangchen Luo, Le Hou, Hongkun Yu, and Jingbo Shang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.5.1" style="font-size:80%;">Multi-step problem solving through a verifier: An empirical analysis on model-induced process supervision, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib61.2.2.1" style="font-size:80%;">[61]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.4.1" style="font-size:80%;">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.5.1" style="font-size:80%;">Chain of thought prompting elicits reasoning in large language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.6.1" style="font-size:80%;">In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib61.7.2" style="font-size:80%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib61.8.3" style="font-size:80%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib62.2.2.1" style="font-size:80%;">[62]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.4.1" style="font-size:80%;">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.5.1" style="font-size:80%;">Chain-of-thought prompting elicits reasoning in large language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib62.7.2" style="font-size:80%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib62.8.3" style="font-size:80%;">, volume 35, pages 24824–24837. Curran Associates, Inc., 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib63.2.2.1" style="font-size:80%;">[63]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.4.1" style="font-size:80%;">
Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, and Philip S. Yu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.5.1" style="font-size:80%;">Multimodal large language models: A survey, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib64.2.2.1" style="font-size:80%;">[64]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.4.1" style="font-size:80%;">
Sang Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy Liang, Quoc V Le, Tengyu Ma, and Adams Wei Yu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.5.1" style="font-size:80%;">Doremi: Optimizing data mixtures speeds up language model pretraining.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib64.7.2" style="font-size:80%;">Thirty-seventh Conference on Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib64.8.3" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib65.2.2.1" style="font-size:80%;">[65]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.4.1" style="font-size:80%;">
Guowei Xu, Peng Jin, Hao Li, Yibing Song, Lichao Sun, and Li Yuan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.5.1" style="font-size:80%;">Llava-cot: Let vision language models reason step-by-step, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib66.2.2.1" style="font-size:80%;">[66]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.4.1" style="font-size:80%;">
Guowei Xu, Peng Jin, Hao Li, Yibing Song, Lichao Sun, and Li Yuan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.5.1" style="font-size:80%;">Llava-cot: Let vision language models reason step-by-step, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib67.2.2.1" style="font-size:80%;">[67]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.4.1" style="font-size:80%;">
Jiasheng Ye, Peiju Liu, Tianxiang Sun, Jun Zhan, Yunhua Zhou, and Xipeng Qiu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.5.1" style="font-size:80%;">Data mixing laws: Optimizing data mixtures by predicting language modeling performance.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib67.7.2" style="font-size:80%;">The Thirteenth International Conference on Learning Representations</span><span class="ltx_text" id="bib.bib67.8.3" style="font-size:80%;">, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib68.2.2.1" style="font-size:80%;">[68]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.4.1" style="font-size:80%;">
Tianyu Yu, Haoye Zhang, Qiming Li, Qixin Xu, Yuan Yao, Da Chen, Xiaoman Lu, Ganqu Cui, Yunkai Dang, Taiwen He, Xiaocheng Feng, Jun Song, Bo Zheng, Zhiyuan Liu, Tat-Seng Chua, and Maosong Sun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.5.1" style="font-size:80%;">Rlaif-v: Open-source ai feedback leads to super gpt-4v trustworthiness.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib68.6.1" style="font-size:80%;">arXiv preprint arXiv:2405.17220</span><span class="ltx_text" id="bib.bib68.7.2" style="font-size:80%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib69.2.2.1" style="font-size:80%;">[69]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.4.1" style="font-size:80%;">
Weihao Yu, Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Zicheng Liu, Xinchao Wang, and Lijuan Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.5.1" style="font-size:80%;">Mm-vet: Evaluating large multimodal models for integrated capabilities, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib70.2.2.1" style="font-size:80%;">[70]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.4.1" style="font-size:80%;">
Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.5.1" style="font-size:80%;">Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib71.2.2.1" style="font-size:80%;">[71]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.4.1" style="font-size:80%;">
Di Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.5.1" style="font-size:80%;">Aime_1983_2024 (revision 6283828), 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib72.2.2.1" style="font-size:80%;">[72]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.4.1" style="font-size:80%;">
Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.5.1" style="font-size:80%;">Automatic chain of thought prompting in large language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib72.7.2" style="font-size:80%;">The Eleventh International Conference on Learning Representations</span><span class="ltx_text" id="bib.bib72.8.3" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib73.2.2.1" style="font-size:80%;">[73]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.4.1" style="font-size:80%;">
Haojie Zheng, Tianyang Xu, Hanchi Sun, Shu Pu, Ruoxi Chen, and Lichao Sun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.5.1" style="font-size:80%;">Thinking before looking: Improving multimodal llm reasoning via mitigating visual hallucination, 2024.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Related Works</h2>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Multimodal Reasoning</h4>
<div class="ltx_para" id="A1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p1.1">Recent studies have demonstrated that incorporating Chain-of-Thought (CoT) reasoning <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib61" title=""><span class="ltx_text" style="font-size:80%;">61</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib22" title=""><span class="ltx_text" style="font-size:80%;">22</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib72" title=""><span class="ltx_text" style="font-size:80%;">72</span></a>]</cite> into LLMs encourages a step-by-step approach, thereby significantly enhancing question-answering performance. However, it has been reported that CoT prompting can’t be easily extended to MLLMs, mainly due to hallucinated outputs during the reasoning process <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib58" title=""><span class="ltx_text" style="font-size:80%;">58</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib73" title=""><span class="ltx_text" style="font-size:80%;">73</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib17" title=""><span class="ltx_text" style="font-size:80%;">17</span></a>]</cite>. Therefore, some post-training methods have been proposed for enhancing reasoning capability of MLLMs. InternVL-MPO <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib58" title=""><span class="ltx_text" style="font-size:80%;">58</span></a>]</cite> proposes a mixed preference optimization that jointly optimizes preference ranking, response quality, and response generation loss to improve the reasoning abilities. Llava-CoT <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib65" title=""><span class="ltx_text" style="font-size:80%;">65</span></a>]</cite> creates a structured thinking fine-tuning dataset to make MLLM to perform systematic step-by-step reasoning. Some efforts have also been made for inference time scaling. RLAIF-V <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib68" title=""><span class="ltx_text" style="font-size:80%;">68</span></a>]</cite> proposes a novel self-feedback guidance for inference-time scaling and devises a simple length-normalization strategy tackling the bias towards shorter responses. AR-MCTS <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib10" title=""><span class="ltx_text" style="font-size:80%;">10</span></a>]</cite> combines Monte-Carlo Tree Search (MCTS) and Retrival Augmented Generation (RAG) to guide MLLM search step by step and explore the answer space.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Process Reward Model</h4>
<div class="ltx_para" id="A1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p1.1">Process Reward Model (PRM) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib26" title=""><span class="ltx_text" style="font-size:80%;">26</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib24" title=""><span class="ltx_text" style="font-size:80%;">24</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib35" title=""><span class="ltx_text" style="font-size:80%;">35</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib53" title=""><span class="ltx_text" style="font-size:80%;">53</span></a>]</cite> provides a more finer-grained verification than Outcome Reward Model (ORM) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib8" title=""><span class="ltx_text" style="font-size:80%;">8</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib46" title=""><span class="ltx_text" style="font-size:80%;">46</span></a>]</cite>, scoring each step of the reasoning trajectory. However, a central challenge in designing PRMs is obtaining process supervision signals, which require supervised labels for each reasoning step. Current approaches typically depend on costly, labor-intensive human annotation <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib26" title=""><span class="ltx_text" style="font-size:80%;">26</span></a>]</cite>, highlighting the need for automated methods to improve scalability and efficiency. Math-Shepherd <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib55" title=""><span class="ltx_text" style="font-size:80%;">55</span></a>]</cite> proposes a method utilizing Monte-Carlo estimation to provide hard labels and soft labels for automatic process supervision. OmegaPRM <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib34" title=""><span class="ltx_text" style="font-size:80%;">34</span></a>]</cite> proposes a Monte Carlo Tree Search (MCTS) for finer-grained exploration for automatical labeling. MiPS <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib60" title=""><span class="ltx_text" style="font-size:80%;">60</span></a>]</cite> further explores the Monte Carlo estimation method and studies the aggregation of PRM signals.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Domain Reweighting</h4>
<div class="ltx_para" id="A1.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px3.p1.1">Domain reweighting methodologies are developed to modulate the influence of individual data domains, thereby enabling models to achieve robust generalization. Recently, domain reweighting has emerged as a key component in large language model pre-training, where corpora are drawn from heterogeneous sources. DoReMi <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib64" title=""><span class="ltx_text" style="font-size:80%;">64</span></a>]</cite> trains a lightweight proxy model with group distributionally robust optimization to assign domain weights that maximize excess loss relative to a reference model. DOGE <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib12" title=""><span class="ltx_text" style="font-size:80%;">12</span></a>]</cite> proposes a first-order bi-level optimization framework, using gradient alignment between source and target domains to update mixture weights online during training. Complementary to these optimization-based approaches, Data Mixing Laws <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib67" title=""><span class="ltx_text" style="font-size:80%;">67</span></a>]</cite> derives scaling laws that could predict performance under different domain mixtures, enabling low-cost searches for near-optimal weights without proxy models. In this paper, we extend these ideas to process supervision and introduce a novel bi-level domain-reweighting framework.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Optimization algorithm</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">Directly solving the bi-level optimization problem in Equation <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#S4.E9" title="In Upper-level optimization: learning domain reweighting parameters. ‣ 4 The Proposed Domain-reweighting Method ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">9</span></a> can be computational prohibitive due to its nested structure. Following previous work <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib6" title=""><span class="ltx_text" style="font-size:80%;">6</span></a>]</cite>, we use approximated algorithm with a few unrolling steps. For example, under one-step unrolling, the updating of PRM’s weights can be expressed as:</p>
</div>
<div class="ltx_para" id="A2.p2">
<table class="ltx_equation ltx_eqn_table" id="A2.E10">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\phi^{(t+1)}=\phi^{(t)}-\beta_{1}\nabla_{\phi}\mathcal{L}_{tr}(\mathcal{D}_{tr%
},\phi,\alpha)" class="ltx_Math" display="block" id="A2.E10.m1.5"><semantics id="A2.E10.m1.5a"><mrow id="A2.E10.m1.5.5" xref="A2.E10.m1.5.5.cmml"><msup id="A2.E10.m1.5.5.3" xref="A2.E10.m1.5.5.3.cmml"><mi id="A2.E10.m1.5.5.3.2" xref="A2.E10.m1.5.5.3.2.cmml">ϕ</mi><mrow id="A2.E10.m1.1.1.1.1" xref="A2.E10.m1.1.1.1.1.1.cmml"><mo id="A2.E10.m1.1.1.1.1.2" stretchy="false" xref="A2.E10.m1.1.1.1.1.1.cmml">(</mo><mrow id="A2.E10.m1.1.1.1.1.1" xref="A2.E10.m1.1.1.1.1.1.cmml"><mi id="A2.E10.m1.1.1.1.1.1.2" xref="A2.E10.m1.1.1.1.1.1.2.cmml">t</mi><mo id="A2.E10.m1.1.1.1.1.1.1" xref="A2.E10.m1.1.1.1.1.1.1.cmml">+</mo><mn id="A2.E10.m1.1.1.1.1.1.3" xref="A2.E10.m1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="A2.E10.m1.1.1.1.1.3" stretchy="false" xref="A2.E10.m1.1.1.1.1.1.cmml">)</mo></mrow></msup><mo id="A2.E10.m1.5.5.2" xref="A2.E10.m1.5.5.2.cmml">=</mo><mrow id="A2.E10.m1.5.5.1" xref="A2.E10.m1.5.5.1.cmml"><msup id="A2.E10.m1.5.5.1.3" xref="A2.E10.m1.5.5.1.3.cmml"><mi id="A2.E10.m1.5.5.1.3.2" xref="A2.E10.m1.5.5.1.3.2.cmml">ϕ</mi><mrow id="A2.E10.m1.2.2.1.3" xref="A2.E10.m1.5.5.1.3.cmml"><mo id="A2.E10.m1.2.2.1.3.1" stretchy="false" xref="A2.E10.m1.5.5.1.3.cmml">(</mo><mi id="A2.E10.m1.2.2.1.1" xref="A2.E10.m1.2.2.1.1.cmml">t</mi><mo id="A2.E10.m1.2.2.1.3.2" stretchy="false" xref="A2.E10.m1.5.5.1.3.cmml">)</mo></mrow></msup><mo id="A2.E10.m1.5.5.1.2" xref="A2.E10.m1.5.5.1.2.cmml">−</mo><mrow id="A2.E10.m1.5.5.1.1" xref="A2.E10.m1.5.5.1.1.cmml"><msub id="A2.E10.m1.5.5.1.1.3" xref="A2.E10.m1.5.5.1.1.3.cmml"><mi id="A2.E10.m1.5.5.1.1.3.2" xref="A2.E10.m1.5.5.1.1.3.2.cmml">β</mi><mn id="A2.E10.m1.5.5.1.1.3.3" xref="A2.E10.m1.5.5.1.1.3.3.cmml">1</mn></msub><mo id="A2.E10.m1.5.5.1.1.2" lspace="0.167em" xref="A2.E10.m1.5.5.1.1.2.cmml">⁢</mo><mrow id="A2.E10.m1.5.5.1.1.4" xref="A2.E10.m1.5.5.1.1.4.cmml"><msub id="A2.E10.m1.5.5.1.1.4.1" xref="A2.E10.m1.5.5.1.1.4.1.cmml"><mo id="A2.E10.m1.5.5.1.1.4.1.2" rspace="0.167em" xref="A2.E10.m1.5.5.1.1.4.1.2.cmml">∇</mo><mi id="A2.E10.m1.5.5.1.1.4.1.3" xref="A2.E10.m1.5.5.1.1.4.1.3.cmml">ϕ</mi></msub><msub id="A2.E10.m1.5.5.1.1.4.2" xref="A2.E10.m1.5.5.1.1.4.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.E10.m1.5.5.1.1.4.2.2" xref="A2.E10.m1.5.5.1.1.4.2.2.cmml">ℒ</mi><mrow id="A2.E10.m1.5.5.1.1.4.2.3" xref="A2.E10.m1.5.5.1.1.4.2.3.cmml"><mi id="A2.E10.m1.5.5.1.1.4.2.3.2" xref="A2.E10.m1.5.5.1.1.4.2.3.2.cmml">t</mi><mo id="A2.E10.m1.5.5.1.1.4.2.3.1" xref="A2.E10.m1.5.5.1.1.4.2.3.1.cmml">⁢</mo><mi id="A2.E10.m1.5.5.1.1.4.2.3.3" xref="A2.E10.m1.5.5.1.1.4.2.3.3.cmml">r</mi></mrow></msub></mrow><mo id="A2.E10.m1.5.5.1.1.2a" xref="A2.E10.m1.5.5.1.1.2.cmml">⁢</mo><mrow id="A2.E10.m1.5.5.1.1.1.1" xref="A2.E10.m1.5.5.1.1.1.2.cmml"><mo id="A2.E10.m1.5.5.1.1.1.1.2" stretchy="false" xref="A2.E10.m1.5.5.1.1.1.2.cmml">(</mo><msub id="A2.E10.m1.5.5.1.1.1.1.1" xref="A2.E10.m1.5.5.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.E10.m1.5.5.1.1.1.1.1.2" xref="A2.E10.m1.5.5.1.1.1.1.1.2.cmml">𝒟</mi><mrow id="A2.E10.m1.5.5.1.1.1.1.1.3" xref="A2.E10.m1.5.5.1.1.1.1.1.3.cmml"><mi id="A2.E10.m1.5.5.1.1.1.1.1.3.2" xref="A2.E10.m1.5.5.1.1.1.1.1.3.2.cmml">t</mi><mo id="A2.E10.m1.5.5.1.1.1.1.1.3.1" xref="A2.E10.m1.5.5.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="A2.E10.m1.5.5.1.1.1.1.1.3.3" xref="A2.E10.m1.5.5.1.1.1.1.1.3.3.cmml">r</mi></mrow></msub><mo id="A2.E10.m1.5.5.1.1.1.1.3" xref="A2.E10.m1.5.5.1.1.1.2.cmml">,</mo><mi id="A2.E10.m1.3.3" xref="A2.E10.m1.3.3.cmml">ϕ</mi><mo id="A2.E10.m1.5.5.1.1.1.1.4" xref="A2.E10.m1.5.5.1.1.1.2.cmml">,</mo><mi id="A2.E10.m1.4.4" xref="A2.E10.m1.4.4.cmml">α</mi><mo id="A2.E10.m1.5.5.1.1.1.1.5" stretchy="false" xref="A2.E10.m1.5.5.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.E10.m1.5b"><apply id="A2.E10.m1.5.5.cmml" xref="A2.E10.m1.5.5"><eq id="A2.E10.m1.5.5.2.cmml" xref="A2.E10.m1.5.5.2"></eq><apply id="A2.E10.m1.5.5.3.cmml" xref="A2.E10.m1.5.5.3"><csymbol cd="ambiguous" id="A2.E10.m1.5.5.3.1.cmml" xref="A2.E10.m1.5.5.3">superscript</csymbol><ci id="A2.E10.m1.5.5.3.2.cmml" xref="A2.E10.m1.5.5.3.2">italic-ϕ</ci><apply id="A2.E10.m1.1.1.1.1.1.cmml" xref="A2.E10.m1.1.1.1.1"><plus id="A2.E10.m1.1.1.1.1.1.1.cmml" xref="A2.E10.m1.1.1.1.1.1.1"></plus><ci id="A2.E10.m1.1.1.1.1.1.2.cmml" xref="A2.E10.m1.1.1.1.1.1.2">𝑡</ci><cn id="A2.E10.m1.1.1.1.1.1.3.cmml" type="integer" xref="A2.E10.m1.1.1.1.1.1.3">1</cn></apply></apply><apply id="A2.E10.m1.5.5.1.cmml" xref="A2.E10.m1.5.5.1"><minus id="A2.E10.m1.5.5.1.2.cmml" xref="A2.E10.m1.5.5.1.2"></minus><apply id="A2.E10.m1.5.5.1.3.cmml" xref="A2.E10.m1.5.5.1.3"><csymbol cd="ambiguous" id="A2.E10.m1.5.5.1.3.1.cmml" xref="A2.E10.m1.5.5.1.3">superscript</csymbol><ci id="A2.E10.m1.5.5.1.3.2.cmml" xref="A2.E10.m1.5.5.1.3.2">italic-ϕ</ci><ci id="A2.E10.m1.2.2.1.1.cmml" xref="A2.E10.m1.2.2.1.1">𝑡</ci></apply><apply id="A2.E10.m1.5.5.1.1.cmml" xref="A2.E10.m1.5.5.1.1"><times id="A2.E10.m1.5.5.1.1.2.cmml" xref="A2.E10.m1.5.5.1.1.2"></times><apply id="A2.E10.m1.5.5.1.1.3.cmml" xref="A2.E10.m1.5.5.1.1.3"><csymbol cd="ambiguous" id="A2.E10.m1.5.5.1.1.3.1.cmml" xref="A2.E10.m1.5.5.1.1.3">subscript</csymbol><ci id="A2.E10.m1.5.5.1.1.3.2.cmml" xref="A2.E10.m1.5.5.1.1.3.2">𝛽</ci><cn id="A2.E10.m1.5.5.1.1.3.3.cmml" type="integer" xref="A2.E10.m1.5.5.1.1.3.3">1</cn></apply><apply id="A2.E10.m1.5.5.1.1.4.cmml" xref="A2.E10.m1.5.5.1.1.4"><apply id="A2.E10.m1.5.5.1.1.4.1.cmml" xref="A2.E10.m1.5.5.1.1.4.1"><csymbol cd="ambiguous" id="A2.E10.m1.5.5.1.1.4.1.1.cmml" xref="A2.E10.m1.5.5.1.1.4.1">subscript</csymbol><ci id="A2.E10.m1.5.5.1.1.4.1.2.cmml" xref="A2.E10.m1.5.5.1.1.4.1.2">∇</ci><ci id="A2.E10.m1.5.5.1.1.4.1.3.cmml" xref="A2.E10.m1.5.5.1.1.4.1.3">italic-ϕ</ci></apply><apply id="A2.E10.m1.5.5.1.1.4.2.cmml" xref="A2.E10.m1.5.5.1.1.4.2"><csymbol cd="ambiguous" id="A2.E10.m1.5.5.1.1.4.2.1.cmml" xref="A2.E10.m1.5.5.1.1.4.2">subscript</csymbol><ci id="A2.E10.m1.5.5.1.1.4.2.2.cmml" xref="A2.E10.m1.5.5.1.1.4.2.2">ℒ</ci><apply id="A2.E10.m1.5.5.1.1.4.2.3.cmml" xref="A2.E10.m1.5.5.1.1.4.2.3"><times id="A2.E10.m1.5.5.1.1.4.2.3.1.cmml" xref="A2.E10.m1.5.5.1.1.4.2.3.1"></times><ci id="A2.E10.m1.5.5.1.1.4.2.3.2.cmml" xref="A2.E10.m1.5.5.1.1.4.2.3.2">𝑡</ci><ci id="A2.E10.m1.5.5.1.1.4.2.3.3.cmml" xref="A2.E10.m1.5.5.1.1.4.2.3.3">𝑟</ci></apply></apply></apply><vector id="A2.E10.m1.5.5.1.1.1.2.cmml" xref="A2.E10.m1.5.5.1.1.1.1"><apply id="A2.E10.m1.5.5.1.1.1.1.1.cmml" xref="A2.E10.m1.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="A2.E10.m1.5.5.1.1.1.1.1.1.cmml" xref="A2.E10.m1.5.5.1.1.1.1.1">subscript</csymbol><ci id="A2.E10.m1.5.5.1.1.1.1.1.2.cmml" xref="A2.E10.m1.5.5.1.1.1.1.1.2">𝒟</ci><apply id="A2.E10.m1.5.5.1.1.1.1.1.3.cmml" xref="A2.E10.m1.5.5.1.1.1.1.1.3"><times id="A2.E10.m1.5.5.1.1.1.1.1.3.1.cmml" xref="A2.E10.m1.5.5.1.1.1.1.1.3.1"></times><ci id="A2.E10.m1.5.5.1.1.1.1.1.3.2.cmml" xref="A2.E10.m1.5.5.1.1.1.1.1.3.2">𝑡</ci><ci id="A2.E10.m1.5.5.1.1.1.1.1.3.3.cmml" xref="A2.E10.m1.5.5.1.1.1.1.1.3.3">𝑟</ci></apply></apply><ci id="A2.E10.m1.3.3.cmml" xref="A2.E10.m1.3.3">italic-ϕ</ci><ci id="A2.E10.m1.4.4.cmml" xref="A2.E10.m1.4.4">𝛼</ci></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.E10.m1.5c">\phi^{(t+1)}=\phi^{(t)}-\beta_{1}\nabla_{\phi}\mathcal{L}_{tr}(\mathcal{D}_{tr%
},\phi,\alpha)</annotation><annotation encoding="application/x-llamapun" id="A2.E10.m1.5d">italic_ϕ start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT = italic_ϕ start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT - italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∇ start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT ( caligraphic_D start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT , italic_ϕ , italic_α )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="A2.p3">
<p class="ltx_p" id="A2.p3.3">where <math alttext="\beta_{1}" class="ltx_Math" display="inline" id="A2.p3.1.m1.1"><semantics id="A2.p3.1.m1.1a"><msub id="A2.p3.1.m1.1.1" xref="A2.p3.1.m1.1.1.cmml"><mi id="A2.p3.1.m1.1.1.2" xref="A2.p3.1.m1.1.1.2.cmml">β</mi><mn id="A2.p3.1.m1.1.1.3" xref="A2.p3.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A2.p3.1.m1.1b"><apply id="A2.p3.1.m1.1.1.cmml" xref="A2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="A2.p3.1.m1.1.1.1.cmml" xref="A2.p3.1.m1.1.1">subscript</csymbol><ci id="A2.p3.1.m1.1.1.2.cmml" xref="A2.p3.1.m1.1.1.2">𝛽</ci><cn id="A2.p3.1.m1.1.1.3.cmml" type="integer" xref="A2.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.1.m1.1c">\beta_{1}</annotation><annotation encoding="application/x-llamapun" id="A2.p3.1.m1.1d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> is the learning rate in lower level optimization. After obtaining the updated PRM parameter <math alttext="\phi^{(t+1)}" class="ltx_Math" display="inline" id="A2.p3.2.m2.1"><semantics id="A2.p3.2.m2.1a"><msup id="A2.p3.2.m2.1.2" xref="A2.p3.2.m2.1.2.cmml"><mi id="A2.p3.2.m2.1.2.2" xref="A2.p3.2.m2.1.2.2.cmml">ϕ</mi><mrow id="A2.p3.2.m2.1.1.1.1" xref="A2.p3.2.m2.1.1.1.1.1.cmml"><mo id="A2.p3.2.m2.1.1.1.1.2" stretchy="false" xref="A2.p3.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="A2.p3.2.m2.1.1.1.1.1" xref="A2.p3.2.m2.1.1.1.1.1.cmml"><mi id="A2.p3.2.m2.1.1.1.1.1.2" xref="A2.p3.2.m2.1.1.1.1.1.2.cmml">t</mi><mo id="A2.p3.2.m2.1.1.1.1.1.1" xref="A2.p3.2.m2.1.1.1.1.1.1.cmml">+</mo><mn id="A2.p3.2.m2.1.1.1.1.1.3" xref="A2.p3.2.m2.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="A2.p3.2.m2.1.1.1.1.3" stretchy="false" xref="A2.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="A2.p3.2.m2.1b"><apply id="A2.p3.2.m2.1.2.cmml" xref="A2.p3.2.m2.1.2"><csymbol cd="ambiguous" id="A2.p3.2.m2.1.2.1.cmml" xref="A2.p3.2.m2.1.2">superscript</csymbol><ci id="A2.p3.2.m2.1.2.2.cmml" xref="A2.p3.2.m2.1.2.2">italic-ϕ</ci><apply id="A2.p3.2.m2.1.1.1.1.1.cmml" xref="A2.p3.2.m2.1.1.1.1"><plus id="A2.p3.2.m2.1.1.1.1.1.1.cmml" xref="A2.p3.2.m2.1.1.1.1.1.1"></plus><ci id="A2.p3.2.m2.1.1.1.1.1.2.cmml" xref="A2.p3.2.m2.1.1.1.1.1.2">𝑡</ci><cn id="A2.p3.2.m2.1.1.1.1.1.3.cmml" type="integer" xref="A2.p3.2.m2.1.1.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.2.m2.1c">\phi^{(t+1)}</annotation><annotation encoding="application/x-llamapun" id="A2.p3.2.m2.1d">italic_ϕ start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT</annotation></semantics></math> from Equation <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A2.E10" title="In Appendix B Optimization algorithm ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">10</span></a>, the domain-reweighting parameter <math alttext="\alpha" class="ltx_Math" display="inline" id="A2.p3.3.m3.1"><semantics id="A2.p3.3.m3.1a"><mi id="A2.p3.3.m3.1.1" xref="A2.p3.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A2.p3.3.m3.1b"><ci id="A2.p3.3.m3.1.1.cmml" xref="A2.p3.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.3.m3.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="A2.p3.3.m3.1d">italic_α</annotation></semantics></math> is then updated as follows:</p>
</div>
<div class="ltx_para" id="A2.p4">
<table class="ltx_equation ltx_eqn_table" id="A2.E11">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\alpha^{(t+1)}=\alpha^{(t)}-\beta_{2}\nabla_{\alpha}\mathcal{L}_{meta}(%
\mathcal{D}_{meta},\phi^{*}(\alpha))" class="ltx_Math" display="block" id="A2.E11.m1.5"><semantics id="A2.E11.m1.5a"><mrow id="A2.E11.m1.5.5" xref="A2.E11.m1.5.5.cmml"><msup id="A2.E11.m1.5.5.4" xref="A2.E11.m1.5.5.4.cmml"><mi id="A2.E11.m1.5.5.4.2" xref="A2.E11.m1.5.5.4.2.cmml">α</mi><mrow id="A2.E11.m1.1.1.1.1" xref="A2.E11.m1.1.1.1.1.1.cmml"><mo id="A2.E11.m1.1.1.1.1.2" stretchy="false" xref="A2.E11.m1.1.1.1.1.1.cmml">(</mo><mrow id="A2.E11.m1.1.1.1.1.1" xref="A2.E11.m1.1.1.1.1.1.cmml"><mi id="A2.E11.m1.1.1.1.1.1.2" xref="A2.E11.m1.1.1.1.1.1.2.cmml">t</mi><mo id="A2.E11.m1.1.1.1.1.1.1" xref="A2.E11.m1.1.1.1.1.1.1.cmml">+</mo><mn id="A2.E11.m1.1.1.1.1.1.3" xref="A2.E11.m1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="A2.E11.m1.1.1.1.1.3" stretchy="false" xref="A2.E11.m1.1.1.1.1.1.cmml">)</mo></mrow></msup><mo id="A2.E11.m1.5.5.3" xref="A2.E11.m1.5.5.3.cmml">=</mo><mrow id="A2.E11.m1.5.5.2" xref="A2.E11.m1.5.5.2.cmml"><msup id="A2.E11.m1.5.5.2.4" xref="A2.E11.m1.5.5.2.4.cmml"><mi id="A2.E11.m1.5.5.2.4.2" xref="A2.E11.m1.5.5.2.4.2.cmml">α</mi><mrow id="A2.E11.m1.2.2.1.3" xref="A2.E11.m1.5.5.2.4.cmml"><mo id="A2.E11.m1.2.2.1.3.1" stretchy="false" xref="A2.E11.m1.5.5.2.4.cmml">(</mo><mi id="A2.E11.m1.2.2.1.1" xref="A2.E11.m1.2.2.1.1.cmml">t</mi><mo id="A2.E11.m1.2.2.1.3.2" stretchy="false" xref="A2.E11.m1.5.5.2.4.cmml">)</mo></mrow></msup><mo id="A2.E11.m1.5.5.2.3" xref="A2.E11.m1.5.5.2.3.cmml">−</mo><mrow id="A2.E11.m1.5.5.2.2" xref="A2.E11.m1.5.5.2.2.cmml"><msub id="A2.E11.m1.5.5.2.2.4" xref="A2.E11.m1.5.5.2.2.4.cmml"><mi id="A2.E11.m1.5.5.2.2.4.2" xref="A2.E11.m1.5.5.2.2.4.2.cmml">β</mi><mn id="A2.E11.m1.5.5.2.2.4.3" xref="A2.E11.m1.5.5.2.2.4.3.cmml">2</mn></msub><mo id="A2.E11.m1.5.5.2.2.3" lspace="0.167em" xref="A2.E11.m1.5.5.2.2.3.cmml">⁢</mo><mrow id="A2.E11.m1.5.5.2.2.5" xref="A2.E11.m1.5.5.2.2.5.cmml"><msub id="A2.E11.m1.5.5.2.2.5.1" xref="A2.E11.m1.5.5.2.2.5.1.cmml"><mo id="A2.E11.m1.5.5.2.2.5.1.2" rspace="0.167em" xref="A2.E11.m1.5.5.2.2.5.1.2.cmml">∇</mo><mi id="A2.E11.m1.5.5.2.2.5.1.3" xref="A2.E11.m1.5.5.2.2.5.1.3.cmml">α</mi></msub><msub id="A2.E11.m1.5.5.2.2.5.2" xref="A2.E11.m1.5.5.2.2.5.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.E11.m1.5.5.2.2.5.2.2" xref="A2.E11.m1.5.5.2.2.5.2.2.cmml">ℒ</mi><mrow id="A2.E11.m1.5.5.2.2.5.2.3" xref="A2.E11.m1.5.5.2.2.5.2.3.cmml"><mi id="A2.E11.m1.5.5.2.2.5.2.3.2" xref="A2.E11.m1.5.5.2.2.5.2.3.2.cmml">m</mi><mo id="A2.E11.m1.5.5.2.2.5.2.3.1" xref="A2.E11.m1.5.5.2.2.5.2.3.1.cmml">⁢</mo><mi id="A2.E11.m1.5.5.2.2.5.2.3.3" xref="A2.E11.m1.5.5.2.2.5.2.3.3.cmml">e</mi><mo id="A2.E11.m1.5.5.2.2.5.2.3.1a" xref="A2.E11.m1.5.5.2.2.5.2.3.1.cmml">⁢</mo><mi id="A2.E11.m1.5.5.2.2.5.2.3.4" xref="A2.E11.m1.5.5.2.2.5.2.3.4.cmml">t</mi><mo id="A2.E11.m1.5.5.2.2.5.2.3.1b" xref="A2.E11.m1.5.5.2.2.5.2.3.1.cmml">⁢</mo><mi id="A2.E11.m1.5.5.2.2.5.2.3.5" xref="A2.E11.m1.5.5.2.2.5.2.3.5.cmml">a</mi></mrow></msub></mrow><mo id="A2.E11.m1.5.5.2.2.3a" xref="A2.E11.m1.5.5.2.2.3.cmml">⁢</mo><mrow id="A2.E11.m1.5.5.2.2.2.2" xref="A2.E11.m1.5.5.2.2.2.3.cmml"><mo id="A2.E11.m1.5.5.2.2.2.2.3" stretchy="false" xref="A2.E11.m1.5.5.2.2.2.3.cmml">(</mo><msub id="A2.E11.m1.4.4.1.1.1.1.1" xref="A2.E11.m1.4.4.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.E11.m1.4.4.1.1.1.1.1.2" xref="A2.E11.m1.4.4.1.1.1.1.1.2.cmml">𝒟</mi><mrow id="A2.E11.m1.4.4.1.1.1.1.1.3" xref="A2.E11.m1.4.4.1.1.1.1.1.3.cmml"><mi id="A2.E11.m1.4.4.1.1.1.1.1.3.2" xref="A2.E11.m1.4.4.1.1.1.1.1.3.2.cmml">m</mi><mo id="A2.E11.m1.4.4.1.1.1.1.1.3.1" xref="A2.E11.m1.4.4.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="A2.E11.m1.4.4.1.1.1.1.1.3.3" xref="A2.E11.m1.4.4.1.1.1.1.1.3.3.cmml">e</mi><mo id="A2.E11.m1.4.4.1.1.1.1.1.3.1a" xref="A2.E11.m1.4.4.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="A2.E11.m1.4.4.1.1.1.1.1.3.4" xref="A2.E11.m1.4.4.1.1.1.1.1.3.4.cmml">t</mi><mo id="A2.E11.m1.4.4.1.1.1.1.1.3.1b" xref="A2.E11.m1.4.4.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="A2.E11.m1.4.4.1.1.1.1.1.3.5" xref="A2.E11.m1.4.4.1.1.1.1.1.3.5.cmml">a</mi></mrow></msub><mo id="A2.E11.m1.5.5.2.2.2.2.4" xref="A2.E11.m1.5.5.2.2.2.3.cmml">,</mo><mrow id="A2.E11.m1.5.5.2.2.2.2.2" xref="A2.E11.m1.5.5.2.2.2.2.2.cmml"><msup id="A2.E11.m1.5.5.2.2.2.2.2.2" xref="A2.E11.m1.5.5.2.2.2.2.2.2.cmml"><mi id="A2.E11.m1.5.5.2.2.2.2.2.2.2" xref="A2.E11.m1.5.5.2.2.2.2.2.2.2.cmml">ϕ</mi><mo id="A2.E11.m1.5.5.2.2.2.2.2.2.3" xref="A2.E11.m1.5.5.2.2.2.2.2.2.3.cmml">∗</mo></msup><mo id="A2.E11.m1.5.5.2.2.2.2.2.1" xref="A2.E11.m1.5.5.2.2.2.2.2.1.cmml">⁢</mo><mrow id="A2.E11.m1.5.5.2.2.2.2.2.3.2" xref="A2.E11.m1.5.5.2.2.2.2.2.cmml"><mo id="A2.E11.m1.5.5.2.2.2.2.2.3.2.1" stretchy="false" xref="A2.E11.m1.5.5.2.2.2.2.2.cmml">(</mo><mi id="A2.E11.m1.3.3" xref="A2.E11.m1.3.3.cmml">α</mi><mo id="A2.E11.m1.5.5.2.2.2.2.2.3.2.2" stretchy="false" xref="A2.E11.m1.5.5.2.2.2.2.2.cmml">)</mo></mrow></mrow><mo id="A2.E11.m1.5.5.2.2.2.2.5" stretchy="false" xref="A2.E11.m1.5.5.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.E11.m1.5b"><apply id="A2.E11.m1.5.5.cmml" xref="A2.E11.m1.5.5"><eq id="A2.E11.m1.5.5.3.cmml" xref="A2.E11.m1.5.5.3"></eq><apply id="A2.E11.m1.5.5.4.cmml" xref="A2.E11.m1.5.5.4"><csymbol cd="ambiguous" id="A2.E11.m1.5.5.4.1.cmml" xref="A2.E11.m1.5.5.4">superscript</csymbol><ci id="A2.E11.m1.5.5.4.2.cmml" xref="A2.E11.m1.5.5.4.2">𝛼</ci><apply id="A2.E11.m1.1.1.1.1.1.cmml" xref="A2.E11.m1.1.1.1.1"><plus id="A2.E11.m1.1.1.1.1.1.1.cmml" xref="A2.E11.m1.1.1.1.1.1.1"></plus><ci id="A2.E11.m1.1.1.1.1.1.2.cmml" xref="A2.E11.m1.1.1.1.1.1.2">𝑡</ci><cn id="A2.E11.m1.1.1.1.1.1.3.cmml" type="integer" xref="A2.E11.m1.1.1.1.1.1.3">1</cn></apply></apply><apply id="A2.E11.m1.5.5.2.cmml" xref="A2.E11.m1.5.5.2"><minus id="A2.E11.m1.5.5.2.3.cmml" xref="A2.E11.m1.5.5.2.3"></minus><apply id="A2.E11.m1.5.5.2.4.cmml" xref="A2.E11.m1.5.5.2.4"><csymbol cd="ambiguous" id="A2.E11.m1.5.5.2.4.1.cmml" xref="A2.E11.m1.5.5.2.4">superscript</csymbol><ci id="A2.E11.m1.5.5.2.4.2.cmml" xref="A2.E11.m1.5.5.2.4.2">𝛼</ci><ci id="A2.E11.m1.2.2.1.1.cmml" xref="A2.E11.m1.2.2.1.1">𝑡</ci></apply><apply id="A2.E11.m1.5.5.2.2.cmml" xref="A2.E11.m1.5.5.2.2"><times id="A2.E11.m1.5.5.2.2.3.cmml" xref="A2.E11.m1.5.5.2.2.3"></times><apply id="A2.E11.m1.5.5.2.2.4.cmml" xref="A2.E11.m1.5.5.2.2.4"><csymbol cd="ambiguous" id="A2.E11.m1.5.5.2.2.4.1.cmml" xref="A2.E11.m1.5.5.2.2.4">subscript</csymbol><ci id="A2.E11.m1.5.5.2.2.4.2.cmml" xref="A2.E11.m1.5.5.2.2.4.2">𝛽</ci><cn id="A2.E11.m1.5.5.2.2.4.3.cmml" type="integer" xref="A2.E11.m1.5.5.2.2.4.3">2</cn></apply><apply id="A2.E11.m1.5.5.2.2.5.cmml" xref="A2.E11.m1.5.5.2.2.5"><apply id="A2.E11.m1.5.5.2.2.5.1.cmml" xref="A2.E11.m1.5.5.2.2.5.1"><csymbol cd="ambiguous" id="A2.E11.m1.5.5.2.2.5.1.1.cmml" xref="A2.E11.m1.5.5.2.2.5.1">subscript</csymbol><ci id="A2.E11.m1.5.5.2.2.5.1.2.cmml" xref="A2.E11.m1.5.5.2.2.5.1.2">∇</ci><ci id="A2.E11.m1.5.5.2.2.5.1.3.cmml" xref="A2.E11.m1.5.5.2.2.5.1.3">𝛼</ci></apply><apply id="A2.E11.m1.5.5.2.2.5.2.cmml" xref="A2.E11.m1.5.5.2.2.5.2"><csymbol cd="ambiguous" id="A2.E11.m1.5.5.2.2.5.2.1.cmml" xref="A2.E11.m1.5.5.2.2.5.2">subscript</csymbol><ci id="A2.E11.m1.5.5.2.2.5.2.2.cmml" xref="A2.E11.m1.5.5.2.2.5.2.2">ℒ</ci><apply id="A2.E11.m1.5.5.2.2.5.2.3.cmml" xref="A2.E11.m1.5.5.2.2.5.2.3"><times id="A2.E11.m1.5.5.2.2.5.2.3.1.cmml" xref="A2.E11.m1.5.5.2.2.5.2.3.1"></times><ci id="A2.E11.m1.5.5.2.2.5.2.3.2.cmml" xref="A2.E11.m1.5.5.2.2.5.2.3.2">𝑚</ci><ci id="A2.E11.m1.5.5.2.2.5.2.3.3.cmml" xref="A2.E11.m1.5.5.2.2.5.2.3.3">𝑒</ci><ci id="A2.E11.m1.5.5.2.2.5.2.3.4.cmml" xref="A2.E11.m1.5.5.2.2.5.2.3.4">𝑡</ci><ci id="A2.E11.m1.5.5.2.2.5.2.3.5.cmml" xref="A2.E11.m1.5.5.2.2.5.2.3.5">𝑎</ci></apply></apply></apply><interval closure="open" id="A2.E11.m1.5.5.2.2.2.3.cmml" xref="A2.E11.m1.5.5.2.2.2.2"><apply id="A2.E11.m1.4.4.1.1.1.1.1.cmml" xref="A2.E11.m1.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="A2.E11.m1.4.4.1.1.1.1.1.1.cmml" xref="A2.E11.m1.4.4.1.1.1.1.1">subscript</csymbol><ci id="A2.E11.m1.4.4.1.1.1.1.1.2.cmml" xref="A2.E11.m1.4.4.1.1.1.1.1.2">𝒟</ci><apply id="A2.E11.m1.4.4.1.1.1.1.1.3.cmml" xref="A2.E11.m1.4.4.1.1.1.1.1.3"><times id="A2.E11.m1.4.4.1.1.1.1.1.3.1.cmml" xref="A2.E11.m1.4.4.1.1.1.1.1.3.1"></times><ci id="A2.E11.m1.4.4.1.1.1.1.1.3.2.cmml" xref="A2.E11.m1.4.4.1.1.1.1.1.3.2">𝑚</ci><ci id="A2.E11.m1.4.4.1.1.1.1.1.3.3.cmml" xref="A2.E11.m1.4.4.1.1.1.1.1.3.3">𝑒</ci><ci id="A2.E11.m1.4.4.1.1.1.1.1.3.4.cmml" xref="A2.E11.m1.4.4.1.1.1.1.1.3.4">𝑡</ci><ci id="A2.E11.m1.4.4.1.1.1.1.1.3.5.cmml" xref="A2.E11.m1.4.4.1.1.1.1.1.3.5">𝑎</ci></apply></apply><apply id="A2.E11.m1.5.5.2.2.2.2.2.cmml" xref="A2.E11.m1.5.5.2.2.2.2.2"><times id="A2.E11.m1.5.5.2.2.2.2.2.1.cmml" xref="A2.E11.m1.5.5.2.2.2.2.2.1"></times><apply id="A2.E11.m1.5.5.2.2.2.2.2.2.cmml" xref="A2.E11.m1.5.5.2.2.2.2.2.2"><csymbol cd="ambiguous" id="A2.E11.m1.5.5.2.2.2.2.2.2.1.cmml" xref="A2.E11.m1.5.5.2.2.2.2.2.2">superscript</csymbol><ci id="A2.E11.m1.5.5.2.2.2.2.2.2.2.cmml" xref="A2.E11.m1.5.5.2.2.2.2.2.2.2">italic-ϕ</ci><times id="A2.E11.m1.5.5.2.2.2.2.2.2.3.cmml" xref="A2.E11.m1.5.5.2.2.2.2.2.2.3"></times></apply><ci id="A2.E11.m1.3.3.cmml" xref="A2.E11.m1.3.3">𝛼</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.E11.m1.5c">\alpha^{(t+1)}=\alpha^{(t)}-\beta_{2}\nabla_{\alpha}\mathcal{L}_{meta}(%
\mathcal{D}_{meta},\phi^{*}(\alpha))</annotation><annotation encoding="application/x-llamapun" id="A2.E11.m1.5d">italic_α start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT = italic_α start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT - italic_β start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ∇ start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT ( caligraphic_D start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT , italic_ϕ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_α ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="A2.p5">
<p class="ltx_p" id="A2.p5.3">where <math alttext="\beta_{2}" class="ltx_Math" display="inline" id="A2.p5.1.m1.1"><semantics id="A2.p5.1.m1.1a"><msub id="A2.p5.1.m1.1.1" xref="A2.p5.1.m1.1.1.cmml"><mi id="A2.p5.1.m1.1.1.2" xref="A2.p5.1.m1.1.1.2.cmml">β</mi><mn id="A2.p5.1.m1.1.1.3" xref="A2.p5.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A2.p5.1.m1.1b"><apply id="A2.p5.1.m1.1.1.cmml" xref="A2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="A2.p5.1.m1.1.1.1.cmml" xref="A2.p5.1.m1.1.1">subscript</csymbol><ci id="A2.p5.1.m1.1.1.2.cmml" xref="A2.p5.1.m1.1.1.2">𝛽</ci><cn id="A2.p5.1.m1.1.1.3.cmml" type="integer" xref="A2.p5.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p5.1.m1.1c">\beta_{2}</annotation><annotation encoding="application/x-llamapun" id="A2.p5.1.m1.1d">italic_β start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> is the learning rate for upper level optimization. The two optimization steps in Equation <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A2.E10" title="In Appendix B Optimization algorithm ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">10</span></a> and Equation <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A2.E11" title="In Appendix B Optimization algorithm ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">11</span></a> are conducted iteratively until convergence to get optimal PRM weights <math alttext="\phi^{*}" class="ltx_Math" display="inline" id="A2.p5.2.m2.1"><semantics id="A2.p5.2.m2.1a"><msup id="A2.p5.2.m2.1.1" xref="A2.p5.2.m2.1.1.cmml"><mi id="A2.p5.2.m2.1.1.2" xref="A2.p5.2.m2.1.1.2.cmml">ϕ</mi><mo id="A2.p5.2.m2.1.1.3" xref="A2.p5.2.m2.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="A2.p5.2.m2.1b"><apply id="A2.p5.2.m2.1.1.cmml" xref="A2.p5.2.m2.1.1"><csymbol cd="ambiguous" id="A2.p5.2.m2.1.1.1.cmml" xref="A2.p5.2.m2.1.1">superscript</csymbol><ci id="A2.p5.2.m2.1.1.2.cmml" xref="A2.p5.2.m2.1.1.2">italic-ϕ</ci><times id="A2.p5.2.m2.1.1.3.cmml" xref="A2.p5.2.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p5.2.m2.1c">\phi^{*}</annotation><annotation encoding="application/x-llamapun" id="A2.p5.2.m2.1d">italic_ϕ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math> and optimal domain reweighting parameter <math alttext="\alpha^{*}" class="ltx_Math" display="inline" id="A2.p5.3.m3.1"><semantics id="A2.p5.3.m3.1a"><msup id="A2.p5.3.m3.1.1" xref="A2.p5.3.m3.1.1.cmml"><mi id="A2.p5.3.m3.1.1.2" xref="A2.p5.3.m3.1.1.2.cmml">α</mi><mo id="A2.p5.3.m3.1.1.3" xref="A2.p5.3.m3.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="A2.p5.3.m3.1b"><apply id="A2.p5.3.m3.1.1.cmml" xref="A2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="A2.p5.3.m3.1.1.1.cmml" xref="A2.p5.3.m3.1.1">superscript</csymbol><ci id="A2.p5.3.m3.1.1.2.cmml" xref="A2.p5.3.m3.1.1.2">𝛼</ci><times id="A2.p5.3.m3.1.1.3.cmml" xref="A2.p5.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p5.3.m3.1c">\alpha^{*}</annotation><annotation encoding="application/x-llamapun" id="A2.p5.3.m3.1d">italic_α start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Dataset Details</h2>
<figure class="ltx_table" id="A3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A3.T2.2.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="A3.T2.3.2" style="font-size:90%;">Multimodal datasets involved in the fine-tuning of DreamPRM, organized by task category.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T2.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A3.T2.4.1.1" style="background-color:#FFFFFF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A3.T2.4.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T2.4.1.1.1.1" style="background-color:#FFFFFF;">Task</span></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A3.T2.4.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.4.1.1.2.1" style="background-color:#FFFFFF;">
<span class="ltx_p" id="A3.T2.4.1.1.2.1.1" style="width:284.5pt;"><span class="ltx_text ltx_font_bold" id="A3.T2.4.1.1.2.1.1.1">Dataset</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T2.4.2.1" style="background-color:#FFFFFF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A3.T2.4.2.1.1"><span class="ltx_text" id="A3.T2.4.2.1.1.1" style="background-color:#FFFFFF;">Science</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T2.4.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.4.2.1.2.1" style="background-color:#FFFFFF;">
<span class="ltx_p" id="A3.T2.4.2.1.2.1.1" style="width:284.5pt;">AI2D <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib21" title=""><span class="ltx_text" style="font-size:80%;">21</span></a>]</cite>, ScienceQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib32" title=""><span class="ltx_text" style="font-size:80%;">32</span></a>]</cite>, M3CoT <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib5" title=""><span class="ltx_text" style="font-size:80%;">5</span></a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T2.4.3.2" style="background-color:#ECECEC;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T2.4.3.2.1"><span class="ltx_text" id="A3.T2.4.3.2.1.1" style="background-color:#ECECEC;">Chart</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T2.4.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.4.3.2.2.1" style="background-color:#ECECEC;">
<span class="ltx_p" id="A3.T2.4.3.2.2.1.1" style="width:284.5pt;">ChartQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib36" title=""><span class="ltx_text" style="font-size:80%;">36</span></a>]</cite>, DVQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib18" title=""><span class="ltx_text" style="font-size:80%;">18</span></a>]</cite>, MapQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib2" title=""><span class="ltx_text" style="font-size:80%;">2</span></a>]</cite>, FigureQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib19" title=""><span class="ltx_text" style="font-size:80%;">19</span></a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T2.4.4.3" style="background-color:#FFFFFF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T2.4.4.3.1"><span class="ltx_text" id="A3.T2.4.4.3.1.1" style="background-color:#FFFFFF;">Geometry</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T2.4.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.4.4.3.2.1" style="background-color:#FFFFFF;">
<span class="ltx_p" id="A3.T2.4.4.3.2.1.1" style="width:284.5pt;">Geo170k <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib14" title=""><span class="ltx_text" style="font-size:80%;">14</span></a>]</cite>, Geometry3K <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib31" title=""><span class="ltx_text" style="font-size:80%;">31</span></a>]</cite>, UniGeo <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib3" title=""><span class="ltx_text" style="font-size:80%;">3</span></a>]</cite>, GeomVerse <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib20" title=""><span class="ltx_text" style="font-size:80%;">20</span></a>]</cite>, GeoS <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib45" title=""><span class="ltx_text" style="font-size:80%;">45</span></a>]</cite></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T2.4.5.4" style="background-color:#ECECEC;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A3.T2.4.5.4.1"><span class="ltx_text" id="A3.T2.4.5.4.1.1" style="background-color:#ECECEC;">Commonsense</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A3.T2.4.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.4.5.4.2.1" style="background-color:#ECECEC;">
<span class="ltx_p" id="A3.T2.4.5.4.2.1.1" style="width:284.5pt;">IconQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib33" title=""><span class="ltx_text" style="font-size:80%;">33</span></a>]</cite>, InfographicsVQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib37" title=""><span class="ltx_text" style="font-size:80%;">37</span></a>]</cite>, CLEVR-Math <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib27" title=""><span class="ltx_text" style="font-size:80%;">27</span></a>]</cite></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.2">To enhance the robustness of DreamPRM, we collect a diverse set of datasets in lower-level optimization, spanning multiple domains to ensure a comprehensive coverage of multimodal reasoning tasks, as reported in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A3.T2" title="Table 2 ‣ Appendix C Dataset Details ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">2</span></a>. The selected 15 multimodal datasets covers 4 major categories including science, chart, geometry and commonsense, with a wide range of task types (QA, OCR, spatial understanding).
Additionally, we observe that for some questions, given the current structural thinking prompts, MLLMs consistently produce either correct or incorrect answers. Continuing to sample such questions is a waste of computational resources. Inspired by the dynamic sampling strategy in DAPO <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib69" title=""><span class="ltx_text" style="font-size:80%;">69</span></a>]</cite>, we propose a similar dynamic sampling technique for Monte Carlo estimation that focuses on prompts with varied outcomes to improve efficiency. After processing and sampling, the training datasets in lower-level <math alttext="\mathcal{D}_{tr}" class="ltx_Math" display="inline" id="A3.p1.1.m1.1"><semantics id="A3.p1.1.m1.1a"><msub id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A3.p1.1.m1.1.1.2" xref="A3.p1.1.m1.1.1.2.cmml">𝒟</mi><mrow id="A3.p1.1.m1.1.1.3" xref="A3.p1.1.m1.1.1.3.cmml"><mi id="A3.p1.1.m1.1.1.3.2" xref="A3.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="A3.p1.1.m1.1.1.3.1" xref="A3.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.p1.1.m1.1.1.3.3" xref="A3.p1.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><apply id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.p1.1.m1.1.1.1.cmml" xref="A3.p1.1.m1.1.1">subscript</csymbol><ci id="A3.p1.1.m1.1.1.2.cmml" xref="A3.p1.1.m1.1.1.2">𝒟</ci><apply id="A3.p1.1.m1.1.1.3.cmml" xref="A3.p1.1.m1.1.1.3"><times id="A3.p1.1.m1.1.1.3.1.cmml" xref="A3.p1.1.m1.1.1.3.1"></times><ci id="A3.p1.1.m1.1.1.3.2.cmml" xref="A3.p1.1.m1.1.1.3.2">𝑡</ci><ci id="A3.p1.1.m1.1.1.3.3.cmml" xref="A3.p1.1.m1.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">\mathcal{D}_{tr}</annotation><annotation encoding="application/x-llamapun" id="A3.p1.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_t italic_r end_POSTSUBSCRIPT</annotation></semantics></math> have around 15k examples (1k per each of the 15 domains), while the meta dataset in the upper-level <math alttext="\mathcal{D}_{meta}" class="ltx_Math" display="inline" id="A3.p1.2.m2.1"><semantics id="A3.p1.2.m2.1a"><msub id="A3.p1.2.m2.1.1" xref="A3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A3.p1.2.m2.1.1.2" xref="A3.p1.2.m2.1.1.2.cmml">𝒟</mi><mrow id="A3.p1.2.m2.1.1.3" xref="A3.p1.2.m2.1.1.3.cmml"><mi id="A3.p1.2.m2.1.1.3.2" xref="A3.p1.2.m2.1.1.3.2.cmml">m</mi><mo id="A3.p1.2.m2.1.1.3.1" xref="A3.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A3.p1.2.m2.1.1.3.3" xref="A3.p1.2.m2.1.1.3.3.cmml">e</mi><mo id="A3.p1.2.m2.1.1.3.1a" xref="A3.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A3.p1.2.m2.1.1.3.4" xref="A3.p1.2.m2.1.1.3.4.cmml">t</mi><mo id="A3.p1.2.m2.1.1.3.1b" xref="A3.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A3.p1.2.m2.1.1.3.5" xref="A3.p1.2.m2.1.1.3.5.cmml">a</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A3.p1.2.m2.1b"><apply id="A3.p1.2.m2.1.1.cmml" xref="A3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A3.p1.2.m2.1.1.1.cmml" xref="A3.p1.2.m2.1.1">subscript</csymbol><ci id="A3.p1.2.m2.1.1.2.cmml" xref="A3.p1.2.m2.1.1.2">𝒟</ci><apply id="A3.p1.2.m2.1.1.3.cmml" xref="A3.p1.2.m2.1.1.3"><times id="A3.p1.2.m2.1.1.3.1.cmml" xref="A3.p1.2.m2.1.1.3.1"></times><ci id="A3.p1.2.m2.1.1.3.2.cmml" xref="A3.p1.2.m2.1.1.3.2">𝑚</ci><ci id="A3.p1.2.m2.1.1.3.3.cmml" xref="A3.p1.2.m2.1.1.3.3">𝑒</ci><ci id="A3.p1.2.m2.1.1.3.4.cmml" xref="A3.p1.2.m2.1.1.3.4">𝑡</ci><ci id="A3.p1.2.m2.1.1.3.5.cmml" xref="A3.p1.2.m2.1.1.3.5">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.2.m2.1c">\mathcal{D}_{meta}</annotation><annotation encoding="application/x-llamapun" id="A3.p1.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_m italic_e italic_t italic_a end_POSTSUBSCRIPT</annotation></semantics></math> has around 1k validation examples from the MMMU <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib70" title=""><span class="ltx_text" style="font-size:80%;">70</span></a>]</cite> dataset.</p>
</div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Structural Thinking Prompt</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">The detailed structural thinking prompt applied in our experiments is reported in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A4.F7" title="Figure 7 ‣ Appendix D Structural Thinking Prompt ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">7</span></a>. We carefully design 5 reasoning steps to boost the reasoning capabilities of the MLLMs and enable process supervision.</p>
</div>
<figure class="ltx_figure" id="A4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="257" id="A4.F7.g1" src="extracted/6475592/figures/7-1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A4.F7.2.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="A4.F7.3.2" style="font-size:90%;">Zero-shot prompting for structural thinking.</span></figcaption>
</figure>
<figure class="ltx_table" id="A4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A4.T3.10.2.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="A4.T3.2.1" style="font-size:90%;">Accuracy on MathVista using DreamPRM with varying numbers <math alttext="k" class="ltx_Math" display="inline" id="A4.T3.2.1.m1.1"><semantics id="A4.T3.2.1.m1.1b"><mi id="A4.T3.2.1.m1.1.1" xref="A4.T3.2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A4.T3.2.1.m1.1c"><ci id="A4.T3.2.1.m1.1.1.cmml" xref="A4.T3.2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T3.2.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="A4.T3.2.1.m1.1e">italic_k</annotation></semantics></math> of CoTs.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A4.T3.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.T3.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A4.T3.3.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="A4.T3.3.1.2.1">Model Name</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.T3.3.1.3">pass@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="A4.T3.3.1.1"><span class="ltx_text ltx_font_bold" id="A4.T3.3.1.1.1">DreamPRM (select <math alttext="k" class="ltx_Math" display="inline" id="A4.T3.3.1.1.1.m1.1"><semantics id="A4.T3.3.1.1.1.m1.1a"><mi id="A4.T3.3.1.1.1.m1.1.1" xref="A4.T3.3.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A4.T3.3.1.1.1.m1.1b"><ci id="A4.T3.3.1.1.1.m1.1.1.cmml" xref="A4.T3.3.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T3.3.1.1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A4.T3.3.1.1.1.m1.1d">italic_k</annotation></semantics></math> CoTs)</span></th>
</tr>
<tr class="ltx_tr" id="A4.T3.8.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T3.4.2.1"><math alttext="k{=}1" class="ltx_Math" display="inline" id="A4.T3.4.2.1.m1.1"><semantics id="A4.T3.4.2.1.m1.1a"><mrow id="A4.T3.4.2.1.m1.1.1" xref="A4.T3.4.2.1.m1.1.1.cmml"><mi id="A4.T3.4.2.1.m1.1.1.2" xref="A4.T3.4.2.1.m1.1.1.2.cmml">k</mi><mo id="A4.T3.4.2.1.m1.1.1.1" xref="A4.T3.4.2.1.m1.1.1.1.cmml">=</mo><mn id="A4.T3.4.2.1.m1.1.1.3" xref="A4.T3.4.2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T3.4.2.1.m1.1b"><apply id="A4.T3.4.2.1.m1.1.1.cmml" xref="A4.T3.4.2.1.m1.1.1"><eq id="A4.T3.4.2.1.m1.1.1.1.cmml" xref="A4.T3.4.2.1.m1.1.1.1"></eq><ci id="A4.T3.4.2.1.m1.1.1.2.cmml" xref="A4.T3.4.2.1.m1.1.1.2">𝑘</ci><cn id="A4.T3.4.2.1.m1.1.1.3.cmml" type="integer" xref="A4.T3.4.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T3.4.2.1.m1.1c">k{=}1</annotation><annotation encoding="application/x-llamapun" id="A4.T3.4.2.1.m1.1d">italic_k = 1</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T3.5.3.2"><math alttext="k{=}2" class="ltx_Math" display="inline" id="A4.T3.5.3.2.m1.1"><semantics id="A4.T3.5.3.2.m1.1a"><mrow id="A4.T3.5.3.2.m1.1.1" xref="A4.T3.5.3.2.m1.1.1.cmml"><mi id="A4.T3.5.3.2.m1.1.1.2" xref="A4.T3.5.3.2.m1.1.1.2.cmml">k</mi><mo id="A4.T3.5.3.2.m1.1.1.1" xref="A4.T3.5.3.2.m1.1.1.1.cmml">=</mo><mn id="A4.T3.5.3.2.m1.1.1.3" xref="A4.T3.5.3.2.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T3.5.3.2.m1.1b"><apply id="A4.T3.5.3.2.m1.1.1.cmml" xref="A4.T3.5.3.2.m1.1.1"><eq id="A4.T3.5.3.2.m1.1.1.1.cmml" xref="A4.T3.5.3.2.m1.1.1.1"></eq><ci id="A4.T3.5.3.2.m1.1.1.2.cmml" xref="A4.T3.5.3.2.m1.1.1.2">𝑘</ci><cn id="A4.T3.5.3.2.m1.1.1.3.cmml" type="integer" xref="A4.T3.5.3.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T3.5.3.2.m1.1c">k{=}2</annotation><annotation encoding="application/x-llamapun" id="A4.T3.5.3.2.m1.1d">italic_k = 2</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T3.6.4.3"><math alttext="k{=}4" class="ltx_Math" display="inline" id="A4.T3.6.4.3.m1.1"><semantics id="A4.T3.6.4.3.m1.1a"><mrow id="A4.T3.6.4.3.m1.1.1" xref="A4.T3.6.4.3.m1.1.1.cmml"><mi id="A4.T3.6.4.3.m1.1.1.2" xref="A4.T3.6.4.3.m1.1.1.2.cmml">k</mi><mo id="A4.T3.6.4.3.m1.1.1.1" xref="A4.T3.6.4.3.m1.1.1.1.cmml">=</mo><mn id="A4.T3.6.4.3.m1.1.1.3" xref="A4.T3.6.4.3.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T3.6.4.3.m1.1b"><apply id="A4.T3.6.4.3.m1.1.1.cmml" xref="A4.T3.6.4.3.m1.1.1"><eq id="A4.T3.6.4.3.m1.1.1.1.cmml" xref="A4.T3.6.4.3.m1.1.1.1"></eq><ci id="A4.T3.6.4.3.m1.1.1.2.cmml" xref="A4.T3.6.4.3.m1.1.1.2">𝑘</ci><cn id="A4.T3.6.4.3.m1.1.1.3.cmml" type="integer" xref="A4.T3.6.4.3.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T3.6.4.3.m1.1c">k{=}4</annotation><annotation encoding="application/x-llamapun" id="A4.T3.6.4.3.m1.1d">italic_k = 4</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T3.7.5.4"><math alttext="k{=}6" class="ltx_Math" display="inline" id="A4.T3.7.5.4.m1.1"><semantics id="A4.T3.7.5.4.m1.1a"><mrow id="A4.T3.7.5.4.m1.1.1" xref="A4.T3.7.5.4.m1.1.1.cmml"><mi id="A4.T3.7.5.4.m1.1.1.2" xref="A4.T3.7.5.4.m1.1.1.2.cmml">k</mi><mo id="A4.T3.7.5.4.m1.1.1.1" xref="A4.T3.7.5.4.m1.1.1.1.cmml">=</mo><mn id="A4.T3.7.5.4.m1.1.1.3" xref="A4.T3.7.5.4.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T3.7.5.4.m1.1b"><apply id="A4.T3.7.5.4.m1.1.1.cmml" xref="A4.T3.7.5.4.m1.1.1"><eq id="A4.T3.7.5.4.m1.1.1.1.cmml" xref="A4.T3.7.5.4.m1.1.1.1"></eq><ci id="A4.T3.7.5.4.m1.1.1.2.cmml" xref="A4.T3.7.5.4.m1.1.1.2">𝑘</ci><cn id="A4.T3.7.5.4.m1.1.1.3.cmml" type="integer" xref="A4.T3.7.5.4.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T3.7.5.4.m1.1c">k{=}6</annotation><annotation encoding="application/x-llamapun" id="A4.T3.7.5.4.m1.1d">italic_k = 6</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.T3.8.6.5"><math alttext="k{=}8" class="ltx_Math" display="inline" id="A4.T3.8.6.5.m1.1"><semantics id="A4.T3.8.6.5.m1.1a"><mrow id="A4.T3.8.6.5.m1.1.1" xref="A4.T3.8.6.5.m1.1.1.cmml"><mi id="A4.T3.8.6.5.m1.1.1.2" xref="A4.T3.8.6.5.m1.1.1.2.cmml">k</mi><mo id="A4.T3.8.6.5.m1.1.1.1" xref="A4.T3.8.6.5.m1.1.1.1.cmml">=</mo><mn id="A4.T3.8.6.5.m1.1.1.3" xref="A4.T3.8.6.5.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T3.8.6.5.m1.1b"><apply id="A4.T3.8.6.5.m1.1.1.cmml" xref="A4.T3.8.6.5.m1.1.1"><eq id="A4.T3.8.6.5.m1.1.1.1.cmml" xref="A4.T3.8.6.5.m1.1.1.1"></eq><ci id="A4.T3.8.6.5.m1.1.1.2.cmml" xref="A4.T3.8.6.5.m1.1.1.2">𝑘</ci><cn id="A4.T3.8.6.5.m1.1.1.3.cmml" type="integer" xref="A4.T3.8.6.5.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T3.8.6.5.m1.1c">k{=}8</annotation><annotation encoding="application/x-llamapun" id="A4.T3.8.6.5.m1.1d">italic_k = 8</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T3.8.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A4.T3.8.7.1.1">InternVL-2.5-8B-MPO <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib58" title=""><span class="ltx_text" style="font-size:80%;">58</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T3.8.7.1.2">65.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T3.8.7.1.3">65.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T3.8.7.1.4">66.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T3.8.7.1.5">67.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T3.8.7.1.6"><span class="ltx_text ltx_font_bold" id="A4.T3.8.7.1.6.1">68.9</span></td>
</tr>
<tr class="ltx_tr" id="A4.T3.8.8.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A4.T3.8.8.2.1">GPT-4.1-mini (4-14-25) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#bib.bib40" title=""><span class="ltx_text" style="font-size:80%;">40</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T3.8.8.2.2">71.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T3.8.8.2.3">71.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T3.8.8.2.4">72.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T3.8.8.2.5">73.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T3.8.8.2.6"><span class="ltx_text ltx_font_bold" id="A4.T3.8.8.2.6.1">74.4</span></td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A4.T4.2.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="A4.T4.3.2" style="font-size:90%;">Ablation study evaluating the impact of individual components of DreamPRM</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A4.T4.4" style="width:433.6pt;height:87.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.0pt,1.4pt) scale(0.968921249772752,0.968921249772752) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A4.T4.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.T4.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A4.T4.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.1.1.1.1">Ablation / Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.T4.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.1.1.2.1">WeMath</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.T4.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.1.1.3.1">MathVista</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.T4.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.1.1.4.1">MathVision</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.T4.4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.1.1.5.1">MMVet</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.T4.4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.1.1.6.1">MMStar</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T4.4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A4.T4.4.1.2.1.1"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.2.1.1.1">DreamPRM (original)</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.4.1.2.1.2"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.2.1.2.1">57.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.4.1.2.1.3"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.2.1.3.1">68.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.4.1.2.1.4"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.2.1.4.1">22.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.4.1.2.1.5"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.2.1.5.1">61.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.4.1.2.1.6"><span class="ltx_text ltx_font_bold" id="A4.T4.4.1.2.1.6.1">62.3</span></td>
</tr>
<tr class="ltx_tr" id="A4.T4.4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.T4.4.1.3.2.1">   w/o aggregation function loss</th>
<td class="ltx_td ltx_align_center" id="A4.T4.4.1.3.2.2">56.3 (-1.1)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.4.1.3.2.3">66.1 (-2.8)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.4.1.3.2.4">20.1 (-2.0)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.4.1.3.2.5">60.0 (-1.4)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.4.1.3.2.6">59.6 (-2.7)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.T4.4.1.4.3.1">   w/o bi-level optimization</th>
<td class="ltx_td ltx_align_center" id="A4.T4.4.1.4.3.2">55.0 (-2.4)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.4.1.4.3.3">65.4 (-3.5)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.4.1.4.3.4">19.9 (-2.2)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.4.1.4.3.5">61.2 (-0.2)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.4.1.4.3.6">58.9 (-3.4)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A4.T4.4.1.5.4.1">   w/o structural thinking</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T4.4.1.5.4.2">54.6 (-2.8)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T4.4.1.5.4.3">65.7 (-3.2)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T4.4.1.5.4.4">20.3 (-1.8)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T4.4.1.5.4.5">57.5 (-3.9)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T4.4.1.5.4.6">61.6 (-0.7)</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Additional Experimental Results</h2>
<div class="ltx_para" id="A5.p1">
<p class="ltx_p" id="A5.p1.1"><span class="ltx_text ltx_font_bold" id="A5.p1.1.1">Best-of-N results.</span> Tab. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A4.T3" title="Table 3 ‣ Appendix D Structural Thinking Prompt ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">3</span></a> reports the accuracy of two state-of-the-art models on MathVista dataset using DreamPRM with varying numbers <math alttext="k" class="ltx_Math" display="inline" id="A5.p1.1.m1.1"><semantics id="A5.p1.1.m1.1a"><mi id="A5.p1.1.m1.1.1" xref="A5.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A5.p1.1.m1.1b"><ci id="A5.p1.1.m1.1.1.cmml" xref="A5.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A5.p1.1.m1.1d">italic_k</annotation></semantics></math> of CoTs. The results indicate that the performance scales well with the number of CoTs.</p>
</div>
<div class="ltx_para" id="A5.p2">
<p class="ltx_p" id="A5.p2.1"><span class="ltx_text ltx_font_bold" id="A5.p2.1.1">Ablation studies.</span> The exact results of ablation experiments in the main paper are included in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A4.T4" title="Table 4 ‣ Appendix D Structural Thinking Prompt ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">4</span></a>, which emphasizes the importance of all the components in DreamPRM.</p>
</div>
<div class="ltx_para" id="A5.p3">
<p class="ltx_p" id="A5.p3.1"><span class="ltx_text ltx_font_bold" id="A5.p3.1.1">Loss curves and domain weights.</span> The loss curves and domain weights during the fine-tuning of DreamPRM are illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A5.F8" title="Figure 8 ‣ Appendix E Additional Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">8</span></a>. It can be observed that the learnt distribution emphasizes informative mathematical figure domains while attenuating less relevant sources. Additionally, domain weights start at 1.0 and quickly diverge, stabilizing after roughly half the training, and the inner and outer losses decrease steadily and plateau, indicating stable convergence of the bi<span class="ltx_text" id="A5.p3.1.2">-</span>level training procedure.</p>
</div>
<div class="ltx_para" id="A5.p4">
<p class="ltx_p" id="A5.p4.1"><span class="ltx_text ltx_font_bold" id="A5.p4.1.1">Case study.</span> A complete case study illustrating DreamPRM’s step-wise evaluation is reported in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2505.20241v1#A5.F9" title="Figure 9 ‣ Appendix E Additional Experimental Results ‣ DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning"><span class="ltx_text ltx_ref_tag">9</span></a>. DreamPRM assigns higher scores to high-quality, coherent reasoning steps, while penalizes flawed or unsupported steps.</p>
</div>
<figure class="ltx_figure" id="A5.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="187" id="A5.F8.g1" src="extracted/6475592/figures/6-3.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A5.F8.2.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="A5.F8.3.2" style="font-size:90%;">Optimization loss curves and dynamic domain weights throughout DreamPRM fine-tuning.</span></figcaption>
</figure>
<figure class="ltx_figure" id="A5.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1131" id="A5.F9.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A5.F9.2.1.1" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text" id="A5.F9.3.2" style="font-size:90%;">A case study of DreamPRM’s step-wise evaluation.</span></figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Limitations &amp; Future Work.</h2>
<div class="ltx_para" id="A6.p1">
<p class="ltx_p" id="A6.p1.1">DreamPRM currently assumes a fixed set of domains and requires Monte-Carlo sampling, which can be computationally heavy.
Future work could explore instance-level reweighting, adaptive sampling strategies, and integration with retrieval-augmented generation to further cut compute while broadening coverage. We will release code, trained weights, and evaluation scripts to facilitate reproducibility and community adoption.</p>
</div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon May 26 17:18:45 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
